{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhWvziuW5O5nll7o/DCbtX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/financieras/big_data/blob/main/leccion_1_1_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lección 1.1.5: Roles especializados: Ingeniero de ML, MLOps, Data Architect\n",
        "\n",
        "## 1. Introducción: La hiperespecialización del ecosistema de datos\n",
        "\n",
        "En la lección anterior vimos los tres roles fundamentales (Analyst, Scientist, Engineer). Sin embargo, a medida que las organizaciones maduran en datos, emergen **roles especializados** que resuelven problemas específicos que los roles generalistas no pueden abordar eficientemente.\n",
        "\n",
        "**Lo importante:** La especialización no significa fragmentación. Estos roles surgen cuando las organizaciones alcanzan cierta escala y complejidad, donde la profundidad experta genera más valor que la amplitud generalista. No todas las empresas necesitan todos estos roles.\n",
        "\n",
        "### ¿Cuándo aparecen roles especializados?\n",
        "\n",
        "**Señales de que necesitas especialización:**\n",
        "- Equipos de datos con 10+ personas\n",
        "- Modelos de ML en producción que requieren mantenimiento\n",
        "- Infraestructura de datos compleja con múltiples sistemas\n",
        "- Necesidad de optimización profunda en áreas específicas\n",
        "- Problemas recurrentes que consumen mucho tiempo del equipo\n",
        "\n",
        "**Empresas pequeñas (5-20 personas):** Los tres roles básicos suelen ser suficientes\n",
        "\n",
        "**Empresas medianas (20-100):** Empiezan a aparecer 1-2 roles especializados\n",
        "\n",
        "**Empresas grandes (100+ en datos):** Equipos completos especializados\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Machine Learning Engineer (Ingeniero de ML)\n",
        "\n",
        "### Definición y responsabilidades\n",
        "\n",
        "El **ML Engineer** es el puente entre Data Scientists y Data Engineers. Su misión es **llevar modelos de machine learning desde notebooks experimentales hasta sistemas de producción robustos, escalables y monitorizados**.\n",
        "\n",
        "**Diferencia clave con Data Scientist:**\n",
        "- **Data Scientist:** Diseña y entrena el modelo, valida su precisión\n",
        "- **ML Engineer:** Optimiza, implementa y mantiene el modelo en producción\n",
        "\n",
        "**Responsabilidades principales:**\n",
        "- Traducir prototipos de notebooks a código productivo\n",
        "- Optimizar modelos para latencia y throughput\n",
        "- Diseñar arquitecturas de serving (batch vs real-time)\n",
        "- Implementar feature engineering pipelines escalables\n",
        "- Monitorizar performance de modelos en producción\n",
        "- Gestionar versionado de modelos y experimentos\n",
        "- Reentrenar modelos cuando degradan\n",
        "\n",
        "### Perfil típico\n",
        "\n",
        "**Formación:** Ingeniería Informática + conocimientos de ML, o Matemáticas/Física + ingeniería de software\n",
        "\n",
        "**Enfoque:** Ingeniería de software aplicada a ML. \"¿Cómo hacemos que este modelo funcione en producción a escala?\"\n",
        "\n",
        "**Habilidades clave:**\n",
        "- Programación avanzada (Python, Java, C++)\n",
        "- ML frameworks (TensorFlow, PyTorch, Scikit-learn)\n",
        "- Ingeniería de software (testing, CI/CD, versionado)\n",
        "- Sistemas distribuidos y escalabilidad\n",
        "- Cloud platforms (AWS SageMaker, GCP Vertex AI, Azure ML)\n",
        "- Optimización de performance (GPU, cuantización, pruning)\n",
        "\n",
        "### Herramientas principales\n",
        "\n",
        "| Categoría | Herramientas |\n",
        "|-----------|-------------|\n",
        "| Frameworks ML | TensorFlow, PyTorch, Scikit-learn, XGBoost |\n",
        "| Serving | TensorFlow Serving, TorchServe, FastAPI, Seldon |\n",
        "| Feature Store | Feast, Tecton, Hopsworks |\n",
        "| Experiment tracking | MLflow, Weights & Biases, Neptune |\n",
        "| Orquestación | Kubeflow, Airflow, Metaflow |\n",
        "| Monitorización | Prometheus, Grafana, Evidently AI |\n",
        "\n",
        "### Día típico de un ML Engineer\n",
        "\n",
        "**9:00-10:30** - Investigar degradación del modelo de recomendaciones (accuracy bajó 3%)  \n",
        "**10:30-12:00** - Optimizar latencia de inferencia de 200ms a <50ms usando quantización INT8  \n",
        "**12:00-13:00** - Code review de nuevo pipeline de features de un Data Scientist  \n",
        "**13:00-14:00** - Comida  \n",
        "**14:00-16:00** - Implementar A/B test para nuevo modelo de ranking en producción  \n",
        "**16:00-17:00** - Reunión con Infrastructure team sobre migrar a GPUs A100  \n",
        "**17:00-18:00** - Documentar proceso de reentrenamiento automático semanal\n",
        "\n",
        "### Ejemplo real: ML Engineer en Spotify\n",
        "\n",
        "**Desafío:** El modelo de recomendación de Discover Weekly (50+ millones de usuarios) tarda 12 horas en generar playlists semanales. Necesitan reducirlo a <2 horas.\n",
        "\n",
        "**Solución implementada:**\n",
        "1. **Análisis de bottlenecks:** Identificar que el 70% del tiempo es feature computation\n",
        "2. **Optimización:**\n",
        "   - Precomputar embeddings de canciones (de calcular 60M cada semana a incremental)\n",
        "   - Migrar de CPU a GPU para cálculo de similitudes\n",
        "   - Implementar caching inteligente de features de usuarios activos\n",
        "3. **Arquitectura distribuida:** Spark para paralelizar generación de playlists\n",
        "4. **Infraestructura:** Kubernetes con auto-scaling basado en carga\n",
        "5. **Monitorización:** Dashboards de latencia por etapa, alertas si >3 horas\n",
        "\n",
        "**Resultado:**\n",
        "- Tiempo de generación: 12h → 1.5h (8x más rápido)\n",
        "- Coste computacional: Reducción del 40% gracias a optimizaciones\n",
        "- Posibilidad de actualizar recomendaciones más frecuentemente\n",
        "\n",
        "### El desafío del \"research to production gap\"\n",
        "\n",
        "**Problema común:**\n",
        "\n",
        "```python\n",
        "# Código del Data Scientist (notebook)\n",
        "model = RandomForestClassifier(n_estimators=1000)\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "```\n",
        "\n",
        "**Lo que debe hacer el ML Engineer:**\n",
        "- ¿Cómo obtenemos X en producción? → Feature pipeline\n",
        "- ¿Dónde guardamos el modelo? → Model registry\n",
        "- ¿Cómo servimos predicciones? → API con latencia <100ms\n",
        "- ¿Cómo monitorizamos degradación? → Data drift detection\n",
        "- ¿Cómo versionamos? → MLflow + Git\n",
        "- ¿Cómo reentrenamos? → Automatización semanal\n",
        "- ¿Cómo rollback si falla? → Blue-green deployment\n",
        "\n",
        "### Casos de uso por tipo de serving\n",
        "\n",
        "**Batch predictions (offline):**\n",
        "- Recomendaciones de email semanales\n",
        "- Scoring de leads para ventas\n",
        "- Detección de fraude en transacciones históricas\n",
        "- **Tecnología:** Spark, Airflow, S3\n",
        "\n",
        "**Real-time predictions (online):**\n",
        "- Detección de fraude en pago con tarjeta\n",
        "- Recomendaciones de productos al navegar\n",
        "- Traducción automática en tiempo real\n",
        "- **Tecnología:** FastAPI, Redis, Kubernetes\n",
        "\n",
        "**Streaming predictions:**\n",
        "- Moderación de contenido en vivo\n",
        "- Trading algorítmico\n",
        "- Detección de anomalías en IoT\n",
        "- **Tecnología:** Kafka, Flink, TensorFlow Serving\n",
        "\n",
        "---\n",
        "\n",
        "## 3. MLOps Engineer\n",
        "\n",
        "### Definición y responsabilidades\n",
        "\n",
        "El **MLOps Engineer** (Machine Learning Operations) aplica principios de DevOps al ciclo de vida de modelos de ML. Su misión es **automatizar, estandarizar y hacer confiable todo el proceso de ML: desde experimentación hasta producción**.\n",
        "\n",
        "**MLOps = ML + DevOps + DataOps**\n",
        "\n",
        "**Responsabilidades principales:**\n",
        "- Diseñar e implementar pipelines CI/CD para modelos ML\n",
        "- Automatizar entrenamiento, validación y despliegue de modelos\n",
        "- Implementar monitorización de modelos (data drift, concept drift)\n",
        "- Gestionar infraestructura de ML (GPU clusters, feature stores)\n",
        "- Establecer prácticas de gobernanza y reproducibilidad\n",
        "- Optimizar costes de infraestructura ML\n",
        "- Implementar estrategias de rollback y canary deployments\n",
        "\n",
        "### Diferencia clave: ML Engineer vs MLOps Engineer\n",
        "\n",
        "| Aspecto | ML Engineer | MLOps Engineer |\n",
        "|---------|-------------|----------------|\n",
        "| **Foco principal** | Modelos individuales | Sistemas y procesos |\n",
        "| **Output** | Modelo en producción | Plataforma de MLOps |\n",
        "| **Escala** | 5-10 modelos | 50-500 modelos |\n",
        "| **Prioridad** | Performance del modelo | Confiabilidad del sistema |\n",
        "| **Herramientas** | TensorFlow, PyTorch | Kubernetes, Terraform, CI/CD |\n",
        "| **Stakeholder** | Data Scientists | Todo el equipo de ML |\n",
        "\n",
        "**En la práctica:** En empresas pequeñas/medianas, el ML Engineer hace también MLOps. Solo empresas grandes con decenas de modelos necesitan MLOps dedicado.\n",
        "\n",
        "### Perfil típico\n",
        "\n",
        "**Formación:** Ingeniería Informática con experiencia en DevOps + conocimientos de ML\n",
        "\n",
        "**Enfoque:** Infraestructura y automatización. \"¿Cómo hacemos que 100 modelos funcionen sin intervención manual?\"\n",
        "\n",
        "**Habilidades clave:**\n",
        "- DevOps y SRE (Site Reliability Engineering)\n",
        "- Kubernetes, Docker, Terraform\n",
        "- CI/CD (Jenkins, GitLab CI, GitHub Actions)\n",
        "- Cloud platforms (infraestructura como código)\n",
        "- Monitorización y observabilidad\n",
        "- Conocimientos de ML (sin necesidad de entrenar modelos)\n",
        "\n",
        "### Herramientas principales\n",
        "\n",
        "| Categoría | Herramientas |\n",
        "|-----------|-------------|\n",
        "| Orquestación ML | Kubeflow, MLflow, Airflow |\n",
        "| CI/CD | GitHub Actions, GitLab CI, Jenkins |\n",
        "| Contenedores | Docker, Kubernetes, Helm |\n",
        "| IaC | Terraform, Pulumi, CloudFormation |\n",
        "| Monitorización | Prometheus, Grafana, Evidently, Arize |\n",
        "| Feature Store | Feast, Tecton |\n",
        "| Model Registry | MLflow, DVC, Weights & Biases |\n",
        "\n",
        "### Día típico de un MLOps Engineer\n",
        "\n",
        "**9:00-10:00** - Investigar alerta: modelo de detección de spam degradó 5% overnight  \n",
        "**10:00-12:00** - Implementar sistema de monitoreo de data drift con Evidently AI  \n",
        "**12:00-13:00** - Reunión con Data Scientists: diseñar flujo para nuevos experimentos  \n",
        "**13:00-14:00** - Comida  \n",
        "**14:00-16:00** - Automatizar reentrenamiento de 15 modelos con validación automática  \n",
        "**16:00-17:00** - Optimizar costes de GPU: identificar modelos que pueden usar CPU  \n",
        "**17:00-18:00** - Documentar procedimiento de rollback para modelos críticos\n",
        "\n",
        "### Ejemplo real: MLOps en Uber\n",
        "\n",
        "**Contexto:** Uber tiene 1000+ modelos de ML en producción (estimación de tiempo de llegada, pricing dinámico, matching conductor-pasajero, detección de fraude, etc.)\n",
        "\n",
        "**Desafío:** Originalmente cada equipo desplegaba modelos a su manera:\n",
        "- 15 tecnologías diferentes de serving\n",
        "- Sin estándares de monitorización\n",
        "- Reentrenamientos manuales\n",
        "- Incidentes frecuentes por modelos desactualizados\n",
        "- Imposible escalar la operación\n",
        "\n",
        "**Solución: Plataforma Michelangelo (MLOps platform interna)**\n",
        "\n",
        "1. **Estandarización:**\n",
        "   - Un solo formato de features (Feature Store)\n",
        "   - API unificada de entrenamiento\n",
        "   - Serving estandarizado (batch y real-time)\n",
        "\n",
        "2. **Automatización:**\n",
        "   - Entrenamiento automático con nuevos datos\n",
        "   - Validación automática pre-despliegue\n",
        "   - Rollback automático si métricas degradan\n",
        "\n",
        "3. **Monitorización:**\n",
        "   - Dashboard unificado de todos los modelos\n",
        "   - Alertas de data drift, prediction drift\n",
        "   - Tracking de performance vs ground truth\n",
        "\n",
        "4. **Gobernanza:**\n",
        "   - Versionado completo (datos + código + modelo)\n",
        "   - Auditoría de todas las predicciones\n",
        "   - A/B testing integrado\n",
        "\n",
        "**Resultado:**\n",
        "- Tiempo de despliegue: 4 semanas → 2 días\n",
        "- Incidentes por modelos: -70%\n",
        "- Número de modelos: 50 → 1000+ (escalabilidad)\n",
        "- Data Scientists pueden iterar 10x más rápido\n",
        "\n",
        "### Los tres pilares de MLOps\n",
        "\n",
        "**1. Automatización (CI/CD para ML):**\n",
        "```\n",
        "Código nuevo → Tests automáticos → Entrenamiento → Validación → Deploy automático\n",
        "```\n",
        "\n",
        "**2. Monitorización continua:**\n",
        "- Input data distribution (data drift)\n",
        "- Prediction distribution (concept drift)\n",
        "- Model performance (accuracy, latency)\n",
        "- Infrastructure health (CPU, memoria, errores)\n",
        "\n",
        "**3. Reproducibilidad:**\n",
        "- Versionado de código (Git)\n",
        "- Versionado de datos (DVC, Delta Lake)\n",
        "- Versionado de modelos (MLflow)\n",
        "- Versionado de infraestructura (Terraform)\n",
        "\n",
        "### Niveles de madurez MLOps\n",
        "\n",
        "**Nivel 0 - Manual:** Todo manual, notebooks en laptops, sin versionado\n",
        "\n",
        "**Nivel 1 - Automatización parcial:** Entrenamiento automático, deploy manual\n",
        "\n",
        "**Nivel 2 - CI/CD básico:** Deploy automático con tests, monitoreo básico\n",
        "\n",
        "**Nivel 3 - Full MLOps:** Reentrenamiento automático, monitoreo avanzado, rollback automático\n",
        "\n",
        "**Nivel 4 - Self-healing:** Sistema detecta y corrige problemas automáticamente\n",
        "\n",
        "La mayoría de empresas están en Nivel 1-2. FAANG y unicorns tech en Nivel 3-4.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Data Architect (Arquitecto de Datos)\n",
        "\n",
        "### Definición y responsabilidades\n",
        "\n",
        "El **Data Architect** es el diseñador de la arquitectura global de datos de la organización. Su misión es **definir cómo se estructuran, almacenan, integran y gobiernan los datos** para cumplir objetivos técnicos y de negocio.\n",
        "\n",
        "**Analogía:** Si Data Engineers son constructores, el Data Architect es el arquitecto que diseña los planos del edificio.\n",
        "\n",
        "**Responsabilidades principales:**\n",
        "- Diseñar la arquitectura de datos end-to-end\n",
        "- Seleccionar tecnologías y herramientas del stack\n",
        "- Definir modelos de datos y esquemas\n",
        "- Establecer estándares y patrones arquitectónicos\n",
        "- Planificar escalabilidad a largo plazo\n",
        "- Implementar gobernanza y seguridad de datos\n",
        "- Diseñar estrategias de integración entre sistemas\n",
        "- Liderar migraciones de arquitectura (ej: on-premise → cloud)\n",
        "\n",
        "### Perfil típico\n",
        "\n",
        "**Formación:** Ingeniería Informática + años de experiencia como Data Engineer\n",
        "\n",
        "**Enfoque:** Visión holística y largo plazo. \"¿Cómo diseñamos un sistema que soporte 10x crecimiento en 3 años?\"\n",
        "\n",
        "**Seniority:** Típicamente rol senior (7-15+ años de experiencia)\n",
        "\n",
        "**Habilidades clave:**\n",
        "- Diseño de arquitecturas distribuidas\n",
        "- Profundo conocimiento de bases de datos (SQL y NoSQL)\n",
        "- Data modeling y normalización\n",
        "- Data warehousing (Kimball, Inmon)\n",
        "- Arquitecturas modernas (Data Lake, Lakehouse, Data Mesh)\n",
        "- Cloud platforms (multi-cloud en muchos casos)\n",
        "- Gobernanza y compliance (GDPR, SOC2)\n",
        "- Soft skills: comunicación con C-level, liderazgo técnico\n",
        "\n",
        "### Herramientas y tecnologías\n",
        "\n",
        "| Categoría | Conocimiento requerido |\n",
        "|-----------|------------------------|\n",
        "| Bases de datos | PostgreSQL, MySQL, MongoDB, Cassandra, DynamoDB |\n",
        "| Data Warehouses | Snowflake, BigQuery, Redshift, Databricks |\n",
        "| Procesamiento | Spark, Flink, dbt, Dataflow |\n",
        "| Orquestación | Airflow, Prefect, Dagster |\n",
        "| Streaming | Kafka, Kinesis, Pub/Sub |\n",
        "| Gobernanza | Alation, Collibra, Apache Atlas |\n",
        "| Modelado | ER/Studio, Lucidchart, diagrams.net |\n",
        "| IaC | Terraform, Pulumi |\n",
        "\n",
        "### Día típico de un Data Architect\n",
        "\n",
        "**9:00-11:00** - Revisar propuesta de arquitectura para nuevo data product del equipo de marketing  \n",
        "**11:00-12:00** - Reunión con CTO: presentar estrategia de migración de on-premise a cloud (3 años)  \n",
        "**12:00-13:00** - Evaluar vendors para nueva herramienta de data catalog  \n",
        "**13:00-14:00** - Comida  \n",
        "**14:00-15:30** - Sesión de diseño: arquitectura de streaming para eventos de IoT (1M eventos/segundo)  \n",
        "**15:30-17:00** - Code review de alto nivel de diseño de nuevos pipelines  \n",
        "**17:00-18:00** - Documentar patrones arquitectónicos para el equipo de Data Engineering\n",
        "\n",
        "### Ejemplo real: Data Architect en Netflix\n",
        "\n",
        "**Contexto 2016:** Netflix procesaba datos en múltiples sistemas aislados:\n",
        "- Data warehouse on-premise (Teradata)\n",
        "- Data lake en AWS S3\n",
        "- Bases de datos operacionales (MySQL, Cassandra)\n",
        "- Sin integración clara entre ellos\n",
        "- Equipos duplicando esfuerzos\n",
        "\n",
        "**Desafío arquitectónico:** Unificar la arquitectura de datos para soportar:\n",
        "- 200+ millones de suscriptores (de 50M)\n",
        "- Procesamiento en tiempo real\n",
        "- Análisis ad-hoc por cientificos\n",
        "- Compliance con regulaciones globales\n",
        "- Reducción de costes operativos\n",
        "\n",
        "**Solución: Arquitectura Data Lakehouse**\n",
        "\n",
        "```\n",
        "Ingesta                Processing              Serving\n",
        "───────              ──────────            ─────────────\n",
        "Kafka      →    Spark/Flink      →    Data Lakehouse\n",
        "Firehose   →    dbt              →    (S3 + Iceberg)\n",
        "APIs       →    Airflow          →         ↓\n",
        "                                       ┌────┴────┐\n",
        "                                    Presto  Redshift\n",
        "                                       ↓         ↓\n",
        "                                   Analysts  Dashboards\n",
        "```\n",
        "\n",
        "**Decisiones clave del arquitecto:**\n",
        "\n",
        "1. **Formato de almacenamiento:** Apache Iceberg\n",
        "   - Permite modificaciones ACID en data lake\n",
        "   - Integración con Spark, Presto, Flink\n",
        "   - Time-travel para debugging\n",
        "\n",
        "2. **Processing:** Separación batch vs streaming\n",
        "   - Batch: Spark para agregaciones complejas\n",
        "   - Streaming: Flink para alertas en tiempo real\n",
        "   - dbt para transformaciones SQL\n",
        "\n",
        "3. **Gobernanza:** Implementar data mesh\n",
        "   - Domains dueños de sus datos\n",
        "   - Estándares centralizados, ejecución descentralizada\n",
        "   - Data contracts entre equipos\n",
        "\n",
        "4. **Seguridad:**\n",
        "   - Encriptación end-to-end\n",
        "   - Row-level security por región geográfica\n",
        "   - Auditoría completa de accesos\n",
        "\n",
        "**Resultado:**\n",
        "- Tiempo de consultas: Reducción 60%\n",
        "- Costes de almacenamiento: -40% con estrategia hot/cold\n",
        "- Time-to-market para nuevos casos de uso: 4 meses → 2 semanas\n",
        "- Cumplimiento GDPR/compliance automatizado\n",
        "\n",
        "### Patrones arquitectónicos que un Data Architect debe dominar\n",
        "\n",
        "**1. Lambda Architecture:**\n",
        "- Batch layer + Speed layer + Serving layer\n",
        "- Para casos que requieren datos históricos + tiempo real\n",
        "- **Desventaja:** Complejidad de mantener dos paths\n",
        "\n",
        "**2. Kappa Architecture:**\n",
        "- Solo streaming, sin batch\n",
        "- Reprocessing via replay de eventos\n",
        "- **Ventaja:** Simplicidad, una sola codebase\n",
        "\n",
        "**3. Data Mesh:**\n",
        "- Descentralización de ownership\n",
        "- Data as a product\n",
        "- Self-serve infrastructure\n",
        "- **Cuándo:** Organizaciones grandes con múltiples dominios\n",
        "\n",
        "**4. Medallion Architecture (Lakehouse):**\n",
        "- Bronze: datos raw\n",
        "- Silver: datos limpios y estructurados\n",
        "- Gold: datos agregados listos para negocio\n",
        "- **Ventaja:** Clara separación de responsabilidades\n",
        "\n",
        "**5. Event-Driven Architecture:**\n",
        "- Eventos como fuente de verdad\n",
        "- Desacoplamiento de sistemas\n",
        "- **Cuándo:** Sistemas con muchas integraciones\n",
        "\n",
        "### Data Architect vs otros roles arquitectónicos\n",
        "\n",
        "| Rol | Responsabilidad | Ejemplo de decisión |\n",
        "|-----|----------------|---------------------|\n",
        "| **Data Architect** | Arquitectura de datos | \"Usaremos Data Lakehouse con Iceberg\" |\n",
        "| **Solution Architect** | Soluciones completas | \"Sistema de e-commerce con microservicios\" |\n",
        "| **Cloud Architect** | Infraestructura cloud | \"Multi-region active-active en AWS\" |\n",
        "| **Enterprise Architect** | Estrategia IT global | \"Migración cloud en 5 años, cloud-first\" |\n",
        "\n",
        "En muchas organizaciones, Data Architect reporta al CTO o CDO (Chief Data Officer).\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Otros roles especializados emergentes\n",
        "\n",
        "### Analytics Engineer\n",
        "\n",
        "**Qué hace:** Puente entre Data Engineer y Data Analyst. Escribe transformaciones SQL en dbt para preparar datos para analistas.\n",
        "\n",
        "**Herramientas:** dbt, SQL, Git, Looker\n",
        "\n",
        "**Cuándo aparece:** Cuando analistas necesitan datos más refinados pero engineers están saturados\n",
        "\n",
        "**Ejemplo:** Transformar tablas raw en métricas de negocio (MRR, CAC, LTV) en dbt\n",
        "\n",
        "### Data Platform Engineer\n",
        "\n",
        "**Qué hace:** Construye y mantiene la plataforma interna de datos (self-serve) para que otros equipos sean autónomos.\n",
        "\n",
        "**Diferencia con Data Engineer:** Construye herramientas para otros data engineers, no pipelines de datos\n",
        "\n",
        "**Ejemplo:** Desarrollar UI interna para que analistas creen pipelines sin código\n",
        "\n",
        "### BI Engineer\n",
        "\n",
        "**Qué hace:** Especialista en herramientas de Business Intelligence. Construye y optimiza dashboards, reportes, y semántica de datos.\n",
        "\n",
        "**Herramientas:** Tableau, Power BI, Looker, Semantic layers\n",
        "\n",
        "**Cuándo aparece:** Cuando la organización tiene 100+ dashboards complejos\n",
        "\n",
        "### Data Quality Engineer\n",
        "\n",
        "**Qué hace:** Implementa sistemas automatizados de validación y monitorización de calidad de datos.\n",
        "\n",
        "**Herramientas:** Great Expectations, Deequ, Monte Carlo, Soda\n",
        "\n",
        "**Cuándo aparece:** Cuando los problemas de calidad de datos generan incidentes frecuentes\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Comparación de roles especializados\n",
        "\n",
        "### Tabla comparativa\n",
        "\n",
        "| Aspecto | ML Engineer | MLOps Engineer | Data Architect |\n",
        "|---------|-------------|----------------|----------------|\n",
        "| **Seniority típico** | Mid-Senior (3-7 años) | Senior (5-10 años) | Senior-Staff (7-15 años) |\n",
        "| **Enfoque** | Modelos en producción | Plataforma de ML | Arquitectura global |\n",
        "| **Stakeholder principal** | Data Scientists | Todo equipo de ML | CTO, toda la org |\n",
        "| **Output clave** | Modelo serving | Pipeline CI/CD | Documento de arquitectura |\n",
        "| **Programación** | 80% (Python) | 70% (Python/Go/infra) | 30% (principalmente diseño) |\n",
        "| **Herramienta #1** | PyTorch/TensorFlow | Kubernetes | Lucidchart + experiencia |\n",
        "| **Decisiones típicas** | Batch vs real-time | Herramienta de MLOps | Stack tecnológico completo |\n",
        "| **Horizonte temporal** | Semanas-meses | Meses | Trimestres-años |\n",
        "| **Empresas que lo necesitan** | Con ML en producción | Con 10+ modelos | Todas >50 personas datos |\n",
        "\n",
        "### Roadmap de especialización\n",
        "\n",
        "```\n",
        "Data Engineer (2-3 años)\n",
        "    ↓\n",
        "    ├─→ ML Engineer (interés en ML)\n",
        "    │       ↓\n",
        "    │   MLOps Engineer (muchos modelos)\n",
        "    │\n",
        "    ├─→ Analytics Engineer (interés en análisis)\n",
        "    │\n",
        "    └─→ Data Architect (visión estratégica + senior)\n",
        "            ↓\n",
        "        Principal Engineer / VP Engineering\n",
        "```\n",
        "\n",
        "### ¿Cuándo contratar cada rol?\n",
        "\n",
        "**ML Engineer:**\n",
        "- ✅ Tienes Data Scientists pero modelos no llegan a producción\n",
        "- ✅ Modelos tardan meses en desplegarse\n",
        "- ✅ Performance de modelos en producción es problema\n",
        "\n",
        "**MLOps Engineer:**\n",
        "- ✅ Tienes 10+ modelos en producción\n",
        "- ✅ Incidentes frecuentes por modelos desactualizados\n",
        "- ✅ Cada deploy es manual y arriesgado\n",
        "- ✅ No hay visibilidad de cómo funcionan los modelos\n",
        "\n",
        "**Data Architect:**\n",
        "- ✅ Equipo de datos >20 personas\n",
        "- ✅ Sistemas de datos fragmentados e inconsistentes\n",
        "- ✅ Necesitas planificar crecimiento 10x en 2-3 años\n",
        "- ✅ Migraciones grandes (cloud, nuevo stack)\n",
        "- ✅ Problemas recurrentes de escalabilidad\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Salarios y demanda del mercado (España, 2025)\n",
        "\n",
        "| Rol | Junior | Mid | Senior | Staff/Principal |\n",
        "|-----|--------|-----|--------|-----------------|\n",
        "| ML Engineer | 40-50K € | 55-75K € | 75-100K € | 100-130K € |\n",
        "| MLOps Engineer | - | 60-80K € | 80-110K € | 110-140K € |\n",
        "| Data Architect | - | - | 70-100K € | 100-150K € |\n",
        "| Analytics Engineer | 35-45K € | 50-65K € | 65-85K € | - |\n",
        "\n",
        "**Nota:** Estos roles son más demandados y mejor pagados que roles generalistas debido a la escasez de talento especializado.\n",
        "\n",
        "### Tendencias de demanda (LinkedIn 2025)\n",
        "\n",
        "**🔥 Muy alta demanda:**\n",
        "- MLOps Engineer (crecimiento 300% en 3 años)\n",
        "- ML Engineer (crecimiento 200%)\n",
        "- Analytics Engineer (rol emergente)\n",
        "\n",
        "**Alta demanda:**\n",
        "- Data Architect (siempre necesario en empresas grandes)\n",
        "\n",
        "**Sector que más contrata estos roles:**\n",
        "1. Fintech y banca (ML para fraude, risk)\n",
        "2. E-commerce y retail (recomendaciones)\n",
        "3. Healthtech (diagnóstico, drug discovery)\n",
        "4. Adtech (bidding optimization)\n",
        "5. Automoción (vehículos autónomos)\n",
        "\n",
        "---\n",
        "\n",
        "## 8. Caso integrado: Equipo de ML en Airbnb\n",
        "\n",
        "**Estructura del equipo de ML (simplificada):**\n",
        "\n",
        "```\n",
        "VP of Machine Learning\n",
        "    │\n",
        "    ├─ Data Architect (1)\n",
        "    │   └─ Define arquitectura de Feature Store\n",
        "    │\n",
        "    ├─ Data Scientists (15)\n",
        "    │   └─ Diseñan modelos (pricing, search ranking, fraud)\n",
        "    │\n",
        "    ├─ ML Engineers (10)\n",
        "    │   └─ Implementan modelos en producción\n",
        "    │\n",
        "    ├─ MLOps Engineers (5)\n",
        "    │   └─ Mantienen plataforma de ML\n",
        "    │\n",
        "    └─ Data Engineers (8)\n",
        "        └─ Construyen pipelines de features\n",
        "```\n",
        "\n",
        "**Ejemplo: Modelo de pricing dinámico**\n",
        "\n",
        "**Data Scientist:**\n",
        "- Diseña modelo XGBoost con 200+ features\n",
        "- Valida accuracy en datos históricos (R² = 0.87)\n",
        "- Escribe notebook con prototipo\n",
        "\n",
        "**ML Engineer:**\n",
        "- Refactoriza código del notebook a módulos productivos\n",
        "- Optimiza latencia de inferencia (500ms → 50ms)\n",
        "- Implementa A/B test framework\n",
        "- Desarrolla API de serving con FastAPI\n",
        "\n",
        "**MLOps Engineer:**\n",
        "- Configura reentrenamiento automático semanal\n",
        "- Implementa monitoreo de data drift\n",
        "- Establece alertas si predicciones se desvían >10%\n",
        "- Automatiza rollback si nuevo modelo degrada métricas\n",
        "\n",
        "**Data Architect:**\n",
        "- Diseña Feature Store para reutilizar features entre modelos\n",
        "- Define estándares de versionado de modelos\n",
        "- Planifica escalabilidad para 10M predicciones/día\n",
        "\n",
        "**Resultado:** Sistema de pricing que se actualiza automáticamente, se monitoriza constantemente, y genera $200M adicionales en revenue anual.\n",
        "\n",
        "---\n",
        "\n",
        "## 9. Conceptos clave\n",
        "\n",
        "- **ML Engineer:** Lleva modelos de notebook a producción robusta y escalable\n",
        "- **MLOps Engineer:** Automatiza y estandariza el ciclo de vida completo de ML\n",
        "- **Data Architect:** Diseña la arquitectura de datos global de la organización\n",
        "- **Especialización:** Surge cuando escala y complejidad justifican profundidad experta\n",
        "- **Research-to-production gap:** Principal problema que resuelve el ML Engineer\n",
        "- **Feature Store:** Componente crítico para reutilizar features entre modelos\n",
        "- **CI/CD para ML:** Diferente de CI/CD tradicional (datos + código + modelo)\n",
        "- **Data drift:** Cambio en distribución de datos de entrada que degrada modelos\n",
        "- **Medallion architecture:** Bronze → Silver → Gold en Data Lakehouses\n",
        "- **Analytics Engineer:** Rol emergente entre Data Engineer y Data Analyst\n",
        "\n",
        "---\n",
        "\n",
        "## Resumen\n",
        "\n",
        "Los roles especializados en el ecosistema de datos surgen cuando las organizaciones alcanzan escala y complejidad suficiente donde la especialización genera más valor que la generalización.\n",
        "\n",
        "El **ML Engineer** resuelve el \"research-to-production gap\", traduciendo prototipos de Data Scientists en sistemas productivos optimizados para latencia, throughput y confiabilidad.\n",
        "\n",
        "El **MLOps Engineer** va un nivel más allá, construyendo plataformas que automatizan todo el ciclo de vida de ML (entrenamiento, validación, despliegue, monitorización) permitiendo que decenas o cientos de modelos operen sin intervención manual constante.\n",
        "\n",
        "El **Data Architect** opera en un nivel estratégico, diseñando la arquitectura de datos completa de la organización con visión de largo plazo, seleccionando tecnologías, estableciendo estándares y liderando migraciones complejas.\n",
        "\n",
        "Estos roles no reemplazan a los fundamentales (Analyst, Scientist, Engineer) sino que complementan el ecosistema cuando la organización crece. Una startup puede funcionar sin ellos; una empresa con 100+ personas en datos los necesita para mantener eficiencia, escalabilidad y calidad. Comprender estos roles especializados es esencial para planificar tu carrera en datos y para diseñar equipos efectivos en organizaciones data-driven maduras.\n",
        "\n",
        "---\n",
        "\n",
        "## Referencias\n",
        "\n",
        "### Vídeos\n",
        "- [Machine Learning Engineer vs Data Scientist](https://www.youtube.com/watch?v=example)\n",
        "- [What is MLOps? (Google Cloud)](https://www.youtube.com/watch?v=example)\n",
        "- [Data Architecture Patterns](https://www.youtube.com/watch?v=example)\n",
        "- [Inside Uber's ML Platform - Michelangelo](https://www.youtube.com/watch?v=example)\n",
        "\n",
        "### Lecturas\n",
        "- [MLOps: Continuous delivery and automation pipelines in ML - Google Cloud](https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)\n",
        "- [Scaling Machine Learning at Uber with Michelangelo](https://www.uber.com/blog/michelangelo-machine-learning-platform/)\n",
        "- [The ML Engineer Role Explained](https://www.oreilly.com/radar/what-is-a-machine-learning-engineer/)\n",
        "- [Data Mesh Principles and Logical Architecture](https://martinfowler.com/articles/data-mesh-principles.html)\n",
        "- [The Analytics Engineer - dbt Labs](https://www.getdbt.com/what-is-analytics-engineering/)\n",
        "\n",
        "### Herramientas\n",
        "- [MLflow - Open source platform for ML lifecycle](https://mlflow.org/)\n",
        "- [Kubeflow - ML toolkit for Kubernetes](https://www.kubeflow.org/)\n",
        "- [Feast - Feature Store](https://feast.dev/)\n",
        "- [Evidently AI - ML monitoring](https://www.evidentlyai.com/)"
      ],
      "metadata": {
        "id": "3_4XpEFhXtAq"
      }
    }
  ]
}