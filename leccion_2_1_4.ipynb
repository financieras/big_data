{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnQ8Qk64aqqkSwWNTBLC+0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/financieras/big_data/blob/main/leccion_2_1_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lecci√≥n 2.1.4: Relaciones entre variables (correlaci√≥n, covarianza y tablas cruzadas)\n",
        "\n",
        "## 1. El arte de conectar los puntos: Descubriendo relaciones ocultas\n",
        "\n",
        "Analizar relaciones entre variables es como ser un **detective de conexiones**: encuentras hilos invisibles que unen diferentes aspectos de tus datos. No se trata solo de n√∫meros‚Äîse trata de entender c√≥mo el movimiento en una variable afecta a otras, revelando el tejido interdependiente de tu negocio.\n",
        "\n",
        "> **Idea clave:** Las relaciones te dicen \"cuando esto cambia, qu√© m√°s cambia con ello\"‚Äîel fundamento de la predicci√≥n y la comprensi√≥n.\n",
        "\n",
        "**¬øPor qu√© estas relaciones importan?**\n",
        "- üîÆ **Predicci√≥n:** Si sabes c√≥mo se relacionan las variables, puedes predecir comportamientos\n",
        "- üéØ **Eficiencia:** Enfocar esfuerzos en las variables que m√°s impacto tienen\n",
        "- üë• **Segmentaci√≥n:** Encontrar grupos naturales basados en relaciones compartidas\n",
        "- üí° **Insights de negocio:** Descubrir palancas para intervenir\n",
        "\n",
        "**Ejemplo revelador:** Un retailer descubre que la **relaci√≥n entre tiempo en website y tasa de conversi√≥n** no es lineal‚Äîhay un punto √≥ptimo despu√©s del cual los usuarios se abruman. Esto transforma su estrategia de UX completamente.\n",
        "\n",
        "**Ejemplo de Amazon:** Descubrieron que el tiempo de entrega correlaciona fuertemente con satisfacci√≥n (r=0.72), pero el empaque bonito NO (r=0.08). **Decisi√≥n:** Invertir millones en log√≠stica, no en dise√±o de cajas.\n",
        "\n",
        "> **Advertencia cr√≠tica:** Correlaci√≥n ‚â† Causalidad. Siempre. Sin excepciones. El helado y los ahogamientos correlacionan (ambos suben en verano), pero el helado no causa ahogamientos.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Tipos de relaciones entre variables\n",
        "\n",
        "### **Clasificaci√≥n por tipo de variables**\n",
        "\n",
        "| Relaci√≥n | Variable 1 | Variable 2 | M√©trica principal | Visualizaci√≥n |\n",
        "|----------|-----------|-----------|-------------------|---------------|\n",
        "| **Num√©rica-Num√©rica** | Continua/Discreta | Continua/Discreta | Correlaci√≥n (Pearson) | Scatter plot |\n",
        "| **Categ√≥rica-Categ√≥rica** | Nominal/Ordinal | Nominal/Ordinal | Chi-cuadrado, Cram√©r's V | Tabla cruzada, heatmap |\n",
        "| **Num√©rica-Categ√≥rica** | Continua/Discreta | Nominal/Ordinal | ANOVA, Kruskal-Wallis | Boxplot agrupado |\n",
        "\n",
        "### **Clasificaci√≥n por direcci√≥n y fuerza**\n",
        "\n",
        "| Tipo | Descripci√≥n | Ejemplo | Coeficiente |\n",
        "|------|-------------|---------|-------------|\n",
        "| **Positiva fuerte** | Ambas aumentan juntas | Altura vs peso | r > 0.7 |\n",
        "| **Negativa fuerte** | Una sube, otra baja | Precio vs demanda | r < -0.7 |\n",
        "| **Nula** | No hay relaci√≥n | N√∫mero de zapato vs CI | r ‚âà 0 |\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Correlaci√≥n: La danza sincronizada de las variables\n",
        "\n",
        "### **Interpretaci√≥n detallada de coeficientes**\n",
        "\n",
        "| Valor | Fuerza | Direcci√≥n | Interpretaci√≥n pr√°ctica |\n",
        "|-------|--------|-----------|------------------------|\n",
        "| **0.9 a 1.0** | Muy fuerte | Positiva | \"Casi perfectamente sincronizadas\" |\n",
        "| **0.7 a 0.9** | Fuerte | Positiva | \"Fuertemente relacionadas\" |\n",
        "| **0.5 a 0.7** | Moderada | Positiva | \"Relaci√≥n noticeable\" |\n",
        "| **0.3 a 0.5** | D√©bil | Positiva | \"Relaci√≥n leve\" |\n",
        "| **0.0 a 0.3** | Muy d√©bil | Positiva | \"Pr√°cticamente no relacionadas\" |\n",
        "| **-0.3 a 0.0** | Muy d√©bil | Negativa | \"Pr√°cticamente no relacionadas\" |\n",
        "| **-0.5 a -0.3** | D√©bil | Negativa | \"Relaci√≥n leve inversa\" |\n",
        "| **-0.7 a -0.5** | Moderada | Negativa | \"Relaci√≥n inversa noticeable\" |\n",
        "| **-0.9 a -0.7** | Fuerte | Negativa | \"Fuertemente inversas\" |\n",
        "| **-1.0 a -0.9** | Muy fuerte | Negativa | \"Casi perfectamente opuestas\" |\n",
        "\n",
        "### **Matriz de correlaci√≥n completa**\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "def matriz_correlacion_completa(df):\n",
        "    \"\"\"Calcula y visualiza correlaciones entre todas las variables num√©ricas\"\"\"\n",
        "    # Seleccionar solo columnas num√©ricas\n",
        "    numeric_df = df.select_dtypes(include=[np.number])\n",
        "    \n",
        "    # Matriz de correlaci√≥n\n",
        "    corr_matrix = numeric_df.corr()\n",
        "    \n",
        "    # Visualizaci√≥n con heatmap (solo tri√°ngulo inferior)\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))  # M√°scara para tri√°ngulo superior\n",
        "    sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='coolwarm',\n",
        "                center=0, square=True, fmt='.2f',\n",
        "                linewidths=1, cbar_kws={\"shrink\": .8})\n",
        "    plt.title('Matriz de Correlaci√≥n (Tri√°ngulo Inferior)')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return corr_matrix\n",
        "\n",
        "# Uso\n",
        "correlaciones = matriz_correlacion_completa(df)\n",
        "```\n",
        "\n",
        "### **An√°lisis de correlaci√≥n pareada completo**\n",
        "\n",
        "```python\n",
        "def analizar_correlacion_pareada(df, var1, var2, alpha=0.05):\n",
        "    \"\"\"An√°lisis detallado de correlaci√≥n entre dos variables\"\"\"\n",
        "    # Limpiar datos\n",
        "    data_clean = df[[var1, var2]].dropna()\n",
        "    x = data_clean[var1]\n",
        "    y = data_clean[var2]\n",
        "    \n",
        "    # Correlaci√≥n de Pearson\n",
        "    corr_pearson, p_value_pearson = stats.pearsonr(x, y)\n",
        "    \n",
        "    # Correlaci√≥n de Spearman (robusta a outliers)\n",
        "    corr_spearman, p_value_spearman = stats.spearmanr(x, y)\n",
        "    \n",
        "    # Correlaci√≥n de Kendall (para muestras peque√±as)\n",
        "    corr_kendall, p_value_kendall = stats.kendalltau(x, y)\n",
        "    \n",
        "    # Resultados\n",
        "    print(f\"\\n=== AN√ÅLISIS DE CORRELACI√ìN: {var1} vs {var2} ===\")\n",
        "    print(f\"Pearson:  r = {corr_pearson:.3f}, p-value = {p_value_pearson:.4f}\")\n",
        "    print(f\"Spearman: œÅ = {corr_spearman:.3f}, p-value = {p_value_spearman:.4f}\")\n",
        "    print(f\"Kendall:  œÑ = {corr_kendall:.3f}, p-value = {p_value_kendall:.4f}\")\n",
        "    \n",
        "    # Interpretaci√≥n de significancia\n",
        "    if p_value_pearson < alpha:\n",
        "        print(f\"\\n‚úÖ La correlaci√≥n es SIGNIFICATIVA (Œ± = {alpha})\")\n",
        "    else:\n",
        "        print(f\"\\n‚ùå La correlaci√≥n NO es significativa (Œ± = {alpha})\")\n",
        "    \n",
        "    # Interpretaci√≥n de fuerza\n",
        "    if abs(corr_pearson) >= 0.7:\n",
        "        fuerza = \"fuerte\"\n",
        "    elif abs(corr_pearson) >= 0.5:\n",
        "        fuerza = \"moderada\"\n",
        "    elif abs(corr_pearson) >= 0.3:\n",
        "        fuerza = \"d√©bil\"\n",
        "    else:\n",
        "        fuerza = \"muy d√©bil\"\n",
        "    print(f\"Fuerza de la relaci√≥n: {fuerza}\")\n",
        "    \n",
        "    # Visualizaci√≥n\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # Scatter plot con regresi√≥n\n",
        "    axes[0].scatter(x, y, alpha=0.6, s=50)\n",
        "    z = np.polyfit(x, y, 1)\n",
        "    p = np.poly1d(z)\n",
        "    axes[0].plot(x, p(x), \"r--\", alpha=0.8, linewidth=2)\n",
        "    axes[0].set_xlabel(var1)\n",
        "    axes[0].set_ylabel(var2)\n",
        "    axes[0].set_title(f'Scatter Plot\\nPearson r = {corr_pearson:.3f}')\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Jointplot simplificado (distribuciones marginales)\n",
        "    axes[1].scatter(x, y, alpha=0.6, s=50)\n",
        "    axes[1].set_xlabel(var1)\n",
        "    axes[1].set_ylabel(var2)\n",
        "    axes[1].set_title(f'p-value = {p_value_pearson:.4f}')\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return {\n",
        "        'pearson': {'r': corr_pearson, 'p_value': p_value_pearson},\n",
        "        'spearman': {'rho': corr_spearman, 'p_value': p_value_spearman},\n",
        "        'kendall': {'tau': corr_kendall, 'p_value': p_value_kendall}\n",
        "    }\n",
        "\n",
        "# Uso pr√°ctico\n",
        "resultado = analizar_correlacion_pareada(df, 'precio', 'ventas')\n",
        "```\n",
        "\n",
        "**Cu√°ndo usar cada m√©todo:**\n",
        "- **Pearson:** Relaci√≥n lineal, datos normales, sin outliers\n",
        "- **Spearman:** Relaci√≥n mon√≥tona (no necesariamente lineal), datos ordinales, con outliers\n",
        "- **Kendall:** Muestras peque√±as (n<50), muchos empates, interpretaci√≥n m√°s intuitiva\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Covarianza: Hermana de la correlaci√≥n\n",
        "\n",
        "### **Diferencia entre covarianza y correlaci√≥n**\n",
        "\n",
        "```python\n",
        "def comparar_covarianza_correlacion(df, var1, var2):\n",
        "    \"\"\"Muestra la diferencia entre covarianza y correlaci√≥n\"\"\"\n",
        "    # Datos limpios\n",
        "    data_clean = df[[var1, var2]].dropna()\n",
        "    x = data_clean[var1]\n",
        "    y = data_clean[var2]\n",
        "    \n",
        "    # C√°lculos\n",
        "    covarianza = np.cov(x, y)[0, 1]\n",
        "    correlacion = np.corrcoef(x, y)[0, 1]\n",
        "    \n",
        "    print(f\"\\n=== COVARIANZA vs CORRELACI√ìN ===\")\n",
        "    print(f\"Covarianza: {covarianza:,.2f}\")\n",
        "    print(f\"Correlaci√≥n: {correlacion:.3f}\")\n",
        "    \n",
        "    print(f\"\\nüìä DIFERENCIAS CLAVE:\")\n",
        "    print(f\"‚Ä¢ Covarianza: Mide direcci√≥n + magnitud (depende de escalas)\")\n",
        "    print(f\"‚Ä¢ Correlaci√≥n: Mide direcci√≥n + fuerza (normalizada -1 a 1)\")\n",
        "    print(f\"‚Ä¢ Covarianza: Dif√≠cil de interpretar por s√≠ sola\")\n",
        "    print(f\"‚Ä¢ Correlaci√≥n: F√°cil de interpretar y comparar\")\n",
        "    \n",
        "    # Relaci√≥n matem√°tica\n",
        "    std_x = x.std()\n",
        "    std_y = y.std()\n",
        "    print(f\"\\nüìê RELACI√ìN MATEM√ÅTICA:\")\n",
        "    print(f\"Correlaci√≥n = Covarianza / (œÉx √ó œÉy)\")\n",
        "    print(f\"{correlacion:.3f} = {covarianza:.2f} / ({std_x:.2f} √ó {std_y:.2f})\")\n",
        "    \n",
        "    return covarianza, correlacion\n",
        "\n",
        "# Ejemplo\n",
        "cov, corr = comparar_covarianza_correlacion(df, 'precio', 'ventas')\n",
        "```\n",
        "\n",
        "| Aspecto | Covarianza | Correlaci√≥n |\n",
        "|---------|-----------|-------------|\n",
        "| **Rango** | -‚àû a +‚àû | -1 a +1 |\n",
        "| **Interpretaci√≥n** | Dif√≠cil (depende de escalas) | F√°cil (estandarizada) |\n",
        "| **Sensibilidad a escala** | S√ç (cambia con unidades) | NO (normalizada) |\n",
        "| **Uso com√∫n** | Matem√°tica interna | An√°lisis e interpretaci√≥n |\n",
        "\n",
        "> **Consejo pr√°ctico:** Usa **correlaci√≥n** para interpretar, usa **covarianza** solo si necesitas la matem√°tica cruda (ej: √°lgebra lineal, finanzas).\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Tablas cruzadas: Para variables categ√≥ricas\n",
        "\n",
        "### **An√°lisis completo de relaciones categ√≥ricas**\n",
        "\n",
        "```python\n",
        "def analizar_relaciones_categoricas(df, cat1, cat2, normalizar=False):\n",
        "    \"\"\"Crea y analiza tablas cruzadas entre variables categ√≥ricas\"\"\"\n",
        "    # Tabla cruzada b√°sica\n",
        "    tabla_cruzada = pd.crosstab(df[cat1], df[cat2])\n",
        "    \n",
        "    print(f\"\\n=== TABLA CRUZADA: {cat1} vs {cat2} ===\")\n",
        "    print(\"Frecuencias absolutas:\")\n",
        "    print(tabla_cruzada)\n",
        "    print(f\"\\nTotal de observaciones: {tabla_cruzada.sum().sum()}\")\n",
        "    \n",
        "    # Estad√≠stica Chi-cuadrado\n",
        "    chi2, p_value, dof, expected = stats.chi2_contingency(tabla_cruzada)\n",
        "    \n",
        "    print(f\"\\n=== PRUEBA CHI-CUADRADO ===\")\n",
        "    print(f\"Chi-cuadrado: {chi2:.3f}\")\n",
        "    print(f\"P-value: {p_value:.4f}\")\n",
        "    print(f\"Grados de libertad: {dof}\")\n",
        "    \n",
        "    if p_value < 0.05:\n",
        "        print(\"‚úÖ Hay una relaci√≥n SIGNIFICATIVA entre las variables\")\n",
        "    else:\n",
        "        print(\"‚ùå NO hay evidencia de relaci√≥n significativa\")\n",
        "    \n",
        "    # Cram√©r's V (fuerza de asociaci√≥n)\n",
        "    n = tabla_cruzada.sum().sum()\n",
        "    cramers_v = np.sqrt(chi2 / (n * (min(tabla_cruzada.shape) - 1)))\n",
        "    \n",
        "    if cramers_v < 0.1:\n",
        "        fuerza = \"muy d√©bil\"\n",
        "    elif cramers_v < 0.3:\n",
        "        fuerza = \"d√©bil\"\n",
        "    elif cramers_v < 0.5:\n",
        "        fuerza = \"moderada\"\n",
        "    else:\n",
        "        fuerza = \"fuerte\"\n",
        "    \n",
        "    print(f\"Cram√©r's V: {cramers_v:.3f} (asociaci√≥n {fuerza})\")\n",
        "    \n",
        "    # Tablas normalizadas\n",
        "    if normalizar:\n",
        "        print(f\"\\n=== TABLAS NORMALIZADAS ===\")\n",
        "        print(\"\\nPor filas (%):\")\n",
        "        print((pd.crosstab(df[cat1], df[cat2], normalize='index') * 100).round(1))\n",
        "        print(\"\\nPor columnas (%):\")\n",
        "        print((pd.crosstab(df[cat1], df[cat2], normalize='columns') * 100).round(1))\n",
        "    \n",
        "    # Visualizaci√≥n\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "    \n",
        "    # Heatmap de frecuencias\n",
        "    sns.heatmap(tabla_cruzada, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
        "    axes[0].set_title(f'Frecuencias Absolutas\\n(Chi¬≤ = {chi2:.1f}, p = {p_value:.4f})')\n",
        "    \n",
        "    # Barras apiladas\n",
        "    tabla_porcentaje = pd.crosstab(df[cat1], df[cat2], normalize='index') * 100\n",
        "    tabla_porcentaje.plot(kind='bar', stacked=True, ax=axes[1])\n",
        "    axes[1].set_title(f'Distribuci√≥n Porcentual por {cat1}')\n",
        "    axes[1].set_ylabel('Porcentaje')\n",
        "    axes[1].legend(title=cat2, bbox_to_anchor=(1.05, 1))\n",
        "    axes[1].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return tabla_cruzada, chi2, p_value, cramers_v\n",
        "\n",
        "# Uso: Relaci√≥n entre canal de adquisici√≥n y conversi√≥n\n",
        "tabla, chi2, p_val, cramers = analizar_relaciones_categoricas(\n",
        "    df, 'canal_adquisicion', 'convertido', normalizar=True\n",
        ")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Relaciones mixtas: Num√©rica vs Categ√≥rica\n",
        "\n",
        "### **An√°lisis con ANOVA**\n",
        "\n",
        "```python\n",
        "def analizar_relacion_mixta(df, cat_var, num_var):\n",
        "    \"\"\"Analiza relaci√≥n entre variable categ√≥rica y num√©rica\"\"\"\n",
        "    print(f\"\\n=== AN√ÅLISIS MIXTO: {cat_var} vs {num_var} ===\")\n",
        "    \n",
        "    # Estad√≠sticas por grupo\n",
        "    stats_grupos = df.groupby(cat_var)[num_var].agg([\n",
        "        'mean', 'std', 'count', 'median', 'min', 'max'\n",
        "    ])\n",
        "    print(\"\\nEstad√≠sticas por grupo:\")\n",
        "    print(stats_grupos)\n",
        "    \n",
        "    # ANOVA para significancia\n",
        "    grupos = [group[1].dropna().values for group in df.groupby(cat_var)[num_var]]\n",
        "    f_stat, p_value = stats.f_oneway(*grupos)\n",
        "    \n",
        "    print(f\"\\n=== ANOVA (One-Way) ===\")\n",
        "    print(f\"F-statistic: {f_stat:.3f}\")\n",
        "    print(f\"P-value: {p_value:.4f}\")\n",
        "    \n",
        "    if p_value < 0.05:\n",
        "        print(\"‚úÖ Las diferencias entre grupos SON significativas\")\n",
        "    else:\n",
        "        print(\"‚ùå No hay diferencias significativas entre grupos\")\n",
        "    \n",
        "    # Visualizaci√≥n\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "    \n",
        "    # Boxplot\n",
        "    df.boxplot(column=num_var, by=cat_var, ax=axes[0])\n",
        "    axes[0].set_title(f'Distribuci√≥n de {num_var} por {cat_var}\\n(F = {f_stat:.2f}, p = {p_value:.4f})')\n",
        "    axes[0].set_xlabel(cat_var)\n",
        "    axes[0].set_ylabel(num_var)\n",
        "    plt.sca(axes[0])\n",
        "    plt.xticks(rotation=45)\n",
        "    \n",
        "    # Violin plot (muestra distribuci√≥n completa)\n",
        "    sns.violinplot(data=df, x=cat_var, y=num_var, ax=axes[1])\n",
        "    axes[1].set_title(f'Violin Plot: {num_var} por {cat_var}')\n",
        "    axes[1].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return stats_grupos, f_stat, p_value\n",
        "\n",
        "# Uso: An√°lisis de tiempo de sesi√≥n por dispositivo\n",
        "stats_tiempo, f_stat, p_val = analizar_relacion_mixta(\n",
        "    df, 'dispositivo', 'tiempo_sesion'\n",
        ")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Caso pr√°ctico: E-commerce completo\n",
        "\n",
        "**Contexto:** Dataset de 100,000 sesiones de usuario con m√©tricas de comportamiento y conversi√≥n.\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "# 1. CARGAR DATOS\n",
        "df = pd.read_csv('sesiones_ecommerce.csv')\n",
        "print(f\"Dataset: {df.shape[0]} sesiones, {df.shape[1]} variables\")\n",
        "\n",
        "# 2. AN√ÅLISIS DE CORRELACIONES NUM√âRICAS\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PASO 1: CORRELACIONES ENTRE M√âTRICAS NUM√âRICAS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "metricas = ['tiempo_sesion', 'paginas_vistas', 'ratio_rebote', 'tasa_conversion']\n",
        "matriz_corr = matriz_correlacion_completa(df[metricas])\n",
        "\n",
        "# Correlaciones con variable objetivo\n",
        "correlaciones_conversion = df[metricas].corrwith(df['tasa_conversion']).sort_values(ascending=False)\n",
        "print(\"\\nCorrelaciones con CONVERSI√ìN:\")\n",
        "print(correlaciones_conversion)\n",
        "\n",
        "# 3. AN√ÅLISIS DETALLADO: Tiempo vs Conversi√≥n\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PASO 2: AN√ÅLISIS DETALLADO - Tiempo vs Conversi√≥n\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "resultado_tiempo = analizar_correlacion_pareada(\n",
        "    df, 'tiempo_sesion', 'tasa_conversion'\n",
        ")\n",
        "\n",
        "# 4. AN√ÅLISIS CATEG√ìRICO: Dispositivo vs Conversi√≥n\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PASO 3: AN√ÅLISIS CATEG√ìRICO - Dispositivo vs Conversi√≥n\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "df['dispositivo'] = df['user_agent'].apply(\n",
        "    lambda x: 'Mobile' if 'Mobile' in str(x) else 'Desktop'\n",
        ")\n",
        "tabla_disp, chi2_disp, p_disp, cramers_disp = analizar_relaciones_categoricas(\n",
        "    df, 'dispositivo', 'convertido', normalizar=True\n",
        ")\n",
        "\n",
        "# 5. AN√ÅLISIS MIXTO: Tiempo de sesi√≥n por dispositivo\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PASO 4: AN√ÅLISIS MIXTO - Tiempo por Dispositivo\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "stats_tiempo_disp, f_stat, p_val = analizar_relacion_mixta(\n",
        "    df, 'dispositivo', 'tiempo_sesion'\n",
        ")\n",
        "\n",
        "# 6. RESUMEN DE HALLAZGOS\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"HALLAZGOS CLAVE\")\n",
        "print(\"=\"*60)\n",
        "print(\"üîç Correlaci√≥n fuerte: tiempo_sesion vs paginas_vistas (r = 0.82)\")\n",
        "print(\"üì± Relaci√≥n significativa: Mobile tiene 35% menos conversi√≥n que Desktop\")\n",
        "print(\"‚è±Ô∏è  Diferencia marcada: Usuarios Desktop permanecen 2.3x m√°s tiempo\")\n",
        "print(\"üéØ Insight accionable: Mejorar experiencia Mobile podr√≠a aumentar conversiones 25%\")\n",
        "```\n",
        "\n",
        "**Resultados cuantificados del caso:**\n",
        "- **Correlaci√≥n m√°s fuerte:** tiempo_sesion vs paginas_vistas (r=0.82, p<0.001)\n",
        "- **Diferencia Mobile vs Desktop:** 35% menos conversi√≥n en Mobile (œá¬≤=450, p<0.001)\n",
        "- **Tiempo de sesi√≥n:** Desktop 2.3x mayor que Mobile (F=380, p<0.001)\n",
        "- **ROI potencial:** Mejora en Mobile = +25% conversiones = +‚Ç¨500K/a√±o\n",
        "\n",
        "---\n",
        "\n",
        "## 8. T√©cnicas avanzadas\n",
        "\n",
        "### **Matriz de correlaci√≥n con significancia**\n",
        "\n",
        "```python\n",
        "def matriz_correlacion_con_significancia(df):\n",
        "    \"\"\"Matriz de correlaci√≥n que incluye significancia estad√≠stica\"\"\"\n",
        "    numeric_df = df.select_dtypes(include=[np.number])\n",
        "    columns = numeric_df.columns\n",
        "    n = len(columns)\n",
        "    \n",
        "    # Crear matrices\n",
        "    corr_matrix = np.zeros((n, n))\n",
        "    p_value_matrix = np.zeros((n, n))\n",
        "    \n",
        "    # Calcular correlaciones y p-values\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            if i == j:\n",
        "                corr_matrix[i, j] = 1.0\n",
        "                p_value_matrix[i, j] = 0.0\n",
        "            else:\n",
        "                corr, p_value = stats.pearsonr(\n",
        "                    numeric_df.iloc[:, i],\n",
        "                    numeric_df.iloc[:, j]\n",
        "                )\n",
        "                corr_matrix[i, j] = corr\n",
        "                p_value_matrix[i, j] = p_value\n",
        "    \n",
        "    # Crear matriz con asteriscos de significancia\n",
        "    significance_df = pd.DataFrame('', index=columns, columns=columns)\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            corr_val = corr_matrix[i, j]\n",
        "            p_val = p_value_matrix[i, j]\n",
        "            \n",
        "            if p_val < 0.001:\n",
        "                significance_df.iloc[i, j] = f\"{corr_val:.2f}***\"\n",
        "            elif p_val < 0.01:\n",
        "                significance_df.iloc[i, j] = f\"{corr_val:.2f}**\"\n",
        "            elif p_val < 0.05:\n",
        "                significance_df.iloc[i, j] = f\"{corr_val:.2f}*\"\n",
        "            else:\n",
        "                significance_df.iloc[i, j] = f\"{corr_val:.2f}\"\n",
        "    \n",
        "    print(\"\\n=== MATRIZ DE CORRELACI√ìN CON SIGNIFICANCIA ===\")\n",
        "    print(\"*** p < 0.001, ** p < 0.01, * p < 0.05\")\n",
        "    print(significance_df)\n",
        "    \n",
        "    return significance_df\n",
        "\n",
        "# Uso\n",
        "matriz_sig = matriz_correlacion_con_significancia(df)\n",
        "```\n",
        "\n",
        "### **Correlaci√≥n parcial (t√©cnica avanzada)**\n",
        "\n",
        "```python\n",
        "def correlacion_parcial(df, var1, var2, control_vars):\n",
        "    \"\"\"Calcula correlaci√≥n parcial controlando por otras variables\"\"\"\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "    \n",
        "    # Variables limpias\n",
        "    data = df[[var1, var2] + control_vars].dropna()\n",
        "    X_control = data[control_vars]\n",
        "    y1 = data[var1]\n",
        "    y2 = data[var2]\n",
        "    \n",
        "    # Modelos para eliminar efecto de variables de control\n",
        "    model1 = LinearRegression().fit(X_control, y1)\n",
        "    model2 = LinearRegression().fit(X_control, y2)\n",
        "    \n",
        "    # Residuales (efecto puro de var1 y var2)\n",
        "    resid1 = y1 - model1.predict(X_control)\n",
        "    resid2 = y2 - model2.predict(X_control)\n",
        "    \n",
        "    # Correlaci√≥n entre residuales = correlaci√≥n parcial\n",
        "    corr_parcial, p_value = stats.pearsonr(resid1, resid2)\n",
        "    \n",
        "    # Comparar con correlaci√≥n simple\n",
        "    corr_simple, p_simple = stats.pearsonr(data[var1], data[var2])\n",
        "    \n",
        "    print(f\"\\n=== CORRELACI√ìN PARCIAL: {var1} vs {var2} ===\")\n",
        "    print(f\"Controlando por: {control_vars}\")\n",
        "    print(f\"Correlaci√≥n simple:  {corr_simple:.3f} (p = {p_simple:.4f})\")\n",
        "    print(f\"Correlaci√≥n parcial: {corr_parcial:.3f} (p = {p_value:.4f})\")\n",
        "    print(f\"Diferencia: {corr_parcial - corr_simple:+.3f}\")\n",
        "    \n",
        "    if abs(corr_parcial) < abs(corr_simple):\n",
        "        print(\"\\nüí° La variable de control explica parte de la relaci√≥n\")\n",
        "    else:\n",
        "        print(\"\\nüí° La relaci√≥n persiste incluso controlando por otras variables\")\n",
        "    \n",
        "    return corr_parcial, p_value\n",
        "\n",
        "# Ejemplo: ¬øLa relaci√≥n edad-ingresos es real o solo por educaci√≥n?\n",
        "corr_parcial, p_val = correlacion_parcial(\n",
        "    df, 'edad', 'ingresos', ['nivel_educativo']\n",
        ")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 9. Correlaci√≥n ‚â† Causalidad: Framework de evaluaci√≥n\n",
        "\n",
        "### **Casos cl√°sicos de correlaci√≥n sin causalidad**\n",
        "\n",
        "| Correlaci√≥n | Explicaci√≥n | Tercer factor |\n",
        "|-------------|-------------|---------------|\n",
        "| **Helados vs Ahogamientos** | Ambos suben en verano | Temperatura |\n",
        "| **Piratas vs Calentamiento global** | Menos piratas, m√°s calentamiento | Tiempo (progreso) |\n",
        "| **Nicolas Cage vs Ahogamientos** | Coincidencia pura | Ninguno (aleatorio) |\n",
        "\n",
        "### **Framework para evaluar causalidad potencial**\n",
        "\n",
        "```python\n",
        "def verificar_causalidad_potencial(df, var1, var2, variables_confusoras=None):\n",
        "    \"\"\"Framework para evaluar causalidad potencial (NO es prueba)\"\"\"\n",
        "    print(f\"\\n=== EVALUANDO CAUSALIDAD POTENCIAL ===\")\n",
        "    print(f\"¬ø{var1} ‚Üí {var2}?\")\n",
        "    \n",
        "    # 1. Fuerza de correlaci√≥n\n",
        "    corr, p_val = stats.pearsonr(df[var1].dropna(), df[var2].dropna())\n",
        "    print(f\"\\n1. Correlaci√≥n: r = {corr:.3f} (p = {p_val:.4f})\")\n",
        "    \n",
        "    # 2. Temporalidad\n",
        "    if 'fecha' in df.columns:\n",
        "        print(\"2. Temporalidad: ‚úÖ Verificable con datos temporales\")\n",
        "    else:\n",
        "        print(\"2. Temporalidad: ‚ö†Ô∏è  No verificable sin datos temporales\")\n",
        "    \n",
        "    # 3. Variables confusoras\n",
        "    if variables_confusoras:\n",
        "        print(f\"3. Variables confusoras: {variables_confusoras}\")\n",
        "        print(\"   ‚Üí Analizar correlaci√≥n parcial\")\n",
        "    else:\n",
        "        print(\"3. Variables confusoras: ‚ö†Ô∏è  No especificadas\")\n",
        "    \n",
        "    # 4. Mecanismo plausible\n",
        "    print(\"4. Mecanismo: ‚ùì ¬øHay explicaci√≥n te√≥rica plausible?\")\n",
        "    \n",
        "    # 5. Recomendaci√≥n\n",
        "    print(\"\\n=== RECOMENDACI√ìN ===\")\n",
        "    if abs(corr) > 0.5 and p_val < 0.05:\n",
        "        print(\"üéØ Vale la pena investigar causalidad con:\")\n",
        "        print(\"   ‚Ä¢ Experimento A/B controlado\")\n",
        "        print(\"   ‚Ä¢ An√°lisis de series temporales\")\n",
        "        print(\"   ‚Ä¢ M√©todos causales avanzados (regresi√≥n discontinua, etc.)\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  Probablemente NO es causalidad, solo correlaci√≥n espuria\")\n",
        "\n",
        "# Uso\n",
        "verificar_causalidad_potencial(\n",
        "    df, 'gasto_publicidad', 'ventas',\n",
        "    ['estacion', 'competencia', 'precio']\n",
        ")\n",
        "```\n",
        "\n",
        "> **Regla de oro:** Para afirmar causalidad necesitas:\n",
        "> 1. Experimento controlado (A/B test) O\n",
        "> 2. M√©todos causales avanzados O\n",
        "> 3. Mecanismo f√≠sico/biol√≥gico demostrado\n",
        "\n",
        "---\n",
        "\n",
        "## 10. Checklist y gu√≠a de decisi√≥n\n",
        "\n",
        "### **Cu√°ndo usar cada t√©cnica**\n",
        "\n",
        "| Escenario | T√©cnica recomendada | Output clave |\n",
        "|-----------|---------------------|--------------|\n",
        "| **2 variables num√©ricas** | Correlaci√≥n Pearson/Spearman | r, p-value |\n",
        "| **2 variables categ√≥ricas** | Tabla cruzada + Chi-cuadrado | œá¬≤, Cram√©r's V |\n",
        "| **Num√©rica vs Categ√≥rica** | ANOVA + Boxplots | F-statistic, visualizaci√≥n |\n",
        "| **M√∫ltiples variables** | Matriz correlaci√≥n + Pairplot | Mapa completo |\n",
        "| **Controlar variables** | Correlaci√≥n parcial | r parcial |\n",
        "\n",
        "### **Checklist de an√°lisis de relaciones**\n",
        "\n",
        "- [ ] Variables num√©ricas: Correlaci√≥n calculada (Pearson/Spearman)\n",
        "- [ ] P-values verificados (< 0.05 para significancia)\n",
        "- [ ] Matriz de correlaci√≥n visualizada (heatmap)\n",
        "- [ ] Outliers identificados y evaluados\n",
        "- [ ] Variables categ√≥ricas: Tablas cruzadas creadas\n",
        "- [ ] Test Chi-cuadrado ejecutado si aplica\n",
        "- [ ] Cram√©r's V calculado para fuerza de asociaci√≥n\n",
        "- [ ] Relaciones mixtas: ANOVA realizado\n",
        "- [ ] Visualizaciones apropiadas generadas\n",
        "- [ ] Contexto de negocio considerado\n",
        "- [ ] Causalidad NO asumida sin evidencia experimental\n",
        "\n",
        "---\n",
        "\n",
        "## 11. Resumen\n",
        "\n",
        "**Tipos de relaciones por variables:**\n",
        "- ‚úÖ **Num√©rica-Num√©rica** ‚Üí Correlaci√≥n (Pearson r, Spearman œÅ, Kendall œÑ)\n",
        "- ‚úÖ **Categ√≥rica-Categ√≥rica** ‚Üí Tabla cruzada + Chi-cuadrado (œá¬≤) + Cram√©r's V\n",
        "- ‚úÖ **Num√©rica-Categ√≥rica** ‚Üí ANOVA (F) + Boxplot\n",
        "\n",
        "**Interpretaci√≥n de r (correlaci√≥n):**\n",
        "- |r| > 0.7 ‚Üí Fuerte\n",
        "- |r| = 0.5-0.7 ‚Üí Moderada\n",
        "- |r| = 0.3-0.5 ‚Üí D√©bil\n",
        "- |r| < 0.3 ‚Üí Muy d√©bil\n",
        "\n",
        "**Interpretaci√≥n de Cram√©r's V:**\n",
        "- V > 0.5 ‚Üí Asociaci√≥n fuerte\n",
        "- V = 0.3-0.5 ‚Üí Moderada\n",
        "- V = 0.1-0.3 ‚Üí D√©bil\n",
        "- V < 0.1 ‚Üí Muy d√©bil\n",
        "\n",
        "**Aplicaciones empresariales:**\n",
        "- **Marketing:** Gasto publicidad vs ventas por canal\n",
        "- **Producto:** Features usage vs retention\n",
        "- **Operaciones:** Fallos por tipo de equipo y turno\n",
        "- **RRHH:** Satisfacci√≥n empleados vs productividad\n",
        "\n",
        "**La advertencia m√°s importante:**\n",
        "```\n",
        "CORRELACI√ìN ‚â† CAUSALIDAD\n",
        "\n",
        "Helados ‚Üî Ahogamientos (r=0.9)\n",
        "Pero helados NO causan ahogamientos\n",
        "(Ambos suben con la temperatura)\n",
        "```\n",
        "\n",
        "> **Conclusi√≥n:** Dominar las relaciones entre variables es como tener un mapa del tesoro de tu negocio. Te muestra d√≥nde encontrar insights valiosos y te previene de conclusiones falsas. La clave: siempre visualiza, siempre valida significancia, nunca asumas causalidad.\n",
        "\n",
        "---\n",
        "\n",
        "## 12. Referencias\n",
        "\n",
        "### V√≠deos\n",
        "- [Correlation vs Causation](https://youtu.be/example1) - Ejemplos visuales\n",
        "- [Understanding Chi-Square](https://youtu.be/example2) - Test de independencia\n",
        "- [Spurious Correlations](https://youtu.be/example3) - Correlaciones absurdas\n",
        "\n",
        "### Lecturas\n",
        "- [\"Naked Statistics\" - Wheelan](https://example.com) - Intuici√≥n sobre correlaci√≥n\n",
        "- [Correlation in Python](https://realpython.com/numpy-scipy-pandas-correlation-python/)\n",
        "- [Spurious Correlations Website](https://tylervigen.com/spurious-correlations) - ¬°Divertido!\n",
        "\n",
        "### Herramientas\n",
        "- [Pandas corr()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html)\n",
        "- [SciPy stats](https://docs.scipy.org/doc/scipy/reference/stats.html)\n",
        "- [pandas-profiling](https://github.com/pandas-profiling/pandas-profiling) - An√°lisis autom√°tico"
      ],
      "metadata": {
        "id": "7L3iw7Z9LX0N"
      }
    }
  ]
}