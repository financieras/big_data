{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcWyxy+T8xcp2PqVpYVCeY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/financieras/big_data/blob/main/leccion_1_1_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lecci√≥n 1.1.6: Habilidades y herramientas por rol profesional\n",
        "\n",
        "## 1. Introducci√≥n: El mapa de habilidades del ecosistema de datos\n",
        "\n",
        "Hemos visto los roles del ecosistema de datos y sus responsabilidades. Ahora llega la pregunta pr√°ctica: **¬øQu√© necesito aprender para convertirme en cada rol? ¬øQu√© herramientas debo dominar?**\n",
        "\n",
        "**Lo importante:** No existe un \"Data Professional\" gen√©rico. Cada rol requiere un conjunto espec√≠fico de habilidades t√©cnicas (hard skills) y transversales (soft skills), con diferentes niveles de profundidad. Intentar dominar todas las herramientas es imposible e innecesario. La clave es especializarse estrat√©gicamente.\n",
        "\n",
        "### El mito del \"aprende todo\"\n",
        "\n",
        "**Error com√∫n:** Intentar aprender simult√°neamente SQL, Python, Spark, Hadoop, TensorFlow, Kubernetes, AWS, Tableau, estad√≠stica avanzada...\n",
        "\n",
        "**Realidad:** Cada rol tiene un **core t√©cnico** (3-5 habilidades cr√≠ticas) y habilidades complementarias. Dominar el core te hace empleable; el resto se aprende seg√∫n necesidad.\n",
        "\n",
        "### Estructura de esta lecci√≥n\n",
        "\n",
        "1. **Matriz de habilidades**: Qu√© necesita cada rol y en qu√© nivel\n",
        "2. **Herramientas por categor√≠a**: Stack tecnol√≥gico organizado\n",
        "3. **Roadmaps de aprendizaje**: Orden recomendado para desarrollar habilidades\n",
        "4. **Soft skills**: Habilidades transversales cr√≠ticas\n",
        "5. **Recursos de aprendizaje**: D√≥nde y c√≥mo aprender\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Matriz de habilidades por rol\n",
        "\n",
        "### Niveles de dominio\n",
        "\n",
        "- **No necesario (-)**: No es relevante para el rol\n",
        "- **B√°sico (‚≠ê)**: Entender conceptos, uso superficial\n",
        "- **Intermedio (‚≠ê‚≠ê)**: Uso diario, resolver problemas comunes\n",
        "- **Avanzado (‚≠ê‚≠ê‚≠ê)**: Experto, optimizaci√≥n, casos complejos\n",
        "- **Cr√≠tico (üî•)**: Habilidad definitoria del rol\n",
        "\n",
        "### Habilidades t√©cnicas principales\n",
        "\n",
        "| Habilidad | Analyst | Scientist | Engineer | ML Eng | MLOps | Architect |\n",
        "|-----------|---------|-----------|----------|--------|-------|-----------|\n",
        "| **SQL** | üî•‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | üî•‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê | ‚≠ê‚≠ê‚≠ê |\n",
        "| **Python** | ‚≠ê | üî•‚≠ê‚≠ê‚≠ê | üî•‚≠ê‚≠ê‚≠ê | üî•‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê |\n",
        "| **Estad√≠stica** | ‚≠ê‚≠ê | üî•‚≠ê‚≠ê‚≠ê | ‚≠ê | ‚≠ê‚≠ê | ‚≠ê | - |\n",
        "| **Machine Learning** | ‚≠ê | üî•‚≠ê‚≠ê‚≠ê | ‚≠ê | üî•‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê |\n",
        "| **Visualizaci√≥n** | üî•‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê | ‚≠ê | - | ‚≠ê |\n",
        "| **Cloud (AWS/GCP/Azure)** | ‚≠ê | ‚≠ê‚≠ê | üî•‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | üî•‚≠ê‚≠ê‚≠ê | üî•‚≠ê‚≠ê‚≠ê |\n",
        "| **Spark/procesamiento distribuido** | - | ‚≠ê‚≠ê | üî•‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |\n",
        "| **DevOps/Kubernetes** | - | - | ‚≠ê‚≠ê | ‚≠ê‚≠ê | üî•‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê |\n",
        "| **Git** | ‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê |\n",
        "| **Dise√±o de arquitecturas** | - | - | ‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê | üî•‚≠ê‚≠ê‚≠ê |\n",
        "| **Bases de datos (BBDD)** | ‚≠ê‚≠ê | ‚≠ê | üî•‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê | üî•‚≠ê‚≠ê‚≠ê |\n",
        "| **Excel/Spreadsheets** | üî•‚≠ê‚≠ê‚≠ê | ‚≠ê | - | - | - | - |\n",
        "| **BI Tools (Tableau, Power BI)** | üî•‚≠ê‚≠ê‚≠ê | ‚≠ê | - | - | - | - |\n",
        "| **Deep Learning** | - | ‚≠ê‚≠ê | - | ‚≠ê‚≠ê‚≠ê | ‚≠ê | - |\n",
        "| **Streaming (Kafka, Flink)** | - | - | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê |\n",
        "\n",
        "### Soft skills por rol\n",
        "\n",
        "| Habilidad | Analyst | Scientist | Engineer | ML Eng | MLOps | Architect |\n",
        "|-----------|---------|-----------|----------|--------|-------|-----------|\n",
        "| **Comunicaci√≥n** | üî•‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê | üî•‚≠ê‚≠ê‚≠ê |\n",
        "| **Negocio/Dominio** | üî•‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê | ‚≠ê‚≠ê‚≠ê |\n",
        "| **Pensamiento cr√≠tico** | üî•‚≠ê‚≠ê‚≠ê | üî•‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê | üî•‚≠ê‚≠ê‚≠ê |\n",
        "| **Colaboraci√≥n** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | üî•‚≠ê‚≠ê‚≠ê | üî•‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |\n",
        "| **Resoluci√≥n de problemas** | ‚≠ê‚≠ê‚≠ê | üî•‚≠ê‚≠ê‚≠ê | üî•‚≠ê‚≠ê‚≠ê | üî•‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | üî•‚≠ê‚≠ê‚≠ê |\n",
        "| **Liderazgo t√©cnico** | ‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | üî•‚≠ê‚≠ê‚≠ê |\n",
        "| **Documentaci√≥n** | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | üî•‚≠ê‚≠ê‚≠ê | üî•‚≠ê‚≠ê‚≠ê | üî•‚≠ê‚≠ê‚≠ê | üî•‚≠ê‚≠ê‚≠ê |\n",
        "| **Storytelling** | üî•‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê | ‚≠ê | ‚≠ê | ‚≠ê‚≠ê |\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Deep dive: Habilidades por rol\n",
        "\n",
        "### 3.1 Data Analyst\n",
        "\n",
        "#### Habilidades t√©cnicas core\n",
        "\n",
        "**1. SQL (üî• Cr√≠tico - Nivel avanzado)**\n",
        "\n",
        "**Qu√© necesitas saber:**\n",
        "- Queries complejas: JOINs m√∫ltiples, subqueries, CTEs (Common Table Expressions)\n",
        "- Funciones de ventana (window functions): ROW_NUMBER(), RANK(), LAG(), LEAD()\n",
        "- Agregaciones avanzadas y GROUP BY con HAVING\n",
        "- Optimizaci√≥n de queries (√≠ndices, EXPLAIN)\n",
        "- Diferentes dialectos SQL (PostgreSQL, MySQL, BigQuery)\n",
        "\n",
        "**Ejemplo de query avanzada que debes dominar:**\n",
        "```sql\n",
        "WITH user_activity AS (\n",
        "  SELECT\n",
        "    user_id,\n",
        "    DATE(event_timestamp) as event_date,\n",
        "    COUNT(*) as daily_events,\n",
        "    LAG(DATE(event_timestamp)) OVER (PARTITION BY user_id ORDER BY DATE(event_timestamp)) as previous_date\n",
        "  FROM events\n",
        "  WHERE event_timestamp >= '2025-01-01'\n",
        "  GROUP BY user_id, DATE(event_timestamp)\n",
        "),\n",
        "user_retention AS (\n",
        "  SELECT\n",
        "    user_id,\n",
        "    event_date,\n",
        "    CASE\n",
        "      WHEN DATE_DIFF(event_date, previous_date, DAY) = 1 THEN 'retained'\n",
        "      ELSE 'churned'\n",
        "    END as retention_status\n",
        "  FROM user_activity\n",
        ")\n",
        "SELECT\n",
        "  event_date,\n",
        "  COUNT(DISTINCT CASE WHEN retention_status = 'retained' THEN user_id END) * 100.0 /\n",
        "    COUNT(DISTINCT user_id) as retention_rate\n",
        "FROM user_retention\n",
        "GROUP BY event_date\n",
        "ORDER BY event_date;\n",
        "```\n",
        "\n",
        "**C√≥mo aprender:**\n",
        "- SQLZoo, Mode Analytics SQL Tutorial (interactivos)\n",
        "- Resolver 50+ problemas en LeetCode Database\n",
        "- Practicar con datasets p√∫blicos (Kaggle)\n",
        "- Tiempo estimado: 3-6 meses para nivel avanzado\n",
        "\n",
        "**2. Herramientas de BI (üî• Cr√≠tico - Tableau o Power BI)**\n",
        "\n",
        "**Qu√© necesitas saber:**\n",
        "- Conectar m√∫ltiples fuentes de datos\n",
        "- Crear dashboards interactivos con filtros y par√°metros\n",
        "- Visualizaciones avanzadas (mapas de calor, treemaps, gr√°ficos de sankey)\n",
        "- C√°lculos calculados (LOD en Tableau, DAX en Power BI)\n",
        "- Best practices de dise√±o (colores, jerarqu√≠a visual, storytelling)\n",
        "- Performance optimization para dashboards con millones de registros\n",
        "\n",
        "**Proyecto para practicar:**\n",
        "- Dashboard de an√°lisis de ventas e-commerce con:\n",
        "  - KPIs principales (revenue, AOV, conversion rate)\n",
        "  - An√°lisis de cohortes\n",
        "  - Funnel de conversi√≥n\n",
        "  - Segmentaci√≥n RFM (Recency, Frequency, Monetary)\n",
        "  - Predicci√≥n de tendencias\n",
        "\n",
        "**C√≥mo aprender:**\n",
        "- Certificaci√≥n oficial Tableau Desktop Specialist o Power BI\n",
        "- Recrear dashboards p√∫blicos de Tableau Public\n",
        "- Tiempo estimado: 2-3 meses\n",
        "\n",
        "**3. Excel/Google Sheets (üî• Cr√≠tico - Nivel avanzado)**\n",
        "\n",
        "**Qu√© necesitas saber:**\n",
        "- F√≥rmulas complejas: VLOOKUP/XLOOKUP, INDEX-MATCH, SUMIFS, COUNTIFS\n",
        "- Tablas din√°micas avanzadas\n",
        "- Macros b√°sicas (VBA) para automatizaci√≥n\n",
        "- Power Query (transformaci√≥n de datos)\n",
        "- An√°lisis hipot√©tico (What-if analysis, Solver)\n",
        "\n",
        "**C√≥mo aprender:**\n",
        "- ExcelJet, Chandoo.org\n",
        "- Tiempo estimado: 1-2 meses\n",
        "\n",
        "**4. Python b√°sico (‚≠ê B√°sico)**\n",
        "\n",
        "**Qu√© necesitas saber:**\n",
        "- Pandas para manipulaci√≥n de datos\n",
        "- Matplotlib/Seaborn para visualizaciones\n",
        "- Jupyter notebooks\n",
        "- NO necesitas: algoritmos complejos, POO avanzada, frameworks\n",
        "\n",
        "**Ejemplo de c√≥digo que deber√≠as poder escribir:**\n",
        "```python\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Cargar y limpiar datos\n",
        "df = pd.read_csv('sales.csv')\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df = df.dropna()\n",
        "\n",
        "# An√°lisis\n",
        "monthly_revenue = df.groupby(df['date'].dt.to_period('M'))['revenue'].sum()\n",
        "\n",
        "# Visualizaci√≥n\n",
        "monthly_revenue.plot(kind='bar', title='Monthly Revenue Trend')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Revenue ($)')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "**C√≥mo aprender:**\n",
        "- DataCamp \"Data Analyst with Python\" track\n",
        "- Tiempo estimado: 2-3 meses\n",
        "\n",
        "**5. Estad√≠stica descriptiva (‚≠ê‚≠ê Intermedio)**\n",
        "\n",
        "**Qu√© necesitas saber:**\n",
        "- Medidas de tendencia central (media, mediana, moda)\n",
        "- Medidas de dispersi√≥n (desviaci√≥n est√°ndar, rango intercuart√≠lico)\n",
        "- Distribuciones (normal, sesgada)\n",
        "- Correlaci√≥n vs causalidad\n",
        "- A/B testing b√°sico (interpretaci√≥n de resultados)\n",
        "- Intervalos de confianza\n",
        "\n",
        "**NO necesitas:** Inferencia estad√≠stica avanzada, modelos complejos\n",
        "\n",
        "**C√≥mo aprender:**\n",
        "- \"Statistics for Business\" en Coursera\n",
        "- Khan Academy Statistics\n",
        "- Tiempo estimado: 2 meses\n",
        "\n",
        "#### Herramientas del Data Analyst\n",
        "\n",
        "| Categor√≠a | Herramientas prioritarias | Alternativas |\n",
        "|-----------|--------------------------|--------------|\n",
        "| **Query** | PostgreSQL, BigQuery | MySQL, Snowflake, Redshift |\n",
        "| **Visualizaci√≥n** | Tableau **o** Power BI | Looker, Metabase, Superset |\n",
        "| **Spreadsheets** | Excel, Google Sheets | - |\n",
        "| **Python** | Pandas, Matplotlib | Seaborn, Plotly |\n",
        "| **Colaboraci√≥n** | Slack, Notion | Confluence, Teams |\n",
        "\n",
        "**Prioridad de aprendizaje:**\n",
        "1. SQL (3-6 meses)\n",
        "2. Excel avanzado (1-2 meses)\n",
        "3. Tableau o Power BI (2-3 meses)\n",
        "4. Estad√≠stica b√°sica (2 meses)\n",
        "5. Python b√°sico (2-3 meses)\n",
        "\n",
        "**Total para ser empleable: 10-16 meses de aprendizaje dedicado**\n",
        "\n",
        "---\n",
        "\n",
        "### 3.2 Data Scientist\n",
        "\n",
        "#### Habilidades t√©cnicas core\n",
        "\n",
        "**1. Python (üî• Cr√≠tico - Nivel avanzado)**\n",
        "\n",
        "**Qu√© necesitas saber:**\n",
        "- Programaci√≥n: estructuras de datos, funciones, clases (POO b√°sica)\n",
        "- Librer√≠as cient√≠ficas: NumPy, Pandas (avanzado), Scipy\n",
        "- Machine Learning: Scikit-learn (dominio completo)\n",
        "- Deep Learning: TensorFlow **o** PyTorch\n",
        "- Visualizaci√≥n: Matplotlib, Seaborn, Plotly\n",
        "- Notebooks: Jupyter, Google Colab\n",
        "\n",
        "**Ejemplo de c√≥digo que deber√≠as dominar:**\n",
        "```python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Preparaci√≥n de datos\n",
        "df = pd.read_csv('churn.csv')\n",
        "X = df.drop('churn', axis=1)\n",
        "y = df['churn']\n",
        "\n",
        "# Feature engineering\n",
        "X['tenure_months'] = X['tenure'] / 30\n",
        "X['revenue_per_month'] = X['total_revenue'] / X['tenure_months']\n",
        "\n",
        "# Split y pipeline\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('rf', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# Hyperparameter tuning\n",
        "param_grid = {\n",
        "    'rf__n_estimators': [100, 200, 300],\n",
        "    'rf__max_depth': [10, 20, None],\n",
        "    'rf__min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Evaluaci√≥n\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
        "print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba):.3f}\")\n",
        "\n",
        "# Feature importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': X.columns,\n",
        "    'importance': best_model.named_steps['rf'].feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "```\n",
        "\n",
        "**C√≥mo aprender:**\n",
        "- \"Python for Data Science\" (DataCamp, Coursera)\n",
        "- Kaggle competitions (participar en 5-10)\n",
        "- Tiempo estimado: 6-12 meses\n",
        "\n",
        "**2. Estad√≠stica y matem√°ticas (üî• Cr√≠tico - Nivel avanzado)**\n",
        "\n",
        "**Qu√© necesitas saber:**\n",
        "- **Estad√≠stica inferencial:** Pruebas de hip√≥tesis, p-values, intervalos de confianza\n",
        "- **Probabilidad:** Distribuciones (normal, binomial, Poisson), teorema de Bayes\n",
        "- **Regresi√≥n:** Lineal, log√≠stica, regularizaci√≥n (L1, L2)\n",
        "- **√Ålgebra lineal:** Vectores, matrices, operaciones (para entender ML)\n",
        "- **C√°lculo:** Derivadas, gradientes (para entender backpropagation)\n",
        "- **Dise√±o experimental:** A/B testing, test estad√≠sticos (t-test, chi-cuadrado)\n",
        "\n",
        "**Conceptos que debes explicar con claridad:**\n",
        "- ¬øQu√© es p-value y c√≥mo interpretarlo?\n",
        "- ¬øPor qu√© normalizar features en ML?\n",
        "- ¬øCu√°ndo usar L1 vs L2 regularization?\n",
        "- ¬øC√≥mo funciona gradient descent?\n",
        "\n",
        "**C√≥mo aprender:**\n",
        "- \"Mathematics for Machine Learning\" (Imperial College, Coursera)\n",
        "- \"Statistics with Python\" (University of Michigan, Coursera)\n",
        "- Libro: \"An Introduction to Statistical Learning\" (ISL) - gratuito\n",
        "- Tiempo estimado: 6-12 meses (simult√°neo con Python)\n",
        "\n",
        "**3. Machine Learning (üî• Cr√≠tico - Nivel avanzado)**\n",
        "\n",
        "**Algoritmos que DEBES dominar:**\n",
        "\n",
        "**Supervisado:**\n",
        "- Regresi√≥n: Linear, Logistic, Ridge, Lasso\n",
        "- √Årboles: Decision Trees, Random Forest, XGBoost, LightGBM\n",
        "- SVM, KNN\n",
        "- Redes neuronales b√°sicas\n",
        "\n",
        "**No supervisado:**\n",
        "- Clustering: K-means, DBSCAN, Hierarchical\n",
        "- Reducci√≥n dimensionalidad: PCA, t-SNE, UMAP\n",
        "- Detecci√≥n de anomal√≠as\n",
        "\n",
        "**Conceptos cr√≠ticos:**\n",
        "- Overfitting vs underfitting\n",
        "- Bias-variance tradeoff\n",
        "- Cross-validation\n",
        "- Feature engineering y selection\n",
        "- M√©tricas (accuracy, precision, recall, F1, AUC-ROC)\n",
        "- Interpretabilidad (SHAP, LIME)\n",
        "\n",
        "**Proyecto completo que deber√≠as poder hacer:**\n",
        "- Predecir churn de clientes con:\n",
        "  - EDA completo\n",
        "  - Feature engineering\n",
        "  - Probar 5+ algoritmos\n",
        "  - Hyperparameter tuning\n",
        "  - Interpretaci√≥n de resultados\n",
        "  - Recomendaciones de negocio\n",
        "\n",
        "**C√≥mo aprender:**\n",
        "- \"Machine Learning\" de Andrew Ng (Coursera) - imprescindible\n",
        "- Fast.ai \"Practical Deep Learning\"\n",
        "- Kaggle Learn + competitions\n",
        "- Tiempo estimado: 6-12 meses\n",
        "\n",
        "**4. SQL y bases de datos (‚≠ê‚≠ê Intermedio)**\n",
        "\n",
        "No necesitas el nivel de un Data Engineer, pero debes:\n",
        "- Escribir queries para obtener datos de entrenamiento\n",
        "- Entender √≠ndices y performance b√°sica\n",
        "- JOINs, subqueries, CTEs\n",
        "\n",
        "**Tiempo:** 2-3 meses\n",
        "\n",
        "**5. Comunicaci√≥n y visualizaci√≥n (‚≠ê‚≠ê Intermedio)**\n",
        "\n",
        "**Qu√© necesitas saber:**\n",
        "- Contar historias con datos (data storytelling)\n",
        "- Crear visualizaciones efectivas (no solo bonitas)\n",
        "- Explicar modelos complejos a audiencias no t√©cnicas\n",
        "- Escribir informes t√©cnicos claros\n",
        "\n",
        "**Habilidades espec√≠ficas:**\n",
        "- Presentaciones con insights accionables\n",
        "- Visualizaciones con Matplotlib/Seaborn/Plotly\n",
        "- Dashboards b√°sicos (opcional)\n",
        "\n",
        "**C√≥mo mejorar:**\n",
        "- Presentar tus proyectos a personas no t√©cnicas\n",
        "- Blog personal explicando conceptos de ML\n",
        "- Tiempo: mejora continua\n",
        "\n",
        "#### Herramientas del Data Scientist\n",
        "\n",
        "| Categor√≠a | Herramientas prioritarias | Alternativas |\n",
        "|-----------|--------------------------|--------------|\n",
        "| **Programaci√≥n** | Python | R (sector acad√©mico/farmac√©utico) |\n",
        "| **ML frameworks** | Scikit-learn, XGBoost | LightGBM, CatBoost |\n",
        "| **Deep Learning** | PyTorch **o** TensorFlow | JAX, Keras |\n",
        "| **Notebooks** | Jupyter, Google Colab | Databricks, VSCode |\n",
        "| **Experiment tracking** | MLflow | Weights & Biases, Neptune |\n",
        "| **Visualizaci√≥n** | Matplotlib, Seaborn | Plotly, Altair |\n",
        "| **Versionado** | Git, DVC | - |\n",
        "\n",
        "**Prioridad de aprendizaje:**\n",
        "1. Python + librer√≠as cient√≠ficas (6 meses)\n",
        "2. Estad√≠stica y matem√°ticas (6 meses, paralelo)\n",
        "3. Machine Learning (6 meses)\n",
        "4. Deep Learning (3-6 meses, opcional al inicio)\n",
        "5. SQL (2-3 meses)\n",
        "\n",
        "**Total para ser empleable: 18-24 meses de aprendizaje intensivo**\n",
        "\n",
        "**Nota importante:** Data Scientist es el rol con mayor barrera de entrada. Requiere formaci√≥n universitaria STEM (Matem√°ticas, F√≠sica, Ingenier√≠a) o esfuerzo autodidacta muy significativo.\n",
        "\n",
        "---\n",
        "\n",
        "### 3.3 Data Engineer\n",
        "\n",
        "#### Habilidades t√©cnicas core\n",
        "\n",
        "**1. Python/Scala (üî• Cr√≠tico - Nivel avanzado)**\n",
        "\n",
        "**Python - Qu√© necesitas saber:**\n",
        "- Programaci√≥n: POO, decoradores, generators, context managers\n",
        "- Manejo de errores y logging\n",
        "- Testing (pytest)\n",
        "- Async programming (opcional pero √∫til)\n",
        "- Librer√≠as: Pandas, PySpark, SQLAlchemy\n",
        "\n",
        "**Ejemplo de c√≥digo productivo:**\n",
        "```python\n",
        "import logging\n",
        "from typing import Dict, List\n",
        "from pyspark.sql import SparkSession, DataFrame\n",
        "from pyspark.sql.functions import col, to_date, count\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class SalesETL:\n",
        "    def __init__(self, spark: SparkSession):\n",
        "        self.spark = spark\n",
        "    \n",
        "    def extract(self, source_path: str) -> DataFrame:\n",
        "        \"\"\"Extract data from source\"\"\"\n",
        "        logger.info(f\"Extracting data from {source_path}\")\n",
        "        return self.spark.read.parquet(source_path)\n",
        "    \n",
        "    def transform(self, df: DataFrame) -> DataFrame:\n",
        "        \"\"\"Apply transformations\"\"\"\n",
        "        logger.info(\"Applying transformations\")\n",
        "        \n",
        "        # Data quality checks\n",
        "        df = df.dropna(subset=['order_id', 'customer_id', 'revenue'])\n",
        "        df = df.filter(col('revenue') > 0)\n",
        "        \n",
        "        # Business logic\n",
        "        df = df.withColumn('order_date', to_date(col('order_timestamp')))\n",
        "        \n",
        "        return df\n",
        "    \n",
        "    def load(self, df: DataFrame, target_path: str) -> None:\n",
        "        \"\"\"Load data to destination\"\"\"\n",
        "        logger.info(f\"Loading data to {target_path}\")\n",
        "        df.write.mode('overwrite').partitionBy('order_date').parquet(target_path)\n",
        "    \n",
        "    def run(self, source_path: str, target_path: str) -> Dict[str, int]:\n",
        "        \"\"\"Execute full ETL pipeline\"\"\"\n",
        "        try:\n",
        "            df = self.extract(source_path)\n",
        "            df_transformed = self.transform(df)\n",
        "            self.load(df_transformed, target_path)\n",
        "            \n",
        "            record_count = df_transformed.count()\n",
        "            logger.info(f\"ETL completed successfully. Processed {record_count} records\")\n",
        "            return {'status': 'success', 'records': record_count}\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ETL failed: {str(e)}\")\n",
        "            raise\n",
        "```\n",
        "\n",
        "**Scala:** √ötil para Spark avanzado, pero Python es suficiente para empezar\n",
        "\n",
        "**C√≥mo aprender:**\n",
        "- \"Python for Software Engineering\" (Udemy, YouTube)\n",
        "- \"PySpark Essentials\" (Udemy)\n",
        "- Tiempo estimado: 4-6 meses\n",
        "\n",
        "**2. SQL (üî• Cr√≠tico - Nivel avanzado + optimizaci√≥n)**\n",
        "\n",
        "**Qu√© necesitas dominar:**\n",
        "- Todo lo del Data Analyst, M√ÅS:\n",
        "- Dise√±o de esquemas y normalizaci√≥n (1NF, 2NF, 3NF)\n",
        "- √çndices: tipos, cu√°ndo usarlos, trade-offs\n",
        "- Query optimization: EXPLAIN plans, identificar bottlenecks\n",
        "- Particionamiento de tablas\n",
        "- Materializations y vistas materializadas\n",
        "- Transactions y ACID properties\n",
        "\n",
        "**Ejemplo de optimizaci√≥n:**\n",
        "```sql\n",
        "-- Query lenta (sin √≠ndice)\n",
        "SELECT customer_id, SUM(revenue)\n",
        "FROM orders\n",
        "WHERE order_date >= '2025-01-01'\n",
        "GROUP BY customer_id;\n",
        "-- Execution time: 45 segundos\n",
        "\n",
        "-- Soluci√≥n: crear √≠ndice\n",
        "CREATE INDEX idx_order_date ON orders(order_date);\n",
        "-- Execution time: 2 segundos\n",
        "\n",
        "-- Mejor soluci√≥n: tabla pre-agregada\n",
        "CREATE TABLE daily_customer_revenue AS\n",
        "SELECT\n",
        "    order_date,\n",
        "    customer_id,\n",
        "    SUM(revenue) as daily_revenue\n",
        "FROM orders\n",
        "GROUP BY order_date, customer_id;\n",
        "-- Queries subsecuentes: <1 segundo\n",
        "```\n",
        "\n",
        "**C√≥mo aprender:**\n",
        "- \"Database Design\" (Coursera, Udacity)\n",
        "- \"SQL Performance Tuning\" (Pluralsight)\n",
        "- Tiempo estimado: 3-4 meses\n",
        "\n",
        "**3. Apache Spark (üî• Cr√≠tico - Nivel avanzado)**\n",
        "\n",
        "**Qu√© necesitas saber:**\n",
        "- Arquitectura de Spark (driver, executors, cluster manager)\n",
        "- RDDs vs DataFrames vs Datasets\n",
        "- Transformaciones (lazy) vs acciones\n",
        "- Partitioning y shuffling\n",
        "- Broadcast variables y accumulators\n",
        "- Optimizaci√≥n de jobs (skew, spill, memory tuning)\n",
        "- Spark SQL\n",
        "- Streaming con Structured Streaming\n",
        "\n",
        "**Conceptos que debes explicar:**\n",
        "- ¬øPor qu√© mi job tarda 2 horas? (data skew, shuffle, memory)\n",
        "- ¬øCu√°ntas particiones necesito?\n",
        "- ¬øCu√°ndo usar broadcast join?\n",
        "\n",
        "**C√≥mo aprender:**\n",
        "- \"Spark and Python for Big Data\" (Udemy)\n",
        "- Databricks Academy (gratuito)\n",
        "- Tiempo estimado: 4-6 meses\n",
        "\n",
        "**4. Cloud platforms (üî• Cr√≠tico - AWS, GCP o Azure)**\n",
        "\n",
        "**Servicios que DEBES conocer (ejemplo AWS):**\n",
        "\n",
        "**Almacenamiento:**\n",
        "- S3: buckets, lifecycle policies, versioning\n",
        "- Redshift: data warehouse\n",
        "\n",
        "**Procesamiento:**\n",
        "- EMR: clusters Spark administrados\n",
        "- Glue: ETL serverless\n",
        "- Lambda: funciones serverless\n",
        "\n",
        "**Orquestaci√≥n:**\n",
        "- Airflow (MWAA) o Step Functions\n",
        "\n",
        "**Streaming:**\n",
        "- Kinesis o MSK (Kafka managed)\n",
        "\n",
        "**Otros:**\n",
        "- IAM: permisos y roles\n",
        "- CloudWatch: monitorizaci√≥n\n",
        "- VPC: networking b√°sico\n",
        "\n",
        "**Equivalentes GCP:**\n",
        "- S3 ‚Üí Cloud Storage\n",
        "- Redshift ‚Üí BigQuery\n",
        "- EMR ‚Üí Dataproc\n",
        "- Glue ‚Üí Dataflow\n",
        "\n",
        "**C√≥mo aprender:**\n",
        "- Certificaci√≥n AWS Cloud Practitioner ‚Üí Solutions Architect Associate\n",
        "- \"Google Cloud Big Data and ML\" (Coursera)\n",
        "- Tiempo estimado: 4-6 meses\n",
        "\n",
        "**5. Orquestaci√≥n: Apache Airflow (üî• Cr√≠tico)**\n",
        "\n",
        "**Qu√© necesitas saber:**\n",
        "- Conceptos: DAGs, operators, tasks, dependencies\n",
        "- Scheduling y backfilling\n",
        "- XComs para compartir datos entre tasks\n",
        "- Sensores y branching\n",
        "- Monitorizaci√≥n y alertas\n",
        "- Best practices (idempotencia, testing)\n",
        "\n",
        "**Ejemplo de DAG:**\n",
        "```python\n",
        "from airflow import DAG\n",
        "from airflow.operators.python import PythonOperator\n",
        "from airflow.providers.amazon.aws.transfers.s3_to_redshift import S3ToRedshiftOperator\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "default_args = {\n",
        "    'owner': 'data-team',\n",
        "    'depends_on_past': False,\n",
        "    'email_on_failure': True,\n",
        "    'email': ['alerts@company.com'],\n",
        "    'retries': 2,\n",
        "    'retry_delay': timedelta(minutes=5)\n",
        "}\n",
        "\n",
        "with DAG(\n",
        "    'daily_sales_pipeline',\n",
        "    default_args=default_args,\n",
        "    schedule_interval='0 2 * * *',  # 2 AM daily\n",
        "    start_date=datetime(2025, 1, 1),\n",
        "    catchup=False\n",
        ") as dag:\n",
        "    \n",
        "    extract_task = PythonOperator(\n",
        "        task_id='extract_from_api',\n",
        "        python_callable=extract_sales_data\n",
        "    )\n",
        "    \n",
        "    transform_task = PythonOperator(\n",
        "        task_id='transform_data',\n",
        "        python_callable=transform_sales_data\n",
        "    )\n",
        "    \n",
        "    load_task = S3ToRedshiftOperator(\n",
        "        task_id='load_to_redshift',\n",
        "        s3_bucket='my-bucket',\n",
        "        s3_key='sales/{{ ds }}/data.parquet',\n",
        "        redshift_conn_id='redshift_default',\n",
        "        table='sales_fact'\n",
        "    )\n",
        "    \n",
        "    extract_task >> transform_task >> load_task\n",
        "```\n",
        "\n",
        "**C√≥mo aprender:**\n",
        "- Documentaci√≥n oficial de Airflow\n",
        "- \"Apache Airflow: The Hands-On Guide\" (Udemy)\n",
        "- Tiempo estimado: 2-3 meses\n",
        "\n",
        "**6. Infraestructura como c√≥digo: Docker, Git (‚≠ê‚≠ê Intermedio)**\n",
        "\n",
        "**Docker:**\n",
        "- Crear Dockerfiles\n",
        "- Docker Compose para entornos locales\n",
        "- Container registries\n",
        "\n",
        "**Git:**\n",
        "- Branching strategies (Git Flow)\n",
        "- Pull requests y code reviews\n",
        "- CI/CD pipelines b√°sicos\n",
        "\n",
        "**C√≥mo aprender:**\n",
        "- \"Docker Mastery\" (Udemy)\n",
        "- Tiempo estimado: 2 meses\n",
        "\n",
        "#### Herramientas del Data Engineer\n",
        "\n",
        "| Categor√≠a | Herramientas prioritarias | Alternativas |\n",
        "|-----------|--------------------------|--------------|\n",
        "| **Programaci√≥n** | Python, SQL | Scala, Java |\n",
        "| **Procesamiento** | Apache Spark | Flink, Beam, dbt |\n",
        "| **Orquestaci√≥n** | Apache Airflow | Prefect, Dagster, Luigi |\n",
        "| **Cloud** | AWS **o** GCP **o** Azure | Elegir UNO |\n",
        "| **Almacenamiento** | S3, Redshift/BigQuery/Snowflake | Delta Lake, Iceberg |\n",
        "| **Streaming** | Kafka | Kinesis, Pub/Sub, Pulsar |\n",
        "| **Contenedores** | Docker | Kubernetes (avanzado) |\n",
        "| **Ingesta** | Fivetran, Airbyte | Custom scripts, Singer |\n",
        "| **Versionado** | Git | - |\n",
        "\n",
        "**Prioridad de aprendizaje:**\n",
        "1. Python + SQL (6 meses)\n",
        "2. Cloud platform (elegir uno: 4-6 meses)\n",
        "3. Spark (4-6 meses, puede solapar con cloud)\n",
        "4. Airflow (2-3 meses)\n",
        "5. Docker + Git (2 meses)\n",
        "\n",
        "**Total para ser empleable: 18-24 meses**\n",
        "\n",
        "---\n",
        "\n",
        "### 3.4 ML Engineer\n",
        "\n",
        "#### Habilidades t√©cnicas core\n",
        "\n",
        "El ML Engineer necesita **una combinaci√≥n de Data Scientist (ML) + Data Engineer (software engineering)**.\n",
        "\n",
        "**Habilidades del Data Scientist que necesitas:**\n",
        "- Machine Learning: ‚≠ê‚≠ê‚≠ê (no tan profundo como Scientist puro)\n",
        "- Python: üî•‚≠ê‚≠ê‚≠ê\n",
        "- Deep Learning: ‚≠ê‚≠ê‚≠ê (especialmente si trabajas con NLP/CV)\n",
        "\n",
        "**Habilidades del Data Engineer que necesitas:**\n",
        "- Ingenier√≠a de software: üî•‚≠ê‚≠ê‚≠ê\n",
        "- Cloud: ‚≠ê‚≠ê‚≠ê\n",
        "- Docker/Kubernetes: ‚≠ê‚≠ê‚≠ê\n",
        "- APIs: üî•‚≠ê‚≠ê‚≠ê\n",
        "\n",
        "**Habilidades √∫nicas del ML Engineer:**\n",
        "\n",
        "**1. Model serving y deployment (üî• Cr√≠tico)**\n",
        "\n",
        "**Qu√© necesitas saber:**\n",
        "- APIs con FastAPI/Flask\n",
        "- TensorFlow Serving, TorchServe\n",
        "- Containerizaci√≥n de modelos\n",
        "- Latency optimization\n",
        "- Batch vs real-time inference\n",
        "\n",
        "**Ejemplo: API de modelo en FastAPI:**\n",
        "```python\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# Cargar modelo al startup\n",
        "model = joblib.load('model.pkl')\n",
        "\n",
        "class PredictionRequest(BaseModel):\n",
        "    feature_1: float\n",
        "    feature_2: float\n",
        "    feature_3: float\n",
        "\n",
        "class PredictionResponse(BaseModel):\n",
        "    prediction: int\n",
        "    probability: float\n",
        "\n",
        "@app.post(\"/predict\", response_model=PredictionResponse)\n",
        "async def predict(request: PredictionRequest):\n",
        "    # Preparar features\n",
        "    features = np.array([[\n",
        "        request.feature_1,\n",
        "        request.feature_2,\n",
        "        request.feature_3\n",
        "    ]])\n",
        "    \n",
        "    # Predicci√≥n\n",
        "    prediction = model.predict(features)[0]\n",
        "    probability = model.predict_proba(features)[0].max()\n",
        "    \n",
        "    return PredictionResponse(\n",
        "        prediction=int(prediction),\n",
        "        probability=float(probability)\n",
        "    )\n",
        "\n",
        "@app.get(\"/health\")\n",
        "async def health():\n",
        "    return {\"status\": \"healthy\"}\n",
        "```\n",
        "\n",
        "**C√≥mo aprender:**\n",
        "- \"Deploying Machine Learning Models\" (Udemy)\n",
        "- Documentaci√≥n FastAPI\n",
        "- Tiempo estimado: 3 meses\n",
        "\n",
        "**2. Feature engineering at scale (üî• Cr√≠tico)**\n",
        "\n",
        "**Qu√© necesitas saber:**\n",
        "- Feature stores (Feast, Tecton)\n",
        "- Pipelines de features con Spark\n",
        "- Online vs offline features\n",
        "- Feature serving con baja latencia\n",
        "\n",
        "**C√≥mo aprender:**\n",
        "- Documentaci√≥n Feast\n",
        "- Blogs de Uber/Airbnb sobre feature stores\n",
        "- Tiempo estimado: 2-3 meses\n",
        "\n",
        "**3. Model optimization (‚≠ê‚≠ê‚≠ê Avanzado)**\n",
        "\n",
        "**T√©cnicas que debes conocer:**\n",
        "- Quantization (INT8, FP16)\n",
        "- Pruning\n",
        "- Knowledge distillation\n",
        "- Model compilation (ONNX, TensorRT)\n",
        "- Hardware acceleration (GPU, TPU)\n",
        "\n",
        "**C√≥mo aprender:**\n",
        "- \"TensorFlow Model Optimization Toolkit\"\n",
        "- Papers y blogs t√©cnicos\n",
        "- Tiempo estimado: 3-4 meses\n",
        "\n",
        "**4. A/B testing y experimentaci√≥n (‚≠ê‚≠ê Intermedio)**\n",
        "\n",
        "**Qu√© necesitas saber:**\n",
        "- Dise√±ar A/B tests para modelos\n",
        "- M√©tricas de √©xito\n",
        "- An√°lisis estad√≠stico de resultados\n",
        "- Implementaci√≥n t√©cnica (feature flags)\n",
        "\n",
        "**Herramientas:** MLflow, Optimizely\n",
        "\n",
        "**Tiempo:** 2 meses\n",
        "\n",
        "#### Herramientas del ML Engineer\n",
        "\n",
        "| Categor√≠a | Herramientas prioritarias |\n",
        "|-----------|--------------------------|\n",
        "| **ML Frameworks** | Scikit-learn, XGBoost, PyTorch/TensorFlow |\n",
        "| **Serving** | FastAPI, TensorFlow Serving, TorchServe |\n",
        "| **Orquestaci√≥n** | Airflow, Kubeflow, Metaflow |\n",
        "| **Feature Store** | Feast, Tecton |\n",
        "| **Experiment tracking** | MLflow, Weights & Biases |\n",
        "| **Containers** | Docker, Kubernetes |\n",
        "| **Cloud** | AWS SageMaker / GCP Vertex AI / Azure ML |\n",
        "| **Monitoring** | Prometheus, Grafana, Evidently |\n",
        "\n",
        "**Prioridad de aprendizaje:**\n",
        "1. Base de Data Scientist (Python + ML): 12 meses\n",
        "2. Ingenier√≠a de software (APIs, Docker): 4 meses\n",
        "3. Model serving y deployment: 3 meses\n",
        "4. Cloud ML platforms: 3 meses\n",
        "5. Feature engineering at scale: 3 meses\n",
        "\n",
        "**Total: 24-30 meses** (asumiendo que empiezas desde cero)\n",
        "\n",
        "**Atajo:** Si ya eres Data Scientist, necesitas +6-12 meses. Si ya eres Data Engineer, necesitas +12-18 meses.\n",
        "\n",
        "---\n",
        "\n",
        "### 3.5 MLOps Engineer\n",
        "\n",
        "#### Habilidades t√©cnicas core\n",
        "\n",
        "El MLOps Engineer es **75% DevOps + 25% ML knowledge**.\n",
        "\n",
        "**De DevOps/SRE necesitas:**\n",
        "- Kubernetes: üî•‚≠ê‚≠ê‚≠ê\n",
        "- CI/CD: üî•‚≠ê‚≠ê‚≠ê\n",
        "- Infrastructure as Code: üî•‚≠ê‚≠ê‚≠ê (Terraform)\n",
        "- Monitoring: üî•‚≠ê‚≠ê‚≠ê\n",
        "- Cloud: üî•‚≠ê‚≠ê‚≠ê\n",
        "\n",
        "**De ML necesitas:**\n",
        "- Entender conceptos de ML: ‚≠ê‚≠ê\n",
        "- NO necesitas entrenar modelos t√∫ mismo\n",
        "- Saber qu√© necesitan los ML Engineers\n",
        "\n",
        "**1. Kubernetes (üî• Cr√≠tico - Nivel avanzado)**\n",
        "\n",
        "**Qu√© necesitas saber:**\n",
        "- Arquitectura: pods, deployments, services, ingress\n",
        "- Networking y storage\n",
        "- Helm charts\n",
        "- Auto-scaling (HPA, VPA)\n",
        "- Resource management (requests, limits)\n",
        "- Operadores de Kubernetes\n",
        "\n",
        "**Ejemplo: Deploy de modelo en K8s:**\n",
        "```yaml\n",
        "apiVersion: apps/v1\n",
        "kind: Deployment\n",
        "metadata:\n",
        "  name: model-serving\n",
        "spec:\n",
        "  replicas: 3\n",
        "  selector:\n",
        "    matchLabels:\n",
        "      app: model-api\n",
        "  template:\n",
        "    metadata:\n",
        "      labels:\n",
        "        app: model-api\n",
        "    spec:\n",
        "      containers:\n",
        "      - name: model-api\n",
        "        image: myregistry/model:v1.2.3\n",
        "        ports:\n",
        "        - containerPort: 8000\n",
        "        resources:\n",
        "          requests:\n",
        "            memory: \"2Gi\"\n",
        "            cpu: \"1000m\"\n",
        "          limits:\n",
        "            memory: \"4Gi\"\n",
        "            cpu: \"2000m\"\n",
        "        livenessProbe:\n",
        "          httpGet:\n",
        "            path: /health\n",
        "            port: 8000\n",
        "          initialDelaySeconds: 30\n",
        "          periodSeconds: 10\n",
        "---\n",
        "apiVersion: v1\n",
        "kind: Service\n",
        "metadata:\n",
        "  name: model-service\n",
        "spec:\n",
        "  selector:\n",
        "    app: model-api\n",
        "  ports:\n",
        "  - protocol: TCP\n",
        "    port: 80\n",
        "    targetPort: 8000\n",
        "  type: LoadBalancer\n",
        "---\n",
        "apiVersion: autoscaling/v2\n",
        "kind: HorizontalPodAutoscaler\n",
        "metadata:\n",
        "  name: model-hpa\n",
        "spec:\n",
        "  scaleTargetRef:\n",
        "    apiVersion: apps/v1\n",
        "    kind: Deployment\n",
        "    name: model-serving\n",
        "  minReplicas: 2\n",
        "  maxReplicas: 10\n",
        "  metrics:\n",
        "  - type: Resource\n",
        "    resource:\n",
        "      name: cpu\n",
        "      target:\n",
        "        type: Utilization\n",
        "        averageUtilization: 70\n",
        "```\n",
        "\n",
        "**C√≥mo aprender:**\n",
        "- Certificaci√≥n CKA (Certified Kubernetes Administrator)\n",
        "- \"Kubernetes for Absolute Beginners\" (KodeKloud)\n",
        "- Tiempo estimado: 4-6 meses\n",
        "\n",
        "**2. CI/CD para ML (üî• Cr√≠tico)**\n",
        "\n",
        "**Qu√© necesitas implementar:**\n",
        "- Pipeline de training autom√°tico\n",
        "- Testing: unit tests, integration tests, model validation\n",
        "- Automated deployment con blue-green o canary\n",
        "- Rollback autom√°tico si performance degrada\n",
        "\n",
        "**Ejemplo: GitHub Actions para ML:**\n",
        "```yaml\n",
        "name: ML Pipeline\n",
        "on:\n",
        "  push:\n",
        "    branches: [main]\n",
        "  pull_request:\n",
        "\n",
        "jobs:\n",
        "  test:\n",
        "    runs-on: ubuntu-latest\n",
        "    steps:\n",
        "    - uses: actions/checkout@v2\n",
        "    - name: Run tests\n",
        "      run: |\n",
        "        pip install -r requirements.txt\n",
        "        pytest tests/\n",
        "  \n",
        "  train:\n",
        "    needs: test\n",
        "    runs-on: ubuntu-latest\n",
        "    if: github.ref == 'refs/heads/main'\n",
        "    steps:\n",
        "    - uses: actions/checkout@v2\n",
        "    - name: Train model\n",
        "      run: python train.py\n",
        "    - name: Validate model\n",
        "      run: |\n",
        "        python validate.py\n",
        "        if [ $? -ne 0 ]; then exit 1; fi\n",
        "    - name: Push model to registry\n",
        "      run: |\n",
        "        mlflow models serve -m model_uri\n",
        "  \n",
        "  deploy:\n",
        "    needs: train\n",
        "    runs-on: ubuntu-latest\n",
        "    steps:\n",
        "    - name: Deploy to Kubernetes\n",
        "      run: |\n",
        "        kubectl apply -f k8s/deployment.yaml\n",
        "    - name: Run smoke tests\n",
        "      run: python smoke_tests.py\n",
        "```\n",
        "\n",
        "**C√≥mo aprender:**\n",
        "- \"MLOps Specialization\" (Coursera - DeepLearning.AI)\n",
        "- GitHub Actions / GitLab CI documentation\n",
        "- Tiempo estimado: 3-4 meses\n",
        "\n",
        "**3. Infrastructure as Code: Terraform (üî• Cr√≠tico)**\n",
        "\n",
        "**Qu√© necesitas saber:**\n",
        "- Sintaxis HCL\n",
        "- Providers (AWS, GCP, Azure)\n",
        "- State management\n",
        "- Modules y reutilizaci√≥n\n",
        "- Workspaces para m√∫ltiples entornos\n",
        "\n",
        "**Ejemplo: Provisionar infraestructura ML en AWS:**\n",
        "```hcl\n",
        "# main.tf\n",
        "provider \"aws\" {\n",
        "  region = \"eu-west-1\"\n",
        "}\n",
        "\n",
        "resource \"aws_s3_bucket\" \"model_artifacts\" {\n",
        "  bucket = \"my-company-ml-models\"\n",
        "  \n",
        "  lifecycle_rule {\n",
        "    id      = \"archive-old-models\"\n",
        "    enabled = true\n",
        "    \n",
        "    transition {\n",
        "      days          = 90\n",
        "      storage_class = \"GLACIER\"\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "resource \"aws_sagemaker_notebook_instance\" \"ml_notebook\" {\n",
        "  name          = \"ml-experimentation\"\n",
        "  role_arn      = aws_iam_role.sagemaker.arn\n",
        "  instance_type = \"ml.t3.medium\"\n",
        "}\n",
        "\n",
        "resource \"aws_eks_cluster\" \"ml_cluster\" {\n",
        "  name     = \"ml-production\"\n",
        "  role_arn = aws_iam_role.eks.arn\n",
        "  version  = \"1.28\"\n",
        "  \n",
        "  vpc_config {\n",
        "    subnet_ids = var.subnet_ids\n",
        "  }\n",
        "}\n",
        "\n",
        "resource \"aws_eks_node_group\" \"ml_nodes\" {\n",
        "  cluster_name    = aws_eks_cluster.ml_cluster.name\n",
        "  node_group_name = \"ml-workers\"\n",
        "  node_role_arn   = aws_iam_role.node.arn\n",
        "  subnet_ids      = var.subnet_ids\n",
        "  \n",
        "  scaling_config {\n",
        "    desired_size = 3\n",
        "    max_size     = 10\n",
        "    min_size     = 2\n",
        "  }\n",
        "  \n",
        "  instance_types = [\"p3.2xlarge\"]  # GPU instances\n",
        "}\n",
        "```\n",
        "\n",
        "**C√≥mo aprender:**\n",
        "- HashiCorp Terraform Associate Certification\n",
        "- \"Terraform: Up & Running\" (libro)\n",
        "- Tiempo estimado: 3-4 meses\n",
        "\n",
        "**4. Monitoring y observabilidad (üî• Cr√≠tico)**\n",
        "\n",
        "**Stack t√≠pico:**\n",
        "- M√©tricas: Prometheus + Grafana\n",
        "- Logs: ELK stack (Elasticsearch, Logstash, Kibana) o CloudWatch\n",
        "- Tracing: Jaeger\n",
        "- ML-specific: Evidently AI, Arize\n",
        "\n",
        "**Qu√© monitorizar en ML:**\n",
        "- Input data distribution (data drift)\n",
        "- Prediction distribution (concept drift)\n",
        "- Model performance (accuracy, latency, throughput)\n",
        "- Infrastructure (CPU, RAM, GPU utilization)\n",
        "- Errors y excepciones\n",
        "\n",
        "**C√≥mo aprender:**\n",
        "- \"Prometheus & Grafana\" (Udemy)\n",
        "- Documentaci√≥n Evidently AI\n",
        "- Tiempo estimado: 3 meses\n",
        "\n",
        "**5. ML platforms y herramientas (‚≠ê‚≠ê‚≠ê Avanzado)**\n",
        "\n",
        "**Herramientas que debes conocer:**\n",
        "- MLflow: experiment tracking, model registry\n",
        "- Kubeflow: pipelines y serving en K8s\n",
        "- Feast: feature store\n",
        "- Seldon Core: model serving en K8s\n",
        "- DVC: versionado de datos\n",
        "\n",
        "**Tiempo:** 4-6 meses (aprenderlas mientras trabajas)\n",
        "\n",
        "#### Herramientas del MLOps Engineer\n",
        "\n",
        "| Categor√≠a | Herramientas prioritarias |\n",
        "|-----------|--------------------------|\n",
        "| **Containers** | Docker, Kubernetes (cr√≠tico) |\n",
        "| **CI/CD** | GitHub Actions, GitLab CI, Jenkins |\n",
        "| **IaC** | Terraform, Pulumi |\n",
        "| **Monitoring** | Prometheus, Grafana, Evidently |\n",
        "| **Cloud** | AWS/GCP/Azure (managed ML services) |\n",
        "| **ML Platforms** | MLflow, Kubeflow, SageMaker/Vertex AI |\n",
        "| **Feature Store** | Feast, Tecton |\n",
        "| **Serving** | Seldon Core, KServe, TensorFlow Serving |\n",
        "\n",
        "**Prioridad de aprendizaje:**\n",
        "1. Kubernetes (4-6 meses)\n",
        "2. CI/CD (3 meses)\n",
        "3. Terraform (3 meses)\n",
        "4. Monitoring (3 meses)\n",
        "5. ML platforms (4-6 meses, progresivo)\n",
        "6. Conocimientos ML b√°sicos (2-3 meses)\n",
        "\n",
        "**Total: 20-26 meses** (asumiendo background en DevOps)\n",
        "\n",
        "**Atajo:** Si ya eres DevOps/SRE, necesitas +6-9 meses para aprender ML tooling. Si eres Data Engineer, necesitas +12-18 meses para profundizar en Kubernetes y DevOps.\n",
        "\n",
        "---\n",
        "\n",
        "### 3.6 Data Architect\n",
        "\n",
        "#### Habilidades t√©cnicas core\n",
        "\n",
        "El Data Architect necesita **amplitud sobre profundidad**. Debe conocer muchas tecnolog√≠as sin necesariamente implementarlas √©l mismo.\n",
        "\n",
        "**1. Dise√±o de arquitecturas de datos (üî• Cr√≠tico)**\n",
        "\n",
        "**Qu√© necesitas dominar:**\n",
        "- Patrones arquitect√≥nicos (Lambda, Kappa, Data Mesh, Lakehouse)\n",
        "- Trade-offs entre arquitecturas\n",
        "- CAP theorem y consistencia distribuida\n",
        "- Escalabilidad vertical vs horizontal\n",
        "- Data modeling (dimensional, 3NF, Data Vault)\n",
        "\n",
        "**Habilidades de dise√±o:**\n",
        "- Diagramas de arquitectura (C4 model, UML)\n",
        "- Documentaci√≥n t√©cnica\n",
        "- POCs (Proof of Concepts)\n",
        "- Cost modeling\n",
        "\n",
        "**C√≥mo desarrollar:**\n",
        "- Experiencia como Data Engineer (5-7 a√±os m√≠nimo)\n",
        "- Estudiar arquitecturas de empresas l√≠deres (blogs de Netflix, Uber, Airbnb)\n",
        "- Certificaciones de arquitectura cloud\n",
        "- Tiempo: Es un rol de evoluci√≥n, no de formaci√≥n inicial\n",
        "\n",
        "**2. Conocimiento profundo de bases de datos (üî• Cr√≠tico)**\n",
        "\n",
        "**Debes conocer:**\n",
        "\n",
        "**SQL:**\n",
        "- PostgreSQL, MySQL (transaccionales)\n",
        "- Redshift, Snowflake, BigQuery (warehouses)\n",
        "\n",
        "**NoSQL:**\n",
        "- MongoDB (documentos)\n",
        "- Cassandra (column-family)\n",
        "- Redis (key-value)\n",
        "- Neo4j (grafos)\n",
        "\n",
        "**Y saber cu√°ndo usar cada una:**\n",
        "- Transaccional: PostgreSQL\n",
        "- Analytics: Snowflake/BigQuery\n",
        "- Caching: Redis\n",
        "- Time-series: InfluxDB\n",
        "- Logs: Elasticsearch\n",
        "\n",
        "**C√≥mo aprender:**\n",
        "- Implementar proyectos con cada tipo\n",
        "- Tiempo: Varios a√±os de experiencia\n",
        "\n",
        "**3. Cloud platforms (üî• Cr√≠tico - Multi-cloud awareness)**\n",
        "\n",
        "**Debes conocer los servicios equivalentes en AWS/GCP/Azure:**\n",
        "\n",
        "| Servicio | AWS | GCP | Azure |\n",
        "|----------|-----|-----|-------|\n",
        "| **Object Storage** | S3 | Cloud Storage | Blob Storage |\n",
        "| **Data Warehouse** | Redshift | BigQuery | Synapse |\n",
        "| **Data Lake** | Lake Formation | Dataplex | Data Lake Storage |\n",
        "| **Spark** | EMR | Dataproc | HDInsight |\n",
        "| **Streaming** | Kinesis | Dataflow | Event Hubs |\n",
        "| **ETL** | Glue | Dataflow | Data Factory |\n",
        "\n",
        "**Certificaciones recomendadas:**\n",
        "- AWS Solutions Architect Professional\n",
        "- Google Cloud Professional Data Engineer\n",
        "- Azure Data Engineer Associate\n",
        "\n",
        "**Tiempo:** 2-3 a√±os trabajando con cloud\n",
        "\n",
        "**4. Gobernanza y seguridad (üî• Cr√≠tico)**\n",
        "\n",
        "**Qu√© necesitas saber:**\n",
        "- GDPR, CCPA y compliance\n",
        "- Data classification (PII, sensitive data)\n",
        "- Encryption (at rest, in transit)\n",
        "- Access control (RBAC, ABAC)\n",
        "- Data lineage y auditing\n",
        "- Data quality frameworks\n",
        "\n",
        "**Herramientas:**\n",
        "- Data catalogs: Alation, Collibra, Apache Atlas\n",
        "- Data quality: Great Expectations, dbt tests\n",
        "- Lineage: OpenLineage, DataHub\n",
        "\n",
        "**C√≥mo aprender:**\n",
        "- Certificaciones de seguridad (CISSP m√≥dulos de datos)\n",
        "- Experiencia pr√°ctica implementando gobernanza\n",
        "- Tiempo: 2-3 a√±os\n",
        "\n",
        "**5. Soft skills (üî• Cr√≠tico - m√°s importante que t√©cnicas)**\n",
        "\n",
        "**Habilidades esenciales:**\n",
        "- **Comunicaci√≥n:** Explicar arquitecturas complejas a C-level\n",
        "- **Liderazgo t√©cnico:** Guiar a equipos de Data Engineers\n",
        "- **Gesti√≥n de stakeholders:** Equilibrar necesidades t√©cnicas y de negocio\n",
        "- **Visi√≥n estrat√©gica:** Planificar 2-3 a√±os adelante\n",
        "- **Toma de decisiones:** Elegir tecnolog√≠as con impacto duradero\n",
        "- **Documentaci√≥n:** Escribir ADRs (Architecture Decision Records)\n",
        "\n",
        "**C√≥mo desarrollar:**\n",
        "- Presentar en meetups/conferencias\n",
        "- Mentorizar junior engineers\n",
        "- Participar en decisiones estrat√©gicas\n",
        "- Tiempo: Se desarrolla con experiencia senior\n",
        "\n",
        "#### Herramientas del Data Architect\n",
        "\n",
        "| Categor√≠a | Conocimiento requerido |\n",
        "|-----------|------------------------|\n",
        "| **Bases de datos** | PostgreSQL, MySQL, MongoDB, Cassandra, Redis |\n",
        "| **Data Warehouses** | Snowflake, BigQuery, Redshift |\n",
        "| **Data Lakes** | S3, Delta Lake, Iceberg, Hudi |\n",
        "| **Procesamiento** | Spark, Flink, dbt |\n",
        "| **Streaming** | Kafka, Kinesis, Pub/Sub |\n",
        "| **Gobernanza** | Alation, Collibra, Atlas |\n",
        "| **Diagramas** | Lucidchart, Draw.io, Miro |\n",
        "| **Cloud** | AWS, GCP, Azure (multi-cloud) |\n",
        "\n",
        "**Camino para llegar a Data Architect:**\n",
        "1. Data Engineer (5-7 a√±os)\n",
        "2. Senior Data Engineer liderando proyectos (2-3 a√±os)\n",
        "3. Data Architect\n",
        "\n",
        "**Total: 7-10 a√±os de experiencia en datos**\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Soft skills cr√≠ticas por rol\n",
        "\n",
        "### Tabla de soft skills\n",
        "\n",
        "| Soft Skill | Por qu√© es importante | Roles m√°s cr√≠ticos |\n",
        "|------------|----------------------|-------------------|\n",
        "| **Comunicaci√≥n** | Traducir hallazgos t√©cnicos a lenguaje de negocio | Analyst, Architect |\n",
        "| **Curiosidad** | Hacer las preguntas correctas, explorar datos | Analyst, Scientist |\n",
        "| **Pensamiento cr√≠tico** | Validar asunciones, detectar sesgos | Scientist, Architect |\n",
        "| **Colaboraci√≥n** | Trabajar con equipos multidisciplinares | ML Engineer, MLOps |\n",
        "| **Atenci√≥n al detalle** | Detectar errores en datos o c√≥digo | Engineer, Scientist |\n",
        "| **Resoluci√≥n de problemas** | Debugging, optimizaci√≥n | Todos los roles |\n",
        "| **Gesti√≥n del tiempo** | Priorizar entre m√∫ltiples stakeholders | Analyst, Engineer |\n",
        "| **Storytelling** | Narrar insights de forma convincente | Analyst |\n",
        "| **Empat√≠a t√©cnica** | Entender necesidades de otros equipos | MLOps, Architect |\n",
        "| **Aprendizaje continuo** | Tecnolog√≠as cambian constantemente | Todos los roles |\n",
        "\n",
        "### C√≥mo desarrollar soft skills\n",
        "\n",
        "**Comunicaci√≥n:**\n",
        "- Presenta tus proyectos a personas no t√©cnicas\n",
        "- Escribe blog posts explicando conceptos\n",
        "- Practica storytelling con datos\n",
        "\n",
        "**Pensamiento cr√≠tico:**\n",
        "- Cuestiona tus propios an√°lisis\n",
        "- Busca explicaciones alternativas\n",
        "- Peer review con colegas\n",
        "\n",
        "**Colaboraci√≥n:**\n",
        "- Participa en code reviews\n",
        "- Pair programming\n",
        "- Proyectos open source\n",
        "\n",
        "**Resoluci√≥n de problemas:**\n",
        "- Debugging sistem√°tico\n",
        "- Root cause analysis\n",
        "- Documentar soluciones\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Roadmaps de aprendizaje visuales\n",
        "\n",
        "### Roadmap: Data Analyst (10-16 meses)\n",
        "\n",
        "```\n",
        "Mes 0-3: SQL b√°sico + Excel\n",
        "    ‚Üì\n",
        "Mes 3-6: SQL avanzado (window functions, optimization)\n",
        "    ‚Üì\n",
        "Mes 6-9: Tableau o Power BI + Estad√≠stica descriptiva\n",
        "    ‚Üì\n",
        "Mes 9-12: Python b√°sico (Pandas) + Proyectos personales\n",
        "    ‚Üì\n",
        "Mes 12-16: Portfolio + B√∫squeda de empleo\n",
        "\n",
        "Proyecto final: Dashboard completo de an√°lisis de e-commerce\n",
        "```\n",
        "\n",
        "### Roadmap: Data Scientist (18-24 meses)\n",
        "\n",
        "```\n",
        "Mes 0-6: Python + Matem√°ticas (paralelo)\n",
        "    ‚Üì\n",
        "Mes 6-12: Machine Learning (teor√≠a + pr√°ctica)\n",
        "    ‚Üì\n",
        "Mes 12-15: Kaggle competitions + Deep Learning\n",
        "    ‚Üì\n",
        "Mes 15-18: SQL + proyectos end-to-end\n",
        "    ‚Üì\n",
        "Mes 18-24: Portfolio + Especializaci√≥n (NLP o CV) + Job search\n",
        "\n",
        "Proyecto final: Sistema completo de predicci√≥n con deployment\n",
        "```\n",
        "\n",
        "### Roadmap: Data Engineer (18-24 meses)\n",
        "\n",
        "```\n",
        "Mes 0-6: Python + SQL avanzado\n",
        "    ‚Üì\n",
        "Mes 6-10: Cloud (AWS/GCP) + Docker\n",
        "    ‚Üì\n",
        "Mes 10-16: Spark + Airflow\n",
        "    ‚Üì\n",
        "Mes 16-20: Proyectos completos de pipelines\n",
        "    ‚Üì\n",
        "Mes 20-24: Portfolio + Certificaci√≥n cloud + Job search\n",
        "\n",
        "Proyecto final: Data pipeline end-to-end con orquestaci√≥n\n",
        "```\n",
        "\n",
        "### Roadmap: ML Engineer (24-30 meses desde cero)\n",
        "\n",
        "**Opci√≥n A (desde Data Scientist):**\n",
        "```\n",
        "Base: Data Scientist (18 meses)\n",
        "    ‚Üì\n",
        "+ 6 meses: Docker + Kubernetes + APIs (FastAPI)\n",
        "    ‚Üì\n",
        "+ 3 meses: Model serving + Feature stores\n",
        "    ‚Üì\n",
        "+ 3 meses: Cloud ML platforms\n",
        "\n",
        "Total: 30 meses\n",
        "```\n",
        "\n",
        "**Opci√≥n B (desde Data Engineer):**\n",
        "```\n",
        "Base: Data Engineer (18 meses)\n",
        "    ‚Üì\n",
        "+ 6 meses: Machine Learning (Scikit-learn, XGBoost)\n",
        "    ‚Üì\n",
        "+ 3 meses: Deep Learning (PyTorch/TensorFlow)\n",
        "    ‚Üì\n",
        "+ 3 meses: Model serving + optimization\n",
        "\n",
        "Total: 30 meses\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Recursos de aprendizaje recomendados\n",
        "\n",
        "### Plataformas generales\n",
        "\n",
        "**MOOCs (Massive Open Online Courses):**\n",
        "- **Coursera:** Especializaciones de universidades (Stanford, Imperial College)\n",
        "- **edX:** Similar a Coursera\n",
        "- **DataCamp:** Interactivo, ideal para SQL y Python\n",
        "- **Udacity:** Nanodegrees (m√°s caros pero completos)\n",
        "- **Udemy:** Cursos espec√≠ficos (variable en calidad)\n",
        "\n",
        "**Pr√°ctica:**\n",
        "- **Kaggle:** Competitions + Datasets + Learn\n",
        "- **LeetCode:** SQL y algoritmos\n",
        "- **HackerRank:** Challenges de SQL, Python\n",
        "- **DataLemur:** SQL para entrevistas\n",
        "\n",
        "**Libros (todos gratuitos online):**\n",
        "- \"An Introduction to Statistical Learning\" - ML te√≥rico\n",
        "- \"Hands-On Machine Learning\" (Aur√©lien G√©ron) - ML pr√°ctico\n",
        "- \"Designing Data-Intensive Applications\" (Martin Kleppmann) - Arquitecturas\n",
        "- \"The Data Warehouse Toolkit\" (Ralph Kimball) - Data modeling\n",
        "\n",
        "### Recursos espec√≠ficos por habilidad\n",
        "\n",
        "**SQL:**\n",
        "- Mode Analytics SQL Tutorial\n",
        "- SQLZoo\n",
        "- \"SQL for Data Analysis\" (Cathy Tanimura)\n",
        "\n",
        "**Python:**\n",
        "- \"Python for Data Analysis\" (Wes McKinney - creador de Pandas)\n",
        "- Real Python (blog)\n",
        "\n",
        "**Machine Learning:**\n",
        "- \"Machine Learning\" - Andrew Ng (Coursera) - imprescindible\n",
        "- Fast.ai - Practical Deep Learning\n",
        "- Kaggle Learn\n",
        "\n",
        "**Cloud:**\n",
        "- AWS Skill Builder (gratuito)\n",
        "- Google Cloud Skills Boost\n",
        "- Microsoft Learn (Azure)\n",
        "\n",
        "**Spark:**\n",
        "- Databricks Academy (gratuito)\n",
        "- \"Spark: The Definitive Guide\"\n",
        "\n",
        "**MLOps:**\n",
        "- \"MLOps Specialization\" (DeepLearning.AI, Coursera)\n",
        "- \"Made With ML\" (madewithml.com)\n",
        "\n",
        "### Certificaciones que valen la pena\n",
        "\n",
        "**Cloud (muy valoradas):**\n",
        "- ‚úÖ AWS Certified Solutions Architect Associate\n",
        "- ‚úÖ Google Cloud Professional Data Engineer\n",
        "- ‚úÖ Azure Data Engineer Associate\n",
        "\n",
        "**Kubernetes:**\n",
        "- ‚úÖ CKA (Certified Kubernetes Administrator)\n",
        "\n",
        "**BI:**\n",
        "- ‚úÖ Tableau Desktop Specialist\n",
        "- ‚úÖ Power BI Data Analyst Associate\n",
        "\n",
        "**Menos prioritarias (aprender haciendo es mejor):**\n",
        "- ‚ùå Certificaciones vendor-specific de herramientas nicho\n",
        "- ‚ùå Certificaciones \"Data Scientist\" gen√©ricas sin prestigio\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Consejos pr√°cticos para acelerar el aprendizaje\n",
        "\n",
        "### 1. Aprende haciendo proyectos, no cursos infinitos\n",
        "\n",
        "**‚ùå Error:** Ver 10 cursos de Python sin escribir c√≥digo\n",
        "\n",
        "**‚úÖ Correcto:** Curso b√°sico de Python ‚Üí Proyecto personal ‚Üí Aprender lo que necesitas sobre la marcha\n",
        "\n",
        "### 2. Build in public\n",
        "\n",
        "**Qu√© hacer:**\n",
        "- Crea un GitHub con tus proyectos\n",
        "- Escribe posts en LinkedIn/Medium explicando lo que aprendes\n",
        "- Contribuye a proyectos open source\n",
        "\n",
        "**Beneficios:**\n",
        "- Portfolio visible para recruiters\n",
        "- Aprendes m√°s al ense√±ar\n",
        "- Networking\n",
        "\n",
        "### 3. Especial√≠zate progresivamente\n",
        "\n",
        "**Evoluci√≥n t√≠pica:**\n",
        "1. Aprende lo b√°sico de todo (6 meses)\n",
        "2. Identifica qu√© disfrutas m√°s\n",
        "3. Especial√≠zate en eso (12-18 meses)\n",
        "4. Consigue primer trabajo\n",
        "5. Hiperespecial√≠zate seg√∫n necesidades del trabajo\n",
        "\n",
        "### 4. √önete a comunidades\n",
        "\n",
        "**D√≥nde:**\n",
        "- Discord de Data Science / Machine Learning\n",
        "- Slack de dbt, Airflow\n",
        "- Meetups locales de datos\n",
        "- Subreddits: r/datascience, r/dataengineering\n",
        "\n",
        "**Beneficio:** Aprender de experiencias de otros, resolver dudas r√°pido, job leads\n",
        "\n",
        "### 5. No necesitas saber todo antes de aplicar\n",
        "\n",
        "**Realidad:**\n",
        "- Para junior: 60-70% de las habilidades del rol\n",
        "- Para mid: 70-85%\n",
        "- Para senior: 85%+\n",
        "\n",
        "**Aprender√°s mucho en el trabajo. Aplica aunque no cumplas 100% requisitos del job posting.**\n",
        "\n",
        "### 6. Prioriza habilidades transferibles\n",
        "\n",
        "**Habilidades que sirven para todos los roles:**\n",
        "- SQL (cr√≠tico para todos)\n",
        "- Python (casi todos)\n",
        "- Git\n",
        "- Pensamiento anal√≠tico\n",
        "- Comunicaci√≥n\n",
        "\n",
        "**Habilidades hyper-espec√≠ficas pueden quedar obsoletas.**\n",
        "\n",
        "---\n",
        "\n",
        "## 8. Errores comunes al aprender\n",
        "\n",
        "### Error 1: Tutorial hell\n",
        "\n",
        "**Problema:** Ver cursos infinitamente sin practicar\n",
        "\n",
        "**Soluci√≥n:** Regla 20/80: 20% teor√≠a, 80% pr√°ctica\n",
        "\n",
        "### Error 2: Querer aprender todas las herramientas\n",
        "\n",
        "**Problema:** Intentar dominar Python, R, Julia, Scala simult√°neamente\n",
        "\n",
        "**Soluci√≥n:** Profundidad en una herramienta > amplitud superficial en todas\n",
        "\n",
        "### Error 3: No construir portfolio\n",
        "\n",
        "**Problema:** Aprender mucho pero no tener nada que mostrar\n",
        "\n",
        "**Soluci√≥n:** 3-5 proyectos completos en GitHub > 20 certificados\n",
        "\n",
        "### Error 4: Copiar c√≥digo sin entender\n",
        "\n",
        "**Problema:** Copy-paste de Stack Overflow sin comprender\n",
        "\n",
        "**Soluci√≥n:** Escribir c√≥digo l√≠nea por l√≠nea, debuggear a prop√≥sito\n",
        "\n",
        "### Error 5: Ignorar los fundamentos\n",
        "\n",
        "**Problema:** Saltar directo a Deep Learning sin entender estad√≠stica\n",
        "\n",
        "**Soluci√≥n:** Fundamentos s√≥lidos permiten aprender avanzado m√°s r√°pido\n",
        "\n",
        "### Error 6: No practicar entrevistas t√©cnicas\n",
        "\n",
        "**Problema:** Saber la teor√≠a pero fallar en entrevistas\n",
        "\n",
        "**Soluci√≥n:** Practicar SQL en LeetCode, explicar proyectos en voz alta\n",
        "\n",
        "---\n",
        "\n",
        "## 9. Conceptos clave\n",
        "\n",
        "- **Core t√©cnico:** 3-5 habilidades cr√≠ticas que definen cada rol\n",
        "- **SQL:** Habilidad universal, cr√≠tica para Analyst y Engineer\n",
        "- **Python:** Lenguaje dominante en Data Science y Engineering\n",
        "- **Soft skills:** Igual de importantes que t√©cnicas, especialmente comunicaci√≥n\n",
        "- **Portfolio:** Proyectos visibles valen m√°s que certificados\n",
        "- **Especializaci√≥n progresiva:** Amplitud inicial ‚Üí Profundidad en el rol elegido\n",
        "- **Aprender haciendo:** 80% pr√°ctica, 20% teor√≠a\n",
        "- **Roadmap:** 10-16 meses (Analyst), 18-24 meses (Scientist/Engineer)\n",
        "- **Experiencia:** Architect y MLOps son roles de evoluci√≥n (7-10 a√±os)\n",
        "- **Comunidad:** Aprender en p√∫blico y conectar con otros acelera el aprendizaje\n",
        "\n",
        "---\n",
        "\n",
        "## Resumen\n",
        "\n",
        "Cada rol en el ecosistema de datos requiere un conjunto espec√≠fico de habilidades t√©cnicas y soft skills con diferentes niveles de profundidad. No existe el \"profesional de datos gen√©rico\" que domine todo.\n",
        "\n",
        "El **Data Analyst** necesita SQL avanzado, herramientas de BI y comunicaci√≥n excepcional. El **Data Scientist** requiere Python, estad√≠stica avanzada y machine learning profundo. El **Data Engineer** domina SQL, Spark, cloud y orquestaci√≥n. El **ML Engineer** combina ML con ingenier√≠a de software para producci√≥n. El **MLOps Engineer** es DevOps especializado en ML. El **Data Architect** necesita a√±os de experiencia y visi√≥n estrat√©gica.\n",
        "\n",
        "La clave del √©xito es identificar qu√© rol se alinea con tus intereses y fortalezas, dominar el **core t√©cnico** de ese rol (3-5 habilidades cr√≠ticas), y construir un **portfolio de proyectos** que demuestre tu capacidad. Los roadmaps de aprendizaje var√≠an desde 10-16 meses para Analyst hasta 24-30 meses para ML Engineer, y roles como Architect requieren 7-10 a√±os de experiencia.\n",
        "\n",
        "Las soft skills ‚Äîcomunicaci√≥n, pensamiento cr√≠tico, colaboraci√≥n‚Äî son tan importantes como las t√©cnicas y se desarrollan practicando. La especializaci√≥n progresiva (amplitud inicial ‚Üí profundidad en tu rol) combinada con aprender haciendo proyectos reales (no tutorial hell) es el camino m√°s eficiente. Construye en p√∫blico, √∫nete a comunidades, y aplica a trabajos aunque no cumplas el 100% de requisitos. El aprendizaje contin√∫a toda la carrera: las tecnolog√≠as evolucionan, pero los fundamentos s√≥lidos permiten adaptarse r√°pidamente.\n",
        "\n",
        "---\n",
        "\n",
        "## Referencias\n",
        "\n",
        "### Roadmaps interactivos\n",
        "- [Data Analyst Roadmap](https://roadmap.sh/data-analyst)\n",
        "- [Data Engineer Roadmap](https://roadmap.sh/data-engineer)\n",
        "- [MLOps Roadmap](https://roadmap.sh/mlops)\n",
        "\n",
        "### Plataformas de aprendizaje\n",
        "- [DataCamp](https://www.datacamp.com/) - Cursos interactivos\n",
        "- [Kaggle Learn](https://www.kaggle.com/learn) - Gratuito y pr√°ctico\n",
        "- [Coursera](https://www.coursera.org/) - Especializaciones universitarias\n",
        "- [Fast.ai](https://www.fast.ai/) - Deep Learning pr√°ctico y gratuito\n",
        "\n",
        "### Pr√°ctica\n",
        "- [LeetCode Database](https://leetcode.com/problemset/database/) - SQL practice\n",
        "- [DataLemur](https://datalemur.com/) - SQL para entrevistas\n",
        "- [HackerRank](https://www.hackerrank.com/) - Challenges variados\n",
        "- [Kaggle Competitions](https://www.kaggle.com/competitions) - ML pr√°ctica\n",
        "\n",
        "### Libros (gratuitos online)\n",
        "- [An Introduction to Statistical Learning (ISL)](https://www.statlearning.com/)\n",
        "- [Designing Data-Intensive Applications](https://dataintensive.net/)\n",
        "- [The Data Warehouse Toolkit](https://www.kimballgroup.com/)\n",
        "\n",
        "### Certificaciones\n",
        "- [AWS Certified Solutions Architect](https://aws.amazon.com/certification/certified-solutions-architect-associate/)\n",
        "- [Google Cloud Professional Data Engineer](https://cloud.google.com/certification/data-engineer)\n",
        "- [Tableau Desktop Specialist](https://www.tableau.com/learn/certification/desktop-specialist)\n",
        "- [CKA - Kubernetes](https://www.cncf.io/certification/cka/)\n",
        "\n",
        "### V√≠deos\n",
        "- [How to Learn Data Science in 2025](https://www.youtube.com/results?search_query=how+to+learn+data+science)\n",
        "- [Data Engineering Roadmap](https://www.youtube.com/results?search_query=data+engineering+roadmap)\n",
        "- [SQL Tutorial for Beginners - Full Course](https://www.youtube.com/results?search_query=sql+full+course)\n",
        "- [What I Wish I Knew Before Becoming a Data Scientist](https://www.youtube.com/results?search_query=before+becoming+data+scientist)"
      ],
      "metadata": {
        "id": "GhyZT-5GY4xj"
      }
    }
  ]
}