{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/financieras/big_data/blob/main/retos/retos_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 120 RETOS DE DATA\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 1: FUNDAMENTOS Y CARGA DE DATOS (Retos 1-10)**\n",
        "\n",
        "### Reto 1. Gestión de archivos en Google Colab\n",
        "- Objetivo: Familiarizarse con la interfaz de Colab y la gestión básica de archivos\n",
        "- Descarga manualmente el dataset `Titanic` desde Kaggle\n",
        "- Sube el archivo manualmente a Google Colab\n",
        "- Carga el dataset usando Pandas\n",
        "- Visualiza las primeras 5 filas con `.head()`\n",
        "- Monta Google Drive y verifica persistencia\n",
        "\n",
        "### Reto 2. Carga directa desde URL y análisis exploratorio\n",
        "- Carga Titanic desde URL con Pandas\n",
        "- Verifica con `.shape` y `.head()`\n",
        "- Explora tipos de datos con `.dtypes`, valores nulos con `.isnull().sum()` y estadísticas descriptivas con `.describe()`\n",
        "\n",
        "### Reto 3. Datasets embebidos y análisis de supervivencia\n",
        "- Carga Titanic desde Seaborn: `sns.load_dataset('titanic')`\n",
        "- Calcula proporción de supervivientes por sexo usando `.groupby(['sex'])['survived'].mean()`\n",
        "- Calcula proporción de supervivientes por clase\n",
        "- Crea gráfico de barras con estas proporciones\n",
        "\n",
        "### Reto 4. Limpieza básica de datos\n",
        "- Carga Titanic desde Seaborn: `sns.load_dataset('titanic')`\n",
        "- Identifica valores nulos en Titanic con `.isnull().sum()`\n",
        "- Rellena \"age\" con mediana: `df['age'].fillna(df['age'].median(), inplace=True)`\n",
        "- Elimina columna \"deck\": `df.drop('deck', axis=1, inplace=True)`\n",
        "- Crea columna \"family_size\" = sibsp + parch + 1\n",
        "\n",
        "### Reto 5. Filtros y consultas básicas\n",
        "- Carga Titanic desde Seaborn: `sns.load_dataset('titanic')`\n",
        "- Filtra pasajeros de primera clase que sobrevivieron: `df[(df['class']=='First') & (df['survived']==1)]`\n",
        "- Encuentra pasajero más joven con `df.loc[df['age'].idxmin()]`\n",
        "- Encuentra pasajero más viejo\n",
        "- Calcula tarifa promedio por clase con `.groupby('class')['fare'].mean()`\n",
        "\n",
        "### Reto 6. Dataset \"Iris\" desde Seaborn\n",
        "- Carga Iris desde Seaborn: `sns.load_dataset('iris')`\n",
        "- Explora estructura con `.shape`, `.info()`, `.columns`\n",
        "- Verifica valores nulos\n",
        "- Calcula número de observaciones por especie con `.value_counts()`\n",
        "\n",
        "### Reto 7. Estadísticas descriptivas y pairplot\n",
        "- Carga Iris desde Seaborn: `sns.load_dataset('iris')`\n",
        "- Calcula media de todas las columnas numéricas con `.mean()`\n",
        "- Calcula desviación estándar con `.std()`\n",
        "- Calcula estadísticas por especie: `df.groupby('species').mean()`\n",
        "- Crea pairplot coloreado por especie: `sns.pairplot(df, hue='species')`\n",
        "\n",
        "### Reto 8. Correlaciones y mapa de calor\n",
        "- Carga Iris desde Seaborn: `sns.load_dataset('iris')`\n",
        "- Selecciona solo columnas numéricas de Iris\n",
        "- Calcula matriz de correlación con `.corr()`\n",
        "- Visualiza con heatmap: `sns.heatmap(corr, annot=True, cmap='coolwarm')`\n",
        "- Identifica las dos variables más correlacionadas\n",
        "\n",
        "### Reto 9. Clasificación con regla simple\n",
        "- Carga Iris desde Seaborn: `sns.load_dataset('iris')`\n",
        "- Crea regla: si petal_length < 2.5 → setosa, si < 5.0 → versicolor, sino → virginica\n",
        "- Crea nueva columna 'prediccion' con esta regla\n",
        "- Compara con columna 'species' real\n",
        "- Calcula precisión: `(df['prediccion'] == df['species']).mean()`\n",
        "\n",
        "### Reto 10. Visualización avanzada con boxplot y violinplot\n",
        "- Carga Iris desde Seaborn: `sns.load_dataset('iris')`\n",
        "- Crea boxplot de sepal_width por especie\n",
        "- Crea violinplot de la misma variable\n",
        "- Identifica especie con mayor mediana de sepal_width\n",
        "- Identifica especie con mayor variabilidad\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 2: ANÁLISIS EXPLORATORIO Y VISUALIZACIÓN (Retos 11-25)**\n",
        "\n",
        "### Reto 11. Dataset \"Breast Cancer\" desde scikit-learn\n",
        "```python\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "import pandas as pd\n",
        "\n",
        "data = load_breast_cancer()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "df['diagnosis'] = df['target'].map({0: 'malignant', 1: 'benign'})\n",
        "```\n",
        "- Explora dimensiones con `.shape`\n",
        "- Verifica balance entre clases con `.value_counts()`\n",
        "- Calcula porcentaje de cada diagnóstico\n",
        "\n",
        "### Reto 12. Análisis de características médicas\n",
        "- Carga el dataset \"Breast Cancer\" desde scikit-learn\n",
        "- Calcula estadísticas descriptivas por diagnóstico: `df.groupby('diagnosis').mean()`\n",
        "- Identifica las 5 características con mayor diferencia entre malignos y benignos\n",
        "- Crea histograma de 'mean radius' separado por diagnóstico usando `hue='diagnosis'`\n",
        "\n",
        "### Reto 13. Correlaciones en datos médicos\n",
        "- Carga el dataset \"Breast Cancer\" desde scikit-learn\n",
        "- Calcula matriz de correlación de las primeras 10 características\n",
        "- Encuentra qué características están más correlacionadas con 'worst radius'\n",
        "- Visualiza con heatmap las primeras 10 características\n",
        "\n",
        "### Reto 14. Dataset Tips desde Seaborn\n",
        "- Carga dataset: `sns.load_dataset('tips')`\n",
        "- Explora estructura y variables con `.info()`\n",
        "- Crea columna 'tip_pct' = (tip / total_bill) * 100\n",
        "- Calcula tip_pct promedio del dataset\n",
        "\n",
        "### Reto 15. Análisis de patrones de propinas\n",
        "- Carga el dataset: `sns.load_dataset('tips')`\n",
        "- Calcula propina promedio por día: `df.groupby('day')['tip'].mean()`\n",
        "- Calcula propina promedio por día y sexo\n",
        "- Identifica qué combinación día-sexo deja más propina\n",
        "- Crea boxplot de tip_pct por día\n",
        "\n",
        "### Reto 16. Relación cuenta-propina\n",
        "- Carga el dataset: `sns.load_dataset('tips')`\n",
        "- Crea scatterplot de total_bill vs tip\n",
        "- Calcula correlación entre ambas variables con `.corr()`\n",
        "- Crea scatterplot separado por sexo usando `hue='sex'`\n",
        "- ¿Qué sexo muestra mayor correlación?\n",
        "\n",
        "### Reto 17. Creación de nuevas columnas en Iris\n",
        "- Carga Iris desde Seaborn: `sns.load_dataset('iris')`\n",
        "- Crea 'sepal_area' = sepal_length * sepal_width\n",
        "- Crea 'petal_area' = petal_length * petal_width\n",
        "- Calcula área promedio de pétalos por especie\n",
        "- Identifica especie con pétalos más grandes en promedio\n",
        "\n",
        "### Reto 18. Ordenación y selección\n",
        "- Carga Iris desde Seaborn: `sns.load_dataset('iris')`\n",
        "- Ordena Iris por petal_length de menor a mayor con `.sort_values()`\n",
        "- Muestra las primeras 10 filas con `.head(10)`\n",
        "- Muestra las últimas 10 filas con `.tail(10)`\n",
        "- Extrae solo columnas de pétalos: `df[['petal_length', 'petal_width']]`\n",
        "\n",
        "### Reto 19. Agrupaciones y agregaciones\n",
        "- Carga Iris desde Seaborn: `sns.load_dataset('iris')`\n",
        "- Usa groupby en Iris para calcular media, máximo y mínimo de sepal_length por especie\n",
        "- Cuenta número de observaciones por especie\n",
        "- Crea gráfico de barras con media de sepal_length por especie\n",
        "- Añade título y etiquetas al gráfico\n",
        "\n",
        "### Reto 20. Filtrado combinado\n",
        "- Carga Iris desde Seaborn: `sns.load_dataset('iris')`\n",
        "- Filtra flores con sepal_length > 6 AND petal_width < 1.5\n",
        "- Cuenta cuántas flores cumplen la condición\n",
        "- Identifica qué especies están en este subconjunto\n",
        "- Crea scatterplot de sepal_length vs petal_width de estas flores\n",
        "\n",
        "### Reto 21. Normalización min-max\n",
        "- Carga Iris desde Seaborn: `sns.load_dataset('iris')`\n",
        "- Normaliza sepal_length usando fórmula: (x - min) / (max - min)\n",
        "- Verifica que los valores estén entre 0 y 1 con `.min()` y `.max()`\n",
        "- Normaliza también petal_length\n",
        "- Crea scatterplot de versiones normalizadas\n",
        "\n",
        "### Reto 22. Dataset Penguins desde Seaborn\n",
        "- Carga: `sns.load_dataset('penguins')`\n",
        "- Explora valores nulos por columna\n",
        "- Elimina filas con valores nulos: `df.dropna()`\n",
        "- Identifica las 3 especies diferentes\n",
        "\n",
        "### Reto 23. Análisis morfológico de pingüinos\n",
        "- Carga: `sns.load_dataset('penguins')`\n",
        "- Calcula peso promedio (body_mass_g) por especie\n",
        "- Calcula peso promedio por especie y sexo\n",
        "- Identifica especie con mayor peso promedio\n",
        "- Crea scatterplot de flipper_length_mm vs body_mass_g coloreado por especie\n",
        "\n",
        "### Reto 24. Distribución geográfica de pingüinos\n",
        "- Carga: `sns.load_dataset('penguins')`\n",
        "- Crea boxplot de body_mass_g por island\n",
        "- Identifica isla con pingüinos más pesados en promedio\n",
        "- Crea tabla cruzada de especies por isla: `pd.crosstab(df['species'], df['island'])`\n",
        "- ¿Qué especie está en las tres islas?\n",
        "\n",
        "### Reto 25. Exportación a múltiples formatos\n",
        "- Carga Iris desde Seaborn: `sns.load_dataset('iris')`\n",
        "- Guarda Iris (con columnas calculadas) en CSV: `df.to_csv('iris_modified.csv', index=False)`\n",
        "- Guarda en Excel: `df.to_excel('iris_modified.xlsx', index=False)`\n",
        "- Guarda en JSON: `df.to_json('iris_modified.json', orient='records')`\n",
        "- Verifica carga correcta de cada formato\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 3: OPERACIONES CON DATOS Y TRANSFORMACIONES (Retos 26-45)**\n",
        "\n",
        "### Reto 26. Tablas cruzadas en Titanic\n",
        "- Carga Titanic desde Seaborn: `sns.load_dataset('titanic')`\n",
        "- Crea tabla cruzada entre sex y class: `pd.crosstab(df['sex'], df['class'])`\n",
        "- Crea tabla cruzada con survived como valores y aggfunc='mean'\n",
        "- Interpreta: ¿qué combinación sexo-clase tiene mayor tasa de supervivencia?\n",
        "- Visualiza con heatmap\n",
        "\n",
        "### Reto 27. Dataset Diamonds desde Seaborn\n",
        "- Carga: `sns.load_dataset('diamonds')`\n",
        "- Explora dimensiones y primeras filas\n",
        "- Identifica variables categóricas: cut, color, clarity\n",
        "- Calcula estadísticas descriptivas de price\n",
        "\n",
        "### Reto 28. Análisis de precios por calidad\n",
        "- Carga: `sns.load_dataset('diamonds')`\n",
        "- Calcula precio promedio por cut\n",
        "- Calcula precio promedio por color\n",
        "- Identifica combinación cut-color más costosa con `.groupby(['cut','color'])['price'].mean()`\n",
        "- Crea scatterplot de carat vs price coloreado por cut\n",
        "\n",
        "### Reto 29. Detección y eliminación de duplicados\n",
        "- Carga Iris desde Seaborn: `sns.load_dataset('iris')`\n",
        "- Duplica artificialmente primeras 10 filas: `df = pd.concat([df, df.head(10)])`\n",
        "- Cuenta duplicados con `.duplicated().sum()`\n",
        "- Elimina duplicados: `df.drop_duplicates()`\n",
        "- Verifica nuevo tamaño del dataset\n",
        "\n",
        "### Reto 30. Dataset Flights desde Seaborn\n",
        "- Carga: `sns.load_dataset('flights')`\n",
        "- Explora estructura temporal (year, month, passengers)\n",
        "- Identifica rango de años incluido\n",
        "- Identifica todos los meses únicos\n",
        "\n",
        "### Reto 31. Análisis de tráfico aéreo\n",
        "- Carga: `sns.load_dataset('flights')`\n",
        "- Agrupa por año y calcula total de pasajeros: `df.groupby('year')['passengers'].sum()`\n",
        "- Crea gráfico de líneas de evolución temporal\n",
        "- Calcula tasa de crecimiento entre primer y último año\n",
        "- ¿En qué año se superaron los 400 pasajeros totales?\n",
        "\n",
        "### Reto 32. Mapa de calor mensual\n",
        "- Carga: `sns.load_dataset('flights')`\n",
        "- Crea tabla pivote: `df.pivot(index='month', columns='year', values='passengers')`\n",
        "- Crea heatmap con anotaciones: `sns.heatmap(pivot, annot=True, fmt='d', cmap='YlOrRd')`\n",
        "- Identifica mes con más tráfico consistente a lo largo de los años\n",
        "- ¿Qué mes tiene menos tráfico?\n",
        "\n",
        "### Reto 33. Dataset MPG desde Seaborn\n",
        "- Carga: `sns.load_dataset('mpg')`\n",
        "- Explora variables (mpg, cylinders, horsepower, weight, etc.)\n",
        "- Calcula consumo promedio (mpg) por número de cylinders\n",
        "- Identifica origen de los coches (origin)\n",
        "\n",
        "### Reto 34. Análisis de eficiencia vehicular\n",
        "- Carga: `sns.load_dataset('mpg')`\n",
        "- Filtra solo coches de 4 cilindros\n",
        "- Calcula mpg promedio por origin en estos coches\n",
        "- Crea scatterplot de weight vs mpg\n",
        "- Calcula correlación entre weight y mpg\n",
        "\n",
        "### Reto 35. Manipulación de texto en MPG\n",
        "- Carga: `sns.load_dataset('mpg')`\n",
        "- Extrae marca del coche (primera palabra de 'name'): `df['brand'] = df['name'].str.split().str[0]`\n",
        "- Cuenta coches por marca con `.value_counts()`\n",
        "- Identifica las 5 marcas con más modelos\n",
        "- Calcula mpg promedio por marca (top 5)\n",
        "\n",
        "### Reto 36. Tablas pivot avanzadas\n",
        "- Carga: `sns.load_dataset('flights')`\n",
        "- Con flights, crea tabla pivot año-mes como en Reto 32\n",
        "- Calcula pasajeros promedio por mes (promedio entre todos los años)\n",
        "- Identifica julio de 1955: ¿cuántos pasajeros hubo?\n",
        "- Calcula crecimiento de pasajeros entre enero y diciembre de cada año\n",
        "\n",
        "### Reto 37. Operación melt (formato ancho a largo)\n",
        "- Toma la tabla pivot del Reto 36\n",
        "- Aplica melt para volver a formato largo: `pd.melt(pivot.reset_index(), id_vars=['month'])`\n",
        "- Verifica que coincide con estructura original\n",
        "- Cuenta cuántas filas tiene cada formato\n",
        "\n",
        "### Reto 38. Dataset Planets desde Seaborn\n",
        "- Carga: `sns.load_dataset('planets')`\n",
        "- Explora métodos de descubrimiento (method)\n",
        "- Cuenta exoplanetas descubiertos por cada método\n",
        "- Identifica los 5 métodos más comunes\n",
        "\n",
        "### Reto 39. Análisis de exoplanetas\n",
        "- Carga: `sns.load_dataset('planets')`\n",
        "- Calcula masa promedio por método (ignora nulos)\n",
        "- Calcula año promedio de descubrimiento por método\n",
        "- Usa `.agg()` para calcular múltiples funciones: `df.groupby('method').agg({'mass': 'mean', 'year': 'mean', 'number': 'count'})`\n",
        "- ¿Qué método tiene exoplanetas más masivos en promedio?\n",
        "\n",
        "### Reto 40. Combinación con merge\n",
        "- Crea DataFrame auxiliar con información ficticia de islas:\n",
        "```python\n",
        "island_info = pd.DataFrame({\n",
        "    'island': ['Torgersen', 'Biscoe', 'Dream'],\n",
        "    'country': ['Antarctica', 'Antarctica', 'Antarctica'],\n",
        "    'area_km2': [15, 40, 25]\n",
        "})\n",
        "```\n",
        "- Carga: `sns.load_dataset('penguins')`\n",
        "- Combina con merge: `pd.merge(penguins, island_info, on='island')`\n",
        "- Verifica número de filas resultante\n",
        "- Calcula densidad de pingüinos por km2 por isla\n",
        "\n",
        "### Reto 41. Concatenación vertical\n",
        "- Carga el dataset: `sns.load_dataset('tips')`\n",
        "- En tips, filtra solo filas de Saturday: `sat = df[df['day']=='Sat']`\n",
        "- Filtra solo filas de Sunday: `sun = df[df['day']=='Sun']`\n",
        "- Concatena verticalmente: `pd.concat([sat, sun])`\n",
        "- Verifica que total de filas = suma de ambos\n",
        "\n",
        "### Reto 42. Análisis de cuartiles e IQR\n",
        "- Carga: `sns.load_dataset('diamonds')`\n",
        "- En diamonds, calcula Q1, Q2 (mediana), Q3 de price con `.quantile([0.25, 0.5, 0.75])`\n",
        "- Calcula IQR = Q3 - Q1\n",
        "- Define límites outliers: inferior = Q1 - 1.5*IQR, superior = Q3 + 1.5*IQR\n",
        "- Cuenta cuántos diamantes son outliers de precio\n",
        "\n",
        "### Reto 43. Cálculo de sesgo (skewness)\n",
        "- Carga: `sns.load_dataset('diamonds')`\n",
        "- Usa `from scipy.stats import skew`\n",
        "- Calcula sesgo de price en diamonds: `skew(df['price'])`\n",
        "- Interpreta: valor positivo indica asimetría hacia derecha\n",
        "- Crea histograma de price para visualizar el sesgo\n",
        "\n",
        "### Reto 44. Visualización: swarmplot\n",
        "- Carga: `sns.load_dataset('penguins')`\n",
        "- En penguins (sin nulos), crea swarmplot de body_mass_g por species\n",
        "- Compara visualmente con boxplot de la misma variable\n",
        "- Identifica outliers individuales fácilmente\n",
        "- ¿Qué especie tiene mayor dispersión de pesos?\n",
        "\n",
        "### Reto 45. Visualización: violinplot\n",
        "- Carga el dataset: `sns.load_dataset('tips')`\n",
        "- En tips, crea violinplot de tip_pct por day\n",
        "- Identifica día con distribución más ancha (mayor dispersión)\n",
        "- Identifica día con distribución bimodal (dos picos) si existe\n",
        "- Compara con boxplot de la misma variable\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 4: SERIES TEMPORALES Y DATASETS COMPLEJOS (Retos 46-60)**\n",
        "\n",
        "### Reto 46. Dataset de Temperaturas Globales (Berkeley Earth)\n",
        "- Carga desde URL: `https://raw.githubusercontent.com/datasets/global-temp/master/data/annual.csv`\n",
        "- Explora columnas: Year, Mean\n",
        "- Filtra datos desde 1900 en adelante\n",
        "- Crea gráfico de líneas de temperatura media por año\n",
        "\n",
        "### Reto 47. Análisis de cambio climático\n",
        "- Carga desde URL: `https://raw.githubusercontent.com/datasets/global-temp/master/data/annual.csv`\n",
        "- Calcula temperatura media del período 1900-1950\n",
        "- Calcula temperatura media del período 1970-2020\n",
        "- Calcula diferencia entre ambos períodos\n",
        "- Identifica el año más cálido registrado desde 1900\n",
        "\n",
        "### Reto 48. Media móvil en series temporales\n",
        "- Carga desde URL: `https://raw.githubusercontent.com/datasets/global-temp/master/data/annual.csv`\n",
        "- Con temperaturas globales, calcula media móvil de 10 años: `df['MA_10'] = df['Mean'].rolling(window=10).mean()`\n",
        "- Crea gráfico con temperatura original y media móvil\n",
        "- ¿La media móvil suaviza las fluctuaciones?\n",
        "- Calcula también media móvil de 30 años\n",
        "\n",
        "### Reto 49. Dataset COVID-19 (Our World in Data)\n",
        "- Carga desde URL: `https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv`\n",
        "- Filtra solo datos de Spain\n",
        "- Extrae columnas: date, total_cases, total_deaths\n",
        "- Convierte 'date' a formato datetime\n",
        "\n",
        "### Reto 50. Análisis temporal de COVID en España\n",
        "- Carga desde URL: `https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv`\n",
        "- Calcula nuevos casos diarios: `df['new_cases'] = df['total_cases'].diff()`\n",
        "- Identifica día con más casos nuevos\n",
        "- Calcula media móvil de 7 días de casos nuevos\n",
        "- Crea gráfico de casos nuevos con media móvil\n",
        "\n",
        "### Reto 51. Extracción de componentes de fecha\n",
        "- Carga desde URL: `https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv`\n",
        "- En COVID España, extrae mes y año de 'date'\n",
        "- Agrupa por mes-año y calcula total de casos nuevos\n",
        "- Identifica mes con más casos\n",
        "- Crea gráfico de barras de casos por mes\n",
        "\n",
        "### Reto 52. Dataset Anscombe desde Seaborn\n",
        "- Carga: `sns.load_dataset('anscombe')`\n",
        "- Explora los 4 datasets (I, II, III, IV)\n",
        "- Calcula media y varianza de x e y para cada dataset\n",
        "- Crea 4 scatterplots (uno por dataset) en la misma figura\n",
        "\n",
        "### Reto 53. Lección estadística de Anscombe\n",
        "- Carga: `sns.load_dataset('anscombe')`\n",
        "- Calcula correlación entre x e y para cada dataset\n",
        "- Observa que las 4 tienen estadísticas casi idénticas\n",
        "- Compara con los gráficos del Reto 52\n",
        "- Identifica dataset con outlier claro y dataset con relación no lineal\n",
        "\n",
        "### Reto 54. Normalización Z-score\n",
        "- Carga Iris desde Seaborn: `sns.load_dataset('iris')`\n",
        "- En Iris, calcula Z-score de sepal_length: `(df['sepal_length'] - df['sepal_length'].mean()) / df['sepal_length'].std()`\n",
        "- Verifica que media ≈ 0 con `.mean()`\n",
        "- Verifica que std ≈ 1 con `.std()`\n",
        "- Compara distribución original vs normalizada con histogramas\n",
        "\n",
        "### Reto 55. Análisis de títulos en Titanic\n",
        "- Carga Titanic desde Seaborn: `sns.load_dataset('titanic')`\n",
        "- Extrae título del nombre: `df['title'] = df['name'].str.extract(' ([A-Za-z]+)\\.', expand=False)`\n",
        "- Cuenta pasajeros por título con `.value_counts()`\n",
        "- Identifica títulos raros (< 10 ocurrencias)\n",
        "- Calcula tasa de supervivencia por título\n",
        "\n",
        "### Reto 56. Dataset Car Crashes desde Seaborn\n",
        "- Carga: `sns.load_dataset('car_crashes')`\n",
        "- Explora variables por estado de USA\n",
        "- Identifica estado con más accidentes totales (total)\n",
        "- Crea ranking de top 10 estados por total de accidentes\n",
        "\n",
        "### Reto 57. Correlación alcohol-accidentes\n",
        "- Carga: `sns.load_dataset('car_crashes')`\n",
        "- Crea scatterplot de alcohol vs total en car_crashes\n",
        "- Calcula correlación entre ambas variables\n",
        "- Identifica estado con mayor consumo de alcohol\n",
        "- ¿Este estado también tiene muchos accidentes?\n",
        "\n",
        "### Reto 58. Dataset de Poblaciones (Gapminder)\n",
        "- Carga: `sns.load_dataset('gapminder')`\n",
        "- Explora variables: country, continent, year, lifeExp, pop, gdpPercap\n",
        "- Identifica países y años incluidos\n",
        "- Calcula población mundial por año\n",
        "\n",
        "### Reto 59. Análisis de desarrollo por continente\n",
        "- Carga: `sns.load_dataset('gapminder')`\n",
        "- Filtra solo año 2007\n",
        "- Agrupa por continente y calcula promedios de lifeExp y gdpPercap\n",
        "- Identifica continente con mayor esperanza de vida\n",
        "- Calcula correlación entre gdpPercap y lifeExp\n",
        "\n",
        "### Reto 60. Evolución temporal en Gapminder\n",
        "- Carga: `sns.load_dataset('gapminder')`\n",
        "- Filtra datos de Spain a lo largo del tiempo\n",
        "- Crea gráfico de líneas de lifeExp por año\n",
        "- Crea gráfico de líneas de gdpPercap por año\n",
        "- Calcula crecimiento porcentual de gdpPercap entre 1952 y 2007\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 5: DATOS DEL MUNDO REAL Y WEB (Retos 61-80)**\n",
        "\n",
        "### Reto 61. Dataset Wine Quality desde UCI\n",
        "- Carga desde URL: `https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv`\n",
        "- Nota: usar `sep=';'` en read_csv\n",
        "- Explora características físico-químicas\n",
        "- Identifica vinos con quality > 7\n",
        "\n",
        "### Reto 62. Correlaciones en vinos\n",
        "- Carga desde URL: `https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv`\n",
        "- Calcula matriz de correlación de todas las variables\n",
        "- Crea heatmap con anotaciones\n",
        "- Identifica variable más correlacionada con quality\n",
        "- ¿alcohol está correlacionado con quality?\n",
        "\n",
        "### Reto 63. Dataset de Estudiantes (UCI Student Performance)\n",
        "- Carga desde URL: `https://raw.githubusercontent.com/uci-ml-repo/ucimlrepo/main/docs/assets/student_performance_math.csv`\n",
        "- Explora variables demográficas y académicas\n",
        "- Calcula nota promedio (G3) por sexo\n",
        "- Calcula nota promedio por nivel educativo de los padres (Medu, Fedu)\n",
        "\n",
        "### Reto 64. Análisis de factores académicos\n",
        "- Carga desde URL: `https://raw.githubusercontent.com/uci-ml-repo/ucimlrepo/main/docs/assets/student_performance_math.csv`\n",
        "- Crea variable 'studytime_bin' categorizando studytime en 'bajo', 'medio', 'alto'\n",
        "- Compara G3 promedio por categoría de studytime\n",
        "- Crea boxplot de G3 por studytime_bin\n",
        "- ¿Estudiar más tiempo correlaciona con mejores notas?\n",
        "\n",
        "### Reto 65. Dataset de Países (REST Countries API simulado)\n",
        "```python\n",
        "# Usar dataset pre-descargado de países\n",
        "url = 'https://raw.githubusercontent.com/samayo/country-json/master/src/country-by-population.json'\n",
        "df = pd.read_json(url)\n",
        "```\n",
        "- Explora estructura: country, population\n",
        "- Identifica los 10 países más poblados\n",
        "- Calcula población mundial total\n",
        "- Calcula población promedio por país\n",
        "\n",
        "### Reto 66. Dataset de Capitales\n",
        "```python\n",
        "url = 'https://raw.githubusercontent.com/samayo/country-json/master/src/country-by-capital-city.json'\n",
        "df_capitals = pd.read_json(url)\n",
        "```\n",
        "- Combina con dataset de población del Reto 65\n",
        "- Usa merge para crear dataset completo país-capital-población\n",
        "- Identifica capitales de países más poblados\n",
        "\n",
        "### Reto 67. Dataset Earthquakes (USGS - últimos 30 días)\n",
        "```python\n",
        "url = 'https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_month.csv'\n",
        "df = pd.read_csv(url)\n",
        "```\n",
        "- Explora variables: time, latitude, longitude, mag, place\n",
        "- Filtra terremotos con magnitud > 4.5\n",
        "- Identifica terremoto más fuerte del mes\n",
        "\n",
        "### Reto 68. Análisis sísmico\n",
        "```python\n",
        "url = 'https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_month.csv'\n",
        "df = pd.read_csv(url)\n",
        "```\n",
        "- Calcula media y desviación estándar de magnitudes\n",
        "- Crea histograma de distribución de magnitudes\n",
        "- Identifica el país/región con más terremotos (extraer de 'place')\n",
        "- Calcula cuántos terremotos ocurrieron en la última semana\n",
        "\n",
        "### Reto 69. Dataset de Intercambio de Divisas\n",
        "```python\n",
        "# Usar API gratuita de exchangerate-api\n",
        "url = 'https://open.er-api.com/v6/latest/USD'\n",
        "import requests\n",
        "data = requests.get(url).json()\n",
        "rates = pd.DataFrame(list(data['rates'].items()), columns=['currency', 'rate'])\n",
        "```\n",
        "- Explora tasas de cambio desde USD\n",
        "- Identifica las 10 monedas con mayor valor frente al USD\n",
        "- Calcula cuántos EUR equivalen a 100 USD\n",
        "\n",
        "### Reto 70. Conversión de monedas\n",
        "```python\n",
        "# Usar API gratuita de exchangerate-api\n",
        "url = 'https://open.er-api.com/v6/latest/USD'\n",
        "import requests\n",
        "data = requests.get(url).json()\n",
        "rates = pd.DataFrame(list(data['rates'].items()), columns=['currency', 'rate'])\n",
        "```\n",
        "- Crea función que convierta cualquier cantidad de USD a otra moneda\n",
        "- Calcula equivalencias de 1000 USD en: EUR, GBP, JPY, MXN\n",
        "- Crea DataFrame con estas conversiones\n",
        "- Ordena monedas por valor de mayor a menor\n",
        "\n",
        "### Reto 71. Dataset de Lenguajes de Programación\n",
        "```python\n",
        "url = 'https://raw.githubusercontent.com/datasets/awesome-data/master/programming-languages.csv'\n",
        "# Si no está disponible, usar alternativa de GitHub similar\n",
        "```\n",
        "- Explora variables: nombre, año de creación, paradigma\n",
        "- Identifica los 10 lenguajes más antiguos\n",
        "- Cuenta lenguajes por década de creación\n",
        "- Identifica paradigma más común\n",
        "\n",
        "### Reto 72. Web Scraping: Tabla HTML simple\n",
        "```python\n",
        "url = 'https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)'\n",
        "tables = pd.read_html(url)\n",
        "df = tables[1]  # Segunda tabla suele ser la correcta\n",
        "```\n",
        "- Extrae tabla de GDP de países desde Wikipedia\n",
        "- Limpia nombres de columnas\n",
        "- Identifica top 10 países por GDP\n",
        "- Calcula GDP promedio de top 20\n",
        "\n",
        "### Reto 73. Dataset de Feriados (Nager.Date API)\n",
        "```python\n",
        "url = 'https://date.nager.at/api/v3/PublicHolidays/2024/ES'\n",
        "df = pd.read_json(url)\n",
        "```\n",
        "- Explora feriados de España en 2024\n",
        "- Cuenta cuántos feriados hay\n",
        "- Identifica mes con más feriados\n",
        "- Extrae solo nombre y fecha de cada feriado\n",
        "\n",
        "### Reto 74. Dataset de Universidades\n",
        "```python\n",
        "url = 'https://raw.githubusercontent.com/Hipo/university-domains-list/master/world_universities_and_domains.json'\n",
        "df = pd.read_json(url)\n",
        "```\n",
        "- Filtra universidades de Spain\n",
        "- Cuenta cuántas universidades españolas hay en el dataset\n",
        "- Identifica las 10 primeras universidades de la lista\n",
        "- Extrae dominios web de universidades españolas\n",
        "\n",
        "### Reto 75. Limpieza de texto avanzada\n",
        "- Carga el dataset: `sns.load_dataset('tips')`\n",
        "- En tips, convierte 'sex' a minúsculas: `df['sex'] = df['sex'].str.lower()`\n",
        "- Elimina espacios con `.str.strip()`\n",
        "- Verifica categorías únicas con `.unique()`\n",
        "- Reemplaza valores si hay inconsistencias\n",
        "\n",
        "### Reto 76. Dataset de Datos Abiertos (Data.gov simulado)\n",
        "```python\n",
        "# Usar dataset de calidad del aire\n",
        "url = 'https://data.cityofnewyork.us/api/views/c3uy-2p5r/rows.csv?accessType=DOWNLOAD'\n",
        "df = pd.read_csv(url)\n",
        "```\n",
        "- Explora variables de calidad del aire NYC\n",
        "- Filtra datos más recientes\n",
        "- Calcula promedio de contaminantes\n",
        "- Identifica áreas con peor calidad del aire\n",
        "\n",
        "### Reto 77. Análisis de calidad del aire\n",
        "```python\n",
        "# Usar dataset de calidad del aire\n",
        "url = 'https://data.cityofnewyork.us/api/views/c3uy-2p5r/rows.csv?accessType=DOWNLOAD'\n",
        "df = pd.read_csv(url)\n",
        "```\n",
        "- Agrupa por borough y calcula promedio de contaminantes\n",
        "- Identifica borough con mejor calidad del aire\n",
        "- Crea gráfico de barras comparativo\n",
        "- Filtra días con niveles peligrosos (si aplica)\n",
        "\n",
        "### Reto 78. Dataset de Bibliotecas JSON anidado\n",
        "```python\n",
        "data = {\n",
        "    'students': [\n",
        "        {'name': 'Ana', 'grades': {'math': 85, 'science': 92}},\n",
        "        {'name': 'Luis', 'grades': {'math': 78, 'science': 88}},\n",
        "        {'name': 'María', 'grades': {'math': 95, 'science': 89}}\n",
        "    ]\n",
        "}\n",
        "df = pd.json_normalize(data['students'])\n",
        "```\n",
        "- Aplana estructura JSON anidada\n",
        "- Calcula promedio de cada estudiante\n",
        "- Identifica estudiante con mejor promedio\n",
        "- Calcula nota promedio por materia\n",
        "\n",
        "### Reto 79. Exportación condicional\n",
        "- Carga: `sns.load_dataset('diamonds')`\n",
        "- En diamonds, filtra diamantes con price > 15000\n",
        "- Filtra diamantes \"Ideal\" cut\n",
        "- Combina ambos filtros con operador &\n",
        "- Guarda resultado en CSV: `filtered.to_csv('expensive_ideal_diamonds.csv', index=False)`\n",
        "\n",
        "### Reto 80. Dataset de Pronóstico del Tiempo (Open-Meteo)\n",
        "```python\n",
        "url = 'https://api.open-meteo.com/v1/forecast?latitude=40.4168&longitude=-3.7038&daily=temperature_2m_max,temperature_2m_min&timezone=Europe/Madrid'\n",
        "import requests\n",
        "data = requests.get(url).json()\n",
        "df = pd.DataFrame(data['daily'])\n",
        "```\n",
        "- Extrae pronóstico de 7 días para Madrid\n",
        "- Crea DataFrame con fechas y temperaturas\n",
        "- Calcula temperatura promedio de la semana\n",
        "- Identifica día más cálido y más frío\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 6: INGENIERÍA DE DATOS BÁSICA (Retos 81-95)**\n",
        "\n",
        "### Reto 81. Simulación de operaciones SQL con Pandas\n",
        "- Carga el dataset: `sns.load_dataset('tips')`\n",
        "- SELECT: selecciona columnas total_bill, tip, day\n",
        "- WHERE: filtra dinner meals: `df[df['time']=='Dinner']`\n",
        "- ORDER BY: ordena por total_bill descendente\n",
        "- Muestra primeras 10 filas del resultado\n",
        "\n",
        "### Reto 82. GROUP BY en Pandas\n",
        "- Carga el dataset: `sns.load_dataset('tips')`\n",
        "- En tips, agrupa por day y time\n",
        "- Calcula: COUNT, AVG(total_bill), SUM(tip) usando `.agg()`\n",
        "- Recrea query SQL: `SELECT day, time, COUNT(*), AVG(total_bill), SUM(tip) FROM tips GROUP BY day, time`\n",
        "- Identifica combinación día-hora con más ventas\n",
        "\n",
        "### Reto 83. JOIN simulado con Pandas\n",
        "- Crea dos DataFrames:\n",
        "```python\n",
        "customers = pd.DataFrame({\n",
        "    'customer_id': [1, 2, 3, 4],\n",
        "    'name': ['Ana', 'Luis', 'María', 'Carlos']\n",
        "})\n",
        "orders = pd.DataFrame({\n",
        "    'order_id': [101, 102, 103],\n",
        "    'customer_id': [1, 2, 1],\n",
        "    'amount': [50, 75, 30]\n",
        "})\n",
        "```\n",
        "- Realiza INNER JOIN: `pd.merge(customers, orders, on='customer_id')`\n",
        "- Realiza LEFT JOIN con `how='left'`\n",
        "- Identifica cliente sin órdenes\n",
        "\n",
        "### Reto 84. Subconsultas simuladas\n",
        "- Carga: `sns.load_dataset('penguins')`\n",
        "- En penguins, calcula peso promedio general\n",
        "- Filtra pingüinos con peso mayor al promedio\n",
        "- Equivale a SQL: `SELECT * FROM penguins WHERE body_mass_g > (SELECT AVG(body_mass_g) FROM penguins)`\n",
        "- Cuenta cuántos pingüinos están sobre el promedio\n",
        "\n",
        "### Reto 85. HAVING simulado\n",
        "- Carga el dataset: `sns.load_dataset('tips')`\n",
        "- En tips, agrupa por smoker y day\n",
        "- Calcula total_bill promedio por grupo\n",
        "- Filtra solo grupos con promedio > 20\n",
        "- Equivale a: `SELECT smoker, day, AVG(total_bill) FROM tips GROUP BY smoker, day HAVING AVG(total_bill) > 20`\n",
        "\n",
        "### Reto 86. DISTINCT y COUNT DISTINCT\n",
        "- Carga Titanic desde Seaborn: `sns.load_dataset('titanic')`\n",
        "- En titanic, cuenta valores únicos de embark_town: `df['embark_town'].nunique()`\n",
        "- Cuenta combinaciones únicas de class y sex\n",
        "- Usa `.drop_duplicates()` para obtener filas únicas\n",
        "- Compara tamaño original vs sin duplicados\n",
        "\n",
        "### Reto 87. CASE WHEN simulado con np.where\n",
        "```python\n",
        "import numpy as np\n",
        "```\n",
        "- Carga: `sns.load_dataset('penguins')`\n",
        "- En penguins, crea columna 'size_category':\n",
        "- Si body_mass_g < 3500: 'Small'\n",
        "- Si entre 3500-4500: 'Medium'\n",
        "- Si > 4500: 'Large'\n",
        "- Usa `np.where()` o `pd.cut()`\n",
        "- Cuenta pingüinos por categoría\n",
        "\n",
        "### Reto 88. Window Functions: Ranking\n",
        "- Carga: `sns.load_dataset('diamonds')`\n",
        "- En diamonds, ordena por price descendente\n",
        "- Crea columna 'price_rank' con ranking: `df['price_rank'] = df['price'].rank(ascending=False)`\n",
        "- Identifica los 10 diamantes más caros\n",
        "- Calcula percentil de precio de cada diamante\n",
        "\n",
        "### Reto 89. Window Functions: Media móvil\n",
        "- Carga: `sns.load_dataset('flights')`\n",
        "- En flights, ordena por year y month\n",
        "- Calcula media móvil de 3 meses de passengers: `df['MA_3'] = df['passengers'].rolling(3).mean()`\n",
        "- Crea media móvil de 12 meses (año completo)\n",
        "- Compara valores originales vs suavizados\n",
        "\n",
        "### Reto 90. CTEs simulados con variables\n",
        "- Simula CTE (Common Table Expression):\n",
        "```python\n",
        "# CTE: pasajeros que sobrevivieron\n",
        "cte_survivors = titanic[titanic['survived']==1]\n",
        "# Query principal: edad promedio de sobrevivientes\n",
        "avg_age = cte_survivors['age'].mean()\n",
        "```\n",
        "- Crea CTE de pasajeros de primera clase\n",
        "- Calcula tarifa promedio de este grupo\n",
        "- Compara con tarifa promedio general\n",
        "\n",
        "### Reto 91. UNION simulado\n",
        "- Carga el dataset: `sns.load_dataset('tips')`\n",
        "- En tips, filtra meals de Saturday: `sat = df[df['day']=='Sat']`\n",
        "- Filtra meals de Sunday: `sun = df[df['day']=='Sun']`\n",
        "- Une ambos con concat: `pd.concat([sat, sun])`\n",
        "- Elimina duplicados si los hay\n",
        "- Verifica tamaño final\n",
        "\n",
        "### Reto 92. Pipeline ETL básico - Extract\n",
        "- Simula extracción de múltiples fuentes:\n",
        "```python\n",
        "# Fuente 1: CSV local\n",
        "sales_q1 = pd.read_csv('sales_q1.csv')\n",
        "# Fuente 2: JSON\n",
        "sales_q2 = pd.read_json('sales_q2.json')\n",
        "# Fuente 3: Excel\n",
        "sales_q3 = pd.read_excel('sales_q3.xlsx')\n",
        "```\n",
        "- Para práctica, crea estos archivos artificialmente primero\n",
        "- Verifica que todos se carguen correctamente\n",
        "\n",
        "### Reto 93. Pipeline ETL - Transform\n",
        "- Con los 3 DataFrames del Reto 92:\n",
        "- Estandariza nombres de columnas a minúsculas\n",
        "- Convierte fechas a formato datetime\n",
        "- Elimina duplicados en cada uno\n",
        "- Crea columna 'quarter' en cada DataFrame\n",
        "\n",
        "### Reto 94. Pipeline ETL - Load\n",
        "- Concatena los 3 DataFrames transformados verticalmente\n",
        "- Ordena por fecha\n",
        "- Valida que no haya nulos en columnas críticas\n",
        "- Exporta resultado consolidado a CSV\n",
        "- Crea log simple: `print(f\"Filas procesadas: {len(df)}, Fecha: {datetime.now()}\")`\n",
        "\n",
        "### Reto 95. Validación de calidad de datos\n",
        "- Carga el dataset: `sns.load_dataset('tips')`\n",
        "- Crea validaciones:\n",
        "```python\n",
        "# Check 1: No nulos en columnas críticas\n",
        "assert df['total_bill'].notna().all(), \"Hay nulos en total_bill\"\n",
        "# Check 2: Valores positivos\n",
        "assert (df['total_bill'] > 0).all(), \"Hay valores negativos\"\n",
        "# Check 3: Tip no mayor que bill\n",
        "assert (df['tip'] <= df['total_bill']).all(), \"Propina mayor que cuenta\"\n",
        "```\n",
        "- Añade check de rango de valores\n",
        "- Crea función de validación reutilizable\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 7: ANÁLISIS AVANZADO Y DATOS COMPLEJOS (Retos 96-110)**\n",
        "\n",
        "### Reto 96. Detección de outliers con IQR\n",
        "- Carga: `sns.load_dataset('diamonds')`\n",
        "- En diamonds, calcula Q1, Q3 e IQR de carat\n",
        "- Define límites: `lower = Q1 - 1.5*IQR`, `upper = Q3 + 1.5*IQR`\n",
        "- Identifica outliers: `outliers = df[(df['carat'] < lower) | (df['carat'] > upper)]`\n",
        "- Calcula porcentaje de outliers\n",
        "- Visualiza con boxplot marcando outliers\n",
        "\n",
        "### Reto 97. Detección de outliers con Z-score\n",
        "- Carga: `sns.load_dataset('penguins')`\n",
        "- En penguins, calcula Z-score de body_mass_g\n",
        "- Identifica outliers (|Z| > 3)\n",
        "- Compara cantidad de outliers con método IQR\n",
        "- ¿Qué método es más estricto?\n",
        "\n",
        "### Reto 98. Análisis de outliers multivariante\n",
        "- Carga Iris desde Seaborn: `sns.load_dataset('iris')`\n",
        "- En iris, identifica outliers combinando:\n",
        "- petal_length > Q3 + 1.5*IQR\n",
        "- sepal_width < Q1 - 1.5*IQR\n",
        "- Usa operador & para condición compuesta\n",
        "- Visualiza outliers en scatterplot con color diferente\n",
        "\n",
        "### Reto 99. Imputación de valores nulos - Media/Mediana\n",
        "- Carga: `sns.load_dataset('penguins')`\n",
        "- Carga penguins (con nulos)\n",
        "- Crea 3 copias del dataset\n",
        "- Versión 1: elimina nulos con dropna()\n",
        "- Versión 2: imputa con media\n",
        "- Versión 3: imputa con mediana\n",
        "- Compara estadísticas descriptivas de las 3 versiones\n",
        "\n",
        "### Reto 100. Imputación de valores nulos - Forward Fill\n",
        "- Carga: `sns.load_dataset('flights')`\n",
        "- En series temporal de flights, introduce nulos artificiales:\n",
        "```python\n",
        "df_missing = df.copy()\n",
        "df_missing.loc[10:15, 'passengers'] = np.nan\n",
        "```\n",
        "- Aplica forward fill: `df_missing['passengers'].fillna(method='ffill')`\n",
        "- Aplica backward fill: `fillna(method='bfill')`\n",
        "- Compara ambos métodos visualmente\n",
        "\n",
        "### Reto 101. Análisis de sesgo y curtosis\n",
        "- Carga: `sns.load_dataset('diamonds')`\n",
        "```python\n",
        "from scipy.stats import skew, kurtosis\n",
        "```\n",
        "- Calcula sesgo de price en diamonds\n",
        "- Calcula curtosis de la misma variable\n",
        "- Interpreta: sesgo > 0 (asimetría derecha), curtosis > 3 (leptocúrtica)\n",
        "- Compara con distribución normal en histograma\n",
        "\n",
        "### Reto 102. Transformación logarítmica\n",
        "- Carga: `sns.load_dataset('diamonds')`\n",
        "- En diamonds, price está muy sesgado\n",
        "- Aplica transformación log: `df['log_price'] = np.log(df['price'])`\n",
        "- Compara histogramas de price vs log_price\n",
        "- Calcula nuevo sesgo de log_price\n",
        "- ¿La transformación normalizó la distribución?\n",
        "\n",
        "### Reto 103. Transformación Box-Cox\n",
        "- Carga: `sns.load_dataset('diamonds')`\n",
        "```python\n",
        "from scipy.stats import boxcox\n",
        "```\n",
        "- Aplica transformación Box-Cox a price en diamonds:\n",
        "```python\n",
        "transformed, lambda_param = boxcox(df['price'])\n",
        "df['boxcox_price'] = transformed\n",
        "```\n",
        "- Compara distribución original vs transformada\n",
        "- Box-Cox encuentra automáticamente mejor transformación\n",
        "\n",
        "### Reto 104. Binning de variables continuas\n",
        "- Carga Titanic desde Seaborn: `sns.load_dataset('titanic')`\n",
        "- En titanic, crea bins de edad:\n",
        "```python\n",
        "bins = [0, 12, 18, 35, 60, 100]\n",
        "labels = ['Niño', 'Adolescente', 'Adulto Joven', 'Adulto', 'Senior']\n",
        "df['age_group'] = pd.cut(df['age'], bins=bins, labels=labels)\n",
        "```\n",
        "- Calcula tasa de supervivencia por grupo de edad\n",
        "- Visualiza con gráfico de barras\n",
        "\n",
        "### Reto 105. Encoding de variables categóricas - Label Encoding\n",
        "- Carga: `sns.load_dataset('penguins')`\n",
        "- En penguins, convierte species a números:\n",
        "```python\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "df['species_encoded'] = le.fit_transform(df['species'])\n",
        "```\n",
        "- Verifica mapeo: Adelie=0, Chinstrap=1, Gentoo=2\n",
        "- Guarda mapeo para referencia futura\n",
        "\n",
        "### Reto 106. Encoding de variables categóricas - One-Hot Encoding\n",
        "- Carga: `sns.load_dataset('penguins')`\n",
        "- En penguins, aplica one-hot encoding a island:\n",
        "```python\n",
        "island_dummies = pd.get_dummies(df['island'], prefix='island')\n",
        "df = pd.concat([df, island_dummies], axis=1)\n",
        "```\n",
        "- Verifica que se crearon 3 columnas binarias\n",
        "- ¿Cuándo usar Label vs One-Hot encoding?\n",
        "\n",
        "### Reto 107. Feature Engineering - Interacciones\n",
        "- Carga el dataset: `sns.load_dataset('tips')`\n",
        "- En tips, crea features de interacción:\n",
        "```python\n",
        "df['bill_per_person'] = df['total_bill'] / df['size']\n",
        "df['tip_per_person'] = df['tip'] / df['size']\n",
        "df['tip_rate'] = df['tip'] / df['total_bill']\n",
        "```\n",
        "- Calcula correlación de nuevas features con tip\n",
        "- ¿Alguna feature nueva es más predictiva?\n",
        "\n",
        "### Reto 108. Feature Engineering - Fechas\n",
        "- Carga: `sns.load_dataset('flights')`\n",
        "- En flights, crea features temporales:\n",
        "```python\n",
        "df['month_sin'] = np.sin(2 * np.pi * df['month']/12)\n",
        "df['month_cos'] = np.cos(2 * np.pi * df['month']/12)\n",
        "```\n",
        "- Esto captura ciclicidad de meses\n",
        "- Visualiza relación entre estas features y passengers\n",
        "\n",
        "### Reto 109. Análisis de componentes principales (PCA) - Preparación\n",
        "- Carga Iris desde Seaborn: `sns.load_dataset('iris')`\n",
        "```python\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "```\n",
        "- Carga Iris desde Seaborn: `sns.load_dataset('iris')`\n",
        "- Selecciona solo columnas numéricas\n",
        "- Estandariza datos: `scaler = StandardScaler()` y `scaled = scaler.fit_transform(df_numeric)`\n",
        "- Verifica que media ≈ 0 y std ≈ 1\n",
        "- Prepara para PCA (siguiente reto)\n",
        "\n",
        "### Reto 110. Análisis de componentes principales (PCA)\n",
        "- Carga Iris desde Seaborn: `sns.load_dataset('iris')`\n",
        "```python\n",
        "from sklearn.decomposition import PCA\n",
        "```\n",
        "- Aplica PCA con 2 componentes: `pca = PCA(n_components=2)`\n",
        "- Transforma datos: `transformed = pca.fit_transform(scaled)`\n",
        "- Visualiza datos en 2D coloreados por especie\n",
        "- Imprime varianza explicada: `pca.explained_variance_ratio_`\n",
        "\n",
        "---\n",
        "\n",
        "## **BLOQUE 8: VISUALIZACIÓN AVANZADA (Retos 111-120)**\n",
        "\n",
        "### Reto 111. Subplots múltiples\n",
        "- Carga Iris desde Seaborn: `sns.load_dataset('iris')`\n",
        "- Crea figura con 4 subplots (2x2):\n",
        "```python\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "```\n",
        "- Plot 1: Histograma de sepal_length en iris\n",
        "- Plot 2: Scatterplot de sepal_length vs petal_length\n",
        "- Plot 3: Boxplot de petal_width por especie\n",
        "- Plot 4: Heatmap de correlaciones\n",
        "- Añade título general a la figura\n",
        "\n",
        "### Reto 112. Gráficos de distribución comparativos\n",
        "- Carga: `sns.load_dataset('penguins')`\n",
        "- En penguins, crea figura con 3 distribuciones:\n",
        "- Histograma de body_mass_g\n",
        "- KDE (Kernel Density Estimate) de body_mass_g\n",
        "- Histograma + KDE superpuestos\n",
        "- Usa `sns.histplot()` con `kde=True`\n",
        "\n",
        "### Reto 113. FacetGrid de Seaborn\n",
        "- Carga el dataset: `sns.load_dataset('tips')`\n",
        "- En tips, crea FacetGrid por time y smoker:\n",
        "```python\n",
        "g = sns.FacetGrid(df, col='time', row='smoker', height=4)\n",
        "g.map(plt.hist, 'total_bill')\n",
        "```\n",
        "- Añade títulos descriptivos\n",
        "- Analiza diferencias entre grupos\n",
        "\n",
        "### Reto 114. Pairplot avanzado con personalización\n",
        "- Carga: `sns.load_dataset('penguins')`\n",
        "- En penguins, crea pairplot con:\n",
        "- hue='species'\n",
        "- diag_kind='kde'\n",
        "- markers=['o', 's', 'D'] para cada especie\n",
        "- Personaliza paleta de colores\n",
        "- Añade título general\n",
        "\n",
        "### Reto 115. Gráfico de barras apiladas\n",
        "- Carga Titanic desde Seaborn: `sns.load_dataset('titanic')`\n",
        "- En titanic, crea tabla cruzada de class vs sex\n",
        "- Crea gráfico de barras apiladas:\n",
        "```python\n",
        "cross_tab = pd.crosstab(df['class'], df['sex'])\n",
        "cross_tab.plot(kind='bar', stacked=True)\n",
        "```\n",
        "- Añade leyenda, título y etiquetas\n",
        "- Analiza composición de género por clase\n",
        "\n",
        "### Reto 116. Gráfico de áreas apiladas\n",
        "- Carga: `sns.load_dataset('flights')`\n",
        "- En flights, agrupa por year y calcula total passengers\n",
        "- Simula diferentes categorías (crea columnas artificiales)\n",
        "- Crea gráfico de áreas apiladas:\n",
        "```python\n",
        "df.plot(kind='area', stacked=True)\n",
        "```\n",
        "- Útil para mostrar composición a lo largo del tiempo\n",
        "\n",
        "### Reto 117. Heatmap con anotaciones personalizadas\n",
        "- Carga: `sns.load_dataset('flights')`\n",
        "- En flights, crea pivot table de passengers por year-month\n",
        "- Crea heatmap con:\n",
        "```python\n",
        "sns.heatmap(pivot, annot=True, fmt='d', cmap='YlGnBu',\n",
        "            linewidths=0.5, linecolor='gray')\n",
        "```\n",
        "- Personaliza colorbar\n",
        "- Añade título descriptivo\n",
        "\n",
        "### Reto 118. Gráfico de regresión con intervalo de confianza\n",
        "- Carga el dataset: `sns.load_dataset('tips')`\n",
        "- En tips, crea regplot de total_bill vs tip:\n",
        "```python\n",
        "sns.regplot(x='total_bill', y='tip', data=df,\n",
        "            scatter_kws={'alpha':0.5},\n",
        "            line_kws={'color':'red'})\n",
        "```\n",
        "- Muestra banda de confianza\n",
        "- Añade ecuación de regresión en título\n",
        "\n",
        "### Reto 119. Jointplot para análisis bivariado\n",
        "- Carga: `sns.load_dataset('penguins')`\n",
        "- En penguins, crea jointplot de flipper_length vs body_mass:\n",
        "```python\n",
        "sns.jointplot(x='flipper_length_mm', y='body_mass_g',\n",
        "              data=df, kind='scatter', hue='species')\n",
        "```\n",
        "- Prueba diferentes kinds: 'hex', 'kde', 'reg'\n",
        "- Analiza distribuciones marginales\n",
        "\n",
        "### Reto 120. Dashboard visual completo - Proyecto Integrador Final\n",
        "- Carga: `sns.load_dataset('gapminder')`\n",
        "- Usa gapminder del año 2007\n",
        "- Crea figura con 6 subplots (2x3):\n",
        "\n",
        "**Plot 1:** Scatterplot de gdpPercap vs lifeExp, tamaño por pop, color por continent\n",
        "**Plot 2:** Gráfico de barras horizontales de lifeExp promedio por continente (ordenado)\n",
        "**Plot 3:** Boxplot de gdpPercap por continente\n",
        "**Plot 4:** Histograma de distribución de lifeExp con KDE\n",
        "**Plot 5:** Heatmap de correlación entre variables numéricas\n",
        "**Plot 6:** Top 10 países por gdpPercap (barras horizontales)\n",
        "\n",
        "- Añade título general: \"Análisis Global de Desarrollo 2007\"\n",
        "- Personaliza colores, etiquetas y leyendas\n",
        "- Guarda como imagen PNG de alta calidad: `plt.savefig('dashboard_final.png', dpi=300, bbox_inches='tight')`\n",
        "- **Reflexión final:** Escribe en comentarios 3 insights principales del análisis\n",
        "\n",
        "---\n",
        "\n",
        "# RESUMEN DE LOS 120 RETOS\n",
        "\n",
        "## Distribución por Bloques\n",
        "\n",
        "| Bloque | Retos | Enfoque Principal |\n",
        "|--------|-------|-------------------|\n",
        "| **1. Fundamentos y Carga** | 1-10 | Carga de datos, exploración básica, primeras visualizaciones |\n",
        "| **2. EDA y Visualización** | 11-25 | Análisis exploratorio, estadísticas, gráficos básicos |\n",
        "| **3. Operaciones y Transformaciones** | 26-45 | Manipulación de datos, agregaciones, transformaciones |\n",
        "| **4. Series Temporales** | 46-60 | Datos temporales, tendencias, análisis histórico |\n",
        "| **5. Datos del Mundo Real** | 61-80 | APIs, web scraping, datasets externos, JSON |\n",
        "| **6. Ingeniería de Datos** | 81-95 | SQL simulado, ETL, validación, pipelines |\n",
        "| **7. Análisis Avanzado** | 96-110 | Outliers, imputación, transformaciones, PCA |\n",
        "| **8. Visualización Avanzada** | 111-120 | Gráficos complejos, dashboard, proyecto final |\n",
        "\n",
        "## Fuentes de Datos Utilizadas (Públicas y Accesibles)\n",
        "\n",
        "### Datasets de Seaborn (16 datasets)\n",
        "- titanic, iris, tips, penguins, flights, diamonds, mpg, planets\n",
        "- anscombe, car_crashes, gapminder\n",
        "\n",
        "### Datasets de scikit-learn (2 datasets)\n",
        "- breast_cancer, (california_housing removido por complejidad)\n",
        "\n",
        "### URLs Públicas Verificadas (10+ datasets)\n",
        "- Global Temperature (Berkeley Earth)\n",
        "- COVID-19 (Our World in Data)\n",
        "- Wine Quality (UCI)\n",
        "- Student Performance (UCI)\n",
        "- Country Data (GitHub JSON)\n",
        "- Earthquakes (USGS)\n",
        "- Currency Exchange (open.er-api.com)\n",
        "- Weather Forecast (Open-Meteo)\n",
        "- Wikipedia Tables (web scraping)\n",
        "- Public Holidays (Nager.Date API)\n",
        "- Universities (GitHub JSON)\n",
        "\n",
        "### APIs Públicas Sin Autenticación (5 APIs)\n",
        "- Open-Meteo (clima)\n",
        "- USGS Earthquakes (terremotos)\n",
        "- Exchange Rates API (divisas)\n",
        "- Nager.Date (feriados)\n",
        "- Open Data portals (calidad del aire)\n",
        "\n",
        "## Cobertura del Temario\n",
        "\n",
        "| Área del Temario | Retos que la Cubren | Cobertura |\n",
        "|------------------|---------------------|-----------|\n",
        "| **Bloque 1: Ecosistema de Datos** | 1-10, 61-80 | ⭐⭐⭐⭐⭐ |\n",
        "| **Bloque 2: EDA y Visualización** | 11-45, 111-120 | ⭐⭐⭐⭐⭐ |\n",
        "| **Bloque 3: Estadística y Ciencia de Datos** | 46-60, 96-110 | ⭐⭐⭐⭐⭐ |\n",
        "| **Bloque 4: Ingeniería de Datos** | 81-95 | ⭐⭐⭐⭐⭐ |\n",
        "| **Bloque 5: Proyecto Integrador** | 120 | ⭐⭐⭐⭐⭐ |\n",
        "\n",
        "## Características Técnicas\n",
        "\n",
        "- **Total de retos:** 120\n",
        "- **Datasets únicos:** 35+\n",
        "- **APIs públicas:** 5\n",
        "- **Lenguajes/Herramientas:** Python, Pandas, NumPy, Matplotlib, Seaborn, Scikit-learn, SciPy\n",
        "- **Formatos de datos:** CSV, JSON, Excel, HTML, APIs REST\n",
        "- **Todos los recursos:** Públicos, gratuitos y verificados\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "TyCRRGZG6pAv"
      }
    }
  ]
}