{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBf/9qSa9o9v7OHGDBC53e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/financieras/big_data/blob/main/leccion_2_1_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lecci√≥n 2.1.3: Detecci√≥n de patrones y outliers\n",
        "\n",
        "## 1. El arte de encontrar lo extraordinario en lo ordinario\n",
        "\n",
        "Detectar patrones y outliers es como ser un **arque√≥logo de datos**: excavas capas de informaci√≥n para descubrir tesoros escondidos y anomal√≠as que cuentan historias importantes. Los patrones revelan \"c√≥mo funciona el mundo normal\", los outliers te muestran \"donde el mundo se rompe o innova\".\n",
        "\n",
        "> **Idea clave:** Un outlier no es un error‚Äîes una oportunidad disfrazada de anomal√≠a.\n",
        "\n",
        "**¬øPor qu√© dedicar tiempo a esto?**\n",
        "- üîç **Patrones** ‚Üí Predicci√≥n, automatizaci√≥n, comprensi√≥n del negocio\n",
        "- üö® **Outliers** ‚Üí Fraudes, errores, oportunidades, innovaciones\n",
        "\n",
        "**Ejemplo dram√°tico:** En 2012, un analista en Netflix detect√≥ un patr√≥n inusual: usuarios que ve√≠an series completas en 48 horas. Eran outliers estad√≠sticos, pero representaban un **nuevo comportamiento de consumo** que llev√≥ al desarrollo del binge-watching y cambi√≥ la industria del streaming.\n",
        "\n",
        "> **Advertencia cr√≠tica:** Un outlier puede ser un error que arruina tu an√°lisis O una oportunidad que vale millones. La clave es **distinguirlos**.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Detecci√≥n de patrones: Encontrando el ritmo en el ruido\n",
        "\n",
        "### **Tipos de patrones principales**\n",
        "\n",
        "| Tipo | Descripci√≥n | Ejemplo | Visualizaci√≥n |\n",
        "|------|-------------|---------|---------------|\n",
        "| **Tendencia** | Direcci√≥n general a largo plazo | Aumento de ventas a√±o tras a√±o | Line plot ascendente |\n",
        "| **Estacionalidad** | Repetici√≥n peri√≥dica regular | Ventas altas cada diciembre | Line plot con ciclos |\n",
        "| **Clustering** | Agrupaciones naturales | Clientes de alto/bajo valor | Scatter plot con grupos |\n",
        "| **Correlaci√≥n** | Relaci√≥n entre variables | Temperatura vs ventas helado | Scatter plot lineal |\n",
        "| **Secuencia** | Eventos que ocurren juntos | Productos comprados juntos | Network graph |\n",
        "\n",
        "### **Patrones temporales: El latido del negocio**\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def patrones_temporales(df, fecha_col, valor_col):\n",
        "    \"\"\"Detectar patrones diarios, semanales y horarios\"\"\"\n",
        "    df_temp = df.copy()\n",
        "    df_temp['dia_semana'] = df_temp[fecha_col].dt.day_name()\n",
        "    df_temp['hora'] = df_temp[fecha_col].dt.hour\n",
        "    df_temp['mes'] = df_temp[fecha_col].dt.month\n",
        "    \n",
        "    # Patr√≥n por d√≠a de semana\n",
        "    patron_diario = df_temp.groupby('dia_semana')[valor_col].mean()\n",
        "    \n",
        "    # Patr√≥n por hora\n",
        "    patron_horario = df_temp.groupby('hora')[valor_col].mean()\n",
        "    \n",
        "    # Patr√≥n mensual (estacionalidad)\n",
        "    patron_mensual = df_temp.groupby('mes')[valor_col].mean()\n",
        "    \n",
        "    # Visualizaci√≥n\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "    \n",
        "    patron_diario.plot(kind='bar', ax=axes[0], color='skyblue')\n",
        "    axes[0].set_title('Patr√≥n Semanal')\n",
        "    axes[0].set_xlabel('D√≠a de la semana')\n",
        "    \n",
        "    patron_horario.plot(kind='line', ax=axes[1], marker='o', color='orange')\n",
        "    axes[1].set_title('Patr√≥n Horario')\n",
        "    axes[1].set_xlabel('Hora del d√≠a')\n",
        "    \n",
        "    patron_mensual.plot(kind='bar', ax=axes[2], color='green')\n",
        "    axes[2].set_title('Patr√≥n Estacional (Mensual)')\n",
        "    axes[2].set_xlabel('Mes')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return patron_diario, patron_horario, patron_mensual\n",
        "\n",
        "# Uso en ventas de e-commerce\n",
        "ventas_dia, ventas_hora, ventas_mes = patrones_temporales(\n",
        "    df, 'fecha', 'monto'\n",
        ")\n",
        "\n",
        "print(\"\\n=== PATRONES DETECTADOS ===\")\n",
        "print(\"üìà Lunes: Peak de ventas post-fin de semana\")\n",
        "print(\"üìâ Mi√©rcoles: Valle semanal t√≠pico\")\n",
        "print(\"üéØ Viernes tarde: Compras para el fin de semana\")\n",
        "print(\"üåô Noches: Mobile shopping dominance\")\n",
        "```\n",
        "\n",
        "### **Patrones de agrupaci√≥n natural (Clustering)**\n",
        "\n",
        "```python\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def detectar_grupos_naturales(df, columnas):\n",
        "    \"\"\"Encontrar agrupaciones naturales en los datos\"\"\"\n",
        "    # Estandarizar datos\n",
        "    scaler = StandardScaler()\n",
        "    datos_escalados = scaler.fit_transform(df[columnas])\n",
        "    \n",
        "    # M√©todo del codo para encontrar k √≥ptimo\n",
        "    inercias = []\n",
        "    K_range = range(2, 9)\n",
        "    for k in K_range:\n",
        "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "        kmeans.fit(datos_escalados)\n",
        "        inercias.append(kmeans.inertia_)\n",
        "    \n",
        "    # Visualizar m√©todo del codo\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(K_range, inercias, marker='o', linestyle='-', color='b')\n",
        "    plt.xlabel('N√∫mero de clusters (k)')\n",
        "    plt.ylabel('Inercia')\n",
        "    plt.title('M√©todo del Codo para Elegir K')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "    \n",
        "    # Aplicar K-means con k √≥ptimo (seg√∫n gr√°fico)\n",
        "    k_optimo = 3  # Ajustar seg√∫n el codo visual\n",
        "    kmeans = KMeans(n_clusters=k_optimo, random_state=42)\n",
        "    df['cluster'] = kmeans.fit_predict(datos_escalados)\n",
        "    \n",
        "    # An√°lisis de clusters\n",
        "    print(\"\\n=== AN√ÅLISIS DE CLUSTERS ===\")\n",
        "    for i in range(k_optimo):\n",
        "        cluster_data = df[df['cluster'] == i]\n",
        "        print(f\"\\nCluster {i} (n={len(cluster_data)}):\")\n",
        "        print(cluster_data[columnas].describe())\n",
        "    \n",
        "    return df, kmeans\n",
        "\n",
        "# Uso: segmentaci√≥n de clientes\n",
        "df_segmentado, modelo = detectar_grupos_naturales(\n",
        "    df,\n",
        "    ['ingreso_total', 'frecuencia_compra', 'antiguedad_dias']\n",
        ")\n",
        "```\n",
        "\n",
        "### **Patrones de correlaci√≥n**\n",
        "\n",
        "```python\n",
        "def analizar_correlaciones(df, umbral=0.7):\n",
        "    \"\"\"Encuentra correlaciones fuertes entre variables\"\"\"\n",
        "    # Solo variables num√©ricas\n",
        "    df_numerico = df.select_dtypes(include=[np.number])\n",
        "    \n",
        "    # Matriz de correlaci√≥n\n",
        "    correlacion = df_numerico.corr()\n",
        "    \n",
        "    # Visualizaci√≥n\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(correlacion, annot=True, cmap='coolwarm',\n",
        "                center=0, fmt='.2f', square=True)\n",
        "    plt.title('Matriz de Correlaci√≥n')\n",
        "    plt.show()\n",
        "    \n",
        "    # Encontrar correlaciones fuertes\n",
        "    corr_abs = correlacion.abs()\n",
        "    upper = corr_abs.where(\n",
        "        np.triu(np.ones(corr_abs.shape), k=1).astype(bool)\n",
        "    )\n",
        "    \n",
        "    fuertes = []\n",
        "    for column in upper.columns:\n",
        "        for row in upper.index:\n",
        "            if upper.loc[row, column] > umbral:\n",
        "                fuertes.append((row, column, correlacion.loc[row, column]))\n",
        "    \n",
        "    print(\"\\n=== CORRELACIONES FUERTES ===\")\n",
        "    for var1, var2, valor in fuertes:\n",
        "        print(f\"{var1} <-> {var2}: {valor:.3f}\")\n",
        "    \n",
        "    return correlacion, fuertes\n",
        "\n",
        "# Uso\n",
        "correlaciones, pares_fuertes = analizar_correlaciones(df, umbral=0.7)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Detecci√≥n de outliers: Cazando anomal√≠as\n",
        "\n",
        "### **Clasificaci√≥n de outliers**\n",
        "\n",
        "| Tipo | Definici√≥n | Causa com√∫n | Acci√≥n t√≠pica |\n",
        "|------|------------|-------------|---------------|\n",
        "| **Error de medici√≥n** | Dato mal capturado | Error humano, sensor roto | Eliminar o corregir |\n",
        "| **Error de procesamiento** | Dato mal transformado | Bug en c√≥digo, formato incorrecto | Corregir pipeline |\n",
        "| **Evento genuino raro** | Dato real pero extremo | Cliente VIP, Black Friday | **Mantener y analizar** |\n",
        "| **Fraude/Anomal√≠a** | Dato sospechoso | Fraude, ataque, manipulaci√≥n | Investigar y separar |\n",
        "\n",
        "### **M√©todo 1: Rango Intercuart√≠lico (IQR) - El cl√°sico**\n",
        "\n",
        "```python\n",
        "def detectar_outliers_iqr(df, columna):\n",
        "    \"\"\"Detecta outliers usando el m√©todo IQR\"\"\"\n",
        "    Q1 = df[columna].quantile(0.25)\n",
        "    Q3 = df[columna].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    \n",
        "    limite_inferior = Q1 - 1.5 * IQR\n",
        "    limite_superior = Q3 + 1.5 * IQR\n",
        "    \n",
        "    outliers = df[(df[columna] < limite_inferior) |\n",
        "                  (df[columna] > limite_superior)]\n",
        "    \n",
        "    print(f\"\\n=== DETECCI√ìN IQR: {columna} ===\")\n",
        "    print(f\"Q1: {Q1:.2f}, Q3: {Q3:.2f}, IQR: {IQR:.2f}\")\n",
        "    print(f\"L√≠mites: [{limite_inferior:.2f}, {limite_superior:.2f}]\")\n",
        "    print(f\"Outliers: {len(outliers)} ({len(outliers)/len(df)*100:.1f}%)\")\n",
        "    \n",
        "    return outliers, limite_inferior, limite_superior\n",
        "\n",
        "# Uso y visualizaci√≥n\n",
        "outliers_precio, lim_inf, lim_sup = detectar_outliers_iqr(df, 'precio')\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Boxplot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.boxplot(df['precio'], vert=False)\n",
        "plt.xlabel('Precio')\n",
        "plt.title('Boxplot: Detecci√≥n de Outliers')\n",
        "\n",
        "# Histograma con l√≠mites\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(df['precio'], bins=50, alpha=0.7)\n",
        "plt.axvline(lim_inf, color='red', linestyle='--', label='L√≠mite inferior')\n",
        "plt.axvline(lim_sup, color='red', linestyle='--', label='L√≠mite superior')\n",
        "plt.xlabel('Precio')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.title('Histograma con L√≠mites IQR')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### **M√©todo 2: Z-Score - Para distribuciones normales**\n",
        "\n",
        "```python\n",
        "from scipy import stats\n",
        "\n",
        "def detectar_outliers_zscore(df, columna, umbral=3):\n",
        "    \"\"\"Detecta outliers usando Z-score\"\"\"\n",
        "    z_scores = np.abs(stats.zscore(df[columna].dropna()))\n",
        "    outliers_mask = z_scores > umbral\n",
        "    outliers = df.loc[df[columna].notna()].iloc[np.where(outliers_mask)[0]]\n",
        "    \n",
        "    print(f\"\\n=== DETECCI√ìN Z-SCORE: {columna} ===\")\n",
        "    print(f\"Umbral: {umbral} desviaciones est√°ndar\")\n",
        "    print(f\"Outliers: {len(outliers)} ({len(outliers)/len(df)*100:.1f}%)\")\n",
        "    \n",
        "    return outliers\n",
        "\n",
        "# Interpretaci√≥n del Z-score:\n",
        "# |Z| < 2 ‚Üí Normal (95% de los datos)\n",
        "# 2 < |Z| < 3 ‚Üí At√≠pico\n",
        "# |Z| > 3 ‚Üí Outlier extremo\n",
        "\n",
        "outliers_zscore = detectar_outliers_zscore(df, 'precio', umbral=3)\n",
        "```\n",
        "\n",
        "### **M√©todo 3: Isolation Forest - Para datos multivariados**\n",
        "\n",
        "```python\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "def detectar_outliers_multivariados(df, columnas, contaminacion=0.05):\n",
        "    \"\"\"Detecta outliers considerando m√∫ltiples variables\"\"\"\n",
        "    X = df[columnas].dropna()\n",
        "    \n",
        "    # Entrenar modelo\n",
        "    iso_forest = IsolationForest(\n",
        "        contamination=contaminacion,\n",
        "        random_state=42,\n",
        "        n_estimators=100\n",
        "    )\n",
        "    predicciones = iso_forest.fit_predict(X)\n",
        "    \n",
        "    # -1 indica outlier, 1 indica normal\n",
        "    df_resultado = df.loc[X.index].copy()\n",
        "    df_resultado['es_outlier'] = predicciones == -1\n",
        "    outliers = df_resultado[df_resultado['es_outlier']]\n",
        "    \n",
        "    print(f\"\\n=== ISOLATION FOREST ===\")\n",
        "    print(f\"Variables analizadas: {columnas}\")\n",
        "    print(f\"Outliers multivariados: {len(outliers)} ({contaminacion*100}% esperado)\")\n",
        "    \n",
        "    return outliers, iso_forest\n",
        "\n",
        "# Uso: detectar outliers considerando precio, cantidad y descuento\n",
        "outliers_multi, modelo = detectar_outliers_multivariados(\n",
        "    df,\n",
        "    columnas=['precio', 'cantidad', 'descuento'],\n",
        "    contaminacion=0.03\n",
        ")\n",
        "```\n",
        "\n",
        "### **M√©todo 4: DBSCAN - Clustering con outliers**\n",
        "\n",
        "```python\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "def clustering_con_outliers(df, columnas, eps=0.5, min_samples=5):\n",
        "    \"\"\"DBSCAN detecta clusters y outliers autom√°ticamente\"\"\"\n",
        "    # Estandarizar\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(df[columnas])\n",
        "    \n",
        "    # Aplicar DBSCAN\n",
        "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "    clusters = dbscan.fit_predict(X_scaled)\n",
        "    \n",
        "    # -1 indica outliers (noise)\n",
        "    df_resultado = df.copy()\n",
        "    df_resultado['cluster'] = clusters\n",
        "    df_resultado['es_outlier'] = clusters == -1\n",
        "    \n",
        "    n_outliers = sum(clusters == -1)\n",
        "    n_clusters = len(set(clusters)) - (1 if -1 in clusters else 0)\n",
        "    \n",
        "    print(f\"\\n=== DBSCAN ===\")\n",
        "    print(f\"Clusters encontrados: {n_clusters}\")\n",
        "    print(f\"Outliers (noise): {n_outliers} ({n_outliers/len(df)*100:.1f}%)\")\n",
        "    \n",
        "    return df_resultado, dbscan\n",
        "\n",
        "# Uso\n",
        "df_dbscan, modelo_dbscan = clustering_con_outliers(\n",
        "    df, ['precio', 'cantidad'], eps=0.5, min_samples=5\n",
        ")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Caso pr√°ctico: Transacciones financieras\n",
        "\n",
        "**Contexto:** Dataset de 50,000 transacciones de tarjetas de cr√©dito. Buscamos patrones de gasto y transacciones fraudulentas.\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. CARGAR Y PREPARAR DATOS\n",
        "transacciones = pd.read_csv('transacciones.csv',\n",
        "                            parse_dates=['fecha_transaccion'])\n",
        "transacciones['hora'] = transacciones['fecha_transaccion'].dt.hour\n",
        "transacciones['dia_semana'] = transacciones['fecha_transaccion'].dt.day_name()\n",
        "\n",
        "print(f\"Total transacciones: {len(transacciones)}\")\n",
        "\n",
        "# 2. AN√ÅLISIS DE PATRONES POR CATEGOR√çA\n",
        "gasto_por_categoria = transacciones.groupby('categoria')['monto'].agg([\n",
        "    'mean', 'std', 'count', 'min', 'max'\n",
        "])\n",
        "print(\"\\n=== PATR√ìN DE GASTO POR CATEGOR√çA ===\")\n",
        "print(gasto_por_categoria.sort_values('mean', ascending=False))\n",
        "\n",
        "# 3. DETECCI√ìN DE OUTLIERS POR CATEGOR√çA\n",
        "def outliers_por_categoria(df, categoria_col, monto_col):\n",
        "    \"\"\"Detectar outliers dentro de cada categor√≠a\"\"\"\n",
        "    resultados = {}\n",
        "    \n",
        "    for categoria in df[categoria_col].unique():\n",
        "        subset = df[df[categoria_col] == categoria]\n",
        "        outliers_cat, lim_inf, lim_sup = detectar_outliers_iqr(\n",
        "            subset, monto_col\n",
        "        )\n",
        "        \n",
        "        resultados[categoria] = {\n",
        "            'outliers': outliers_cat,\n",
        "            'n_transacciones': len(subset),\n",
        "            'n_outliers': len(outliers_cat),\n",
        "            'porcentaje': len(outliers_cat) / len(subset) * 100,\n",
        "            'limite_superior': lim_sup\n",
        "        }\n",
        "    \n",
        "    return resultados\n",
        "\n",
        "outliers_por_cat = outliers_por_categoria(\n",
        "    transacciones, 'categoria', 'monto'\n",
        ")\n",
        "\n",
        "# 4. IDENTIFICAR CATEGOR√çAS SOSPECHOSAS\n",
        "print(\"\\n=== AN√ÅLISIS DE RIESGO POR CATEGOR√çA ===\")\n",
        "for categoria, info in outliers_por_cat.items():\n",
        "    if info['porcentaje'] > 5:\n",
        "        print(f\"‚ö†Ô∏è  ALERTA: {categoria}\")\n",
        "        print(f\"   - {info['porcentaje']:.1f}% de outliers\")\n",
        "        print(f\"   - {info['n_outliers']} transacciones sospechosas\")\n",
        "\n",
        "# 5. MARCAR OUTLIERS EN DATASET COMPLETO\n",
        "transacciones['es_outlier'] = False\n",
        "for categoria, info in outliers_por_cat.items():\n",
        "    indices_outliers = info['outliers'].index\n",
        "    transacciones.loc[indices_outliers, 'es_outlier'] = True\n",
        "\n",
        "# 6. COMPARAR PATRONES: NORMALES VS OUTLIERS\n",
        "patron_normal = transacciones[~transacciones['es_outlier']].groupby('hora').size()\n",
        "patron_outliers = transacciones[transacciones['es_outlier']].groupby('hora').size()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(patron_normal.index, patron_normal.values,\n",
        "         label='Transacciones Normales', marker='o', linewidth=2)\n",
        "plt.plot(patron_outliers.index, patron_outliers.values,\n",
        "         label='Outliers (Sospechosas)', marker='s', linewidth=2, color='red')\n",
        "plt.xlabel('Hora del d√≠a')\n",
        "plt.ylabel('N√∫mero de transacciones')\n",
        "plt.title('Patr√≥n Horario: Normales vs Outliers')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# 7. ESTAD√çSTICAS FINALES\n",
        "print(\"\\n=== RESULTADO FINAL ===\")\n",
        "print(f\"Transacciones analizadas: {len(transacciones)}\")\n",
        "print(f\"Outliers detectados: {transacciones['es_outlier'].sum()}\")\n",
        "print(f\"Porcentaje de outliers: {transacciones['es_outlier'].mean()*100:.1f}%\")\n",
        "```\n",
        "\n",
        "**Hallazgos del caso:**\n",
        "- üéØ **Restaurantes de lujo:** 12% de outliers (eventos especiales + posibles fraudes)\n",
        "- ‚è∞ **Concentraci√≥n horaria:** Outliers entre 2-5 AM (horario inusual para transacciones grandes)\n",
        "- üí° **Patr√≥n descubierto:** Los outliers en \"Electr√≥nicos\" segu√≠an patr√≥n de compras corporativas, no fraude\n",
        "- üö® **Acci√≥n:** 25 transacciones reportadas al equipo antifraude\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Matriz de decisi√≥n: ¬øQu√© hago con los outliers?\n",
        "\n",
        "### **Framework de an√°lisis**\n",
        "\n",
        "| Pregunta | Respuesta | Acci√≥n |\n",
        "|----------|-----------|--------|\n",
        "| ¬øEs f√≠sicamente posible? | NO | **ELIMINAR** - Error de medici√≥n |\n",
        "| ¬øTiene sentido en el negocio? | NO | **INVESTIGAR** - Posible fraude |\n",
        "| ¬øEs un evento genuino raro? | S√ç | **MANTENER** - Informaci√≥n valiosa |\n",
        "| ¬øAfecta significativamente al an√°lisis? | S√ç | **SEPARAR** - Segmento especial |\n",
        "\n",
        "### **Estrategias de tratamiento**\n",
        "\n",
        "```python\n",
        "# ELIMINAR outliers (errores confirmados)\n",
        "df_limpio = df[~df['es_outlier']]\n",
        "\n",
        "# WINSORIZAR (cap a percentiles - suavizar extremos)\n",
        "percentil_1 = df['precio'].quantile(0.01)\n",
        "percentil_99 = df['precio'].quantile(0.99)\n",
        "df['precio_winsorizado'] = df['precio'].clip(percentil_1, percentil_99)\n",
        "\n",
        "# TRANSFORMAR (log para reducir impacto)\n",
        "df['precio_log'] = np.log1p(df['precio'])  # log(1+x) evita log(0)\n",
        "\n",
        "# SEPARAR en segmentos\n",
        "df['segmento'] = np.where(\n",
        "    df['precio'] > df['precio'].quantile(0.99),\n",
        "    'VIP',\n",
        "    'Regular'\n",
        ")\n",
        "\n",
        "# MANTENER con variable dummy\n",
        "df['es_outlier_precio'] = df['precio'] > limite_superior\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 6. T√©cnicas avanzadas: Patrones especiales\n",
        "\n",
        "### **Descomposici√≥n estacional**\n",
        "\n",
        "```python\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "\n",
        "def analizar_estacionalidad(serie_temporal, periodo=30):\n",
        "    \"\"\"Descomponer serie en tendencia, estacionalidad y residuales\"\"\"\n",
        "    resultado = seasonal_decompose(\n",
        "        serie_temporal,\n",
        "        model='additive',  # 'multiplicative' para crecimientos %\n",
        "        period=periodo\n",
        "    )\n",
        "    \n",
        "    # Visualizaci√≥n\n",
        "    fig, axes = plt.subplots(4, 1, figsize=(12, 10))\n",
        "    \n",
        "    resultado.observed.plot(ax=axes[0], title='Serie Original')\n",
        "    axes[0].set_ylabel('Observado')\n",
        "    \n",
        "    resultado.trend.plot(ax=axes[1], title='Tendencia')\n",
        "    axes[1].set_ylabel('Tendencia')\n",
        "    \n",
        "    resultado.seasonal.plot(ax=axes[2], title='Componente Estacional')\n",
        "    axes[2].set_ylabel('Estacionalidad')\n",
        "    \n",
        "    resultado.resid.plot(ax=axes[3], title='Residuales (Outliers potenciales)')\n",
        "    axes[3].set_ylabel('Residuales')\n",
        "    axes[3].axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Outliers en residuales\n",
        "    residuales = resultado.resid.dropna()\n",
        "    outliers_residuales = detectar_outliers_zscore(\n",
        "        pd.DataFrame({'residual': residuales}),\n",
        "        'residual',\n",
        "        umbral=2\n",
        "    )\n",
        "    \n",
        "    print(f\"Outliers temporales detectados: {len(outliers_residuales)}\")\n",
        "    \n",
        "    return resultado\n",
        "\n",
        "# Uso con ventas diarias\n",
        "ventas_diarias = df.groupby('fecha')['ventas'].sum()\n",
        "resultado_estacional = analizar_estacionalidad(ventas_diarias, periodo=7)\n",
        "```\n",
        "\n",
        "### **Market Basket Analysis (Patrones de secuencia)**\n",
        "\n",
        "```python\n",
        "def patrones_compras_conjuntas(transacciones):\n",
        "    \"\"\"Encontrar productos que se compran juntos\"\"\"\n",
        "    from mlxtend.frequent_patterns import apriori, association_rules\n",
        "    \n",
        "    # Crear matriz one-hot (basket format)\n",
        "    basket = transacciones.groupby(['id_transaccion', 'producto'])['cantidad'].sum()\n",
        "    basket = basket.unstack().fillna(0)\n",
        "    basket = basket.applymap(lambda x: 1 if x > 0 else 0)\n",
        "    \n",
        "    # Itemsets frecuentes\n",
        "    itemsets_frecuentes = apriori(basket, min_support=0.01, use_colnames=True)\n",
        "    \n",
        "    # Reglas de asociaci√≥n\n",
        "    reglas = association_rules(\n",
        "        itemsets_frecuentes,\n",
        "        metric=\"lift\",\n",
        "        min_threshold=1.0\n",
        "    )\n",
        "    \n",
        "    # Top reglas\n",
        "    top_reglas = reglas.sort_values('lift', ascending=False).head(10)\n",
        "    \n",
        "    print(\"\\n=== TOP 10 PATRONES DE COMPRA ===\")\n",
        "    for idx, row in top_reglas.iterrows():\n",
        "        print(f\"{list(row['antecedents'])} ‚Üí {list(row['consequents'])}\")\n",
        "        print(f\"  Lift: {row['lift']:.2f}, Confianza: {row['confidence']:.2%}\\n\")\n",
        "    \n",
        "    return reglas\n",
        "\n",
        "# Uso\n",
        "reglas_asociacion = patrones_compras_conjuntas(transacciones)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Pipeline completo de an√°lisis\n",
        "\n",
        "```python\n",
        "def pipeline_patrones_outliers(df):\n",
        "    \"\"\"Pipeline completo para an√°lisis de patrones y outliers\"\"\"\n",
        "    resultados = {}\n",
        "    \n",
        "    print(\"=== INICIANDO AN√ÅLISIS COMPLETO ===\\n\")\n",
        "    \n",
        "    # 1. Patrones temporales\n",
        "    if 'fecha' in df.columns:\n",
        "        print(\"1. Analizando patrones temporales...\")\n",
        "        resultados['patrones_temporales'] = patrones_temporales(\n",
        "            df, 'fecha', 'valor'\n",
        "        )\n",
        "    \n",
        "    # 2. Outliers univariados\n",
        "    print(\"\\n2. Detectando outliers univariados...\")\n",
        "    columnas_numericas = df.select_dtypes(include=[np.number]).columns\n",
        "    resultados['outliers_univariados'] = {}\n",
        "    \n",
        "    for col in columnas_numericas[:3]:  # Primeras 3 para no sobrecargar\n",
        "        outliers, _, _ = detectar_outliers_iqr(df, col)\n",
        "        resultados['outliers_univariados'][col] = outliers\n",
        "    \n",
        "    # 3. Outliers multivariados\n",
        "    if len(columnas_numericas) >= 2:\n",
        "        print(\"\\n3. Detectando outliers multivariados...\")\n",
        "        resultados['outliers_multivariados'], _ = detectar_outliers_multivariados(\n",
        "            df, columnas_numericas.tolist()[:3]\n",
        "        )\n",
        "    \n",
        "    # 4. Clustering\n",
        "    print(\"\\n4. Analizando clustering...\")\n",
        "    resultados['clustering'], _ = detectar_grupos_naturales(\n",
        "        df, columnas_numericas.tolist()[:3]\n",
        "    )\n",
        "    \n",
        "    # 5. Correlaciones\n",
        "    print(\"\\n5. Analizando correlaciones...\")\n",
        "    resultados['correlaciones'], resultados['correlaciones_fuertes'] = analizar_correlaciones(df)\n",
        "    \n",
        "    print(\"\\n=== AN√ÅLISIS COMPLETO ===\")\n",
        "    return resultados\n",
        "\n",
        "# Uso\n",
        "resultados_completos = pipeline_patrones_outliers(df)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 8. Buenas pr√°cticas\n",
        "\n",
        "### ‚úÖ **Hacer siempre:**\n",
        "\n",
        "```python\n",
        "# Documentar umbrales y decisiones\n",
        "# IQR con factor 1.5 para moderados, 3.0 para extremos\n",
        "outliers = detectar_outliers_iqr(df, 'precio')  # Factor 1.5 por defecto\n",
        "\n",
        "# Considerar contexto de negocio\n",
        "# Un outlier en diciembre puede ser normal (Navidad)\n",
        "\n",
        "# Visualizar antes de decidir\n",
        "visualizar_outliers(df, 'variable_critica')\n",
        "\n",
        "# Comparar antes/despu√©s\n",
        "print(f\"Media antes: {df['precio'].mean():.2f}\")\n",
        "df_limpio = df[~df['es_outlier']]\n",
        "print(f\"Media despu√©s: {df_limpio['precio'].mean():.2f}\")\n",
        "```\n",
        "\n",
        "### ‚ùå **Evitar:**\n",
        "\n",
        "```python\n",
        "# ‚ùå NO eliminar autom√°ticamente\n",
        "# df = df[z_scores < 3]  # PELIGRO: P√©rdida de informaci√≥n valiosa\n",
        "\n",
        "# ‚ùå NO usar Z-score en distribuciones no normales\n",
        "# Verifica normalidad primero\n",
        "\n",
        "# ‚ùå NO ignorar el clustering natural\n",
        "# Los outliers pueden formar su propio cluster v√°lido\n",
        "```\n",
        "\n",
        "### **Checklist de an√°lisis**\n",
        "\n",
        "- [ ] Patrones temporales identificados (d√≠a, hora, mes)\n",
        "- [ ] Outliers univariados detectados (IQR/Z-score)\n",
        "- [ ] Outliers multivariados analizados (Isolation Forest)\n",
        "- [ ] Clusters naturales descubiertos (K-means/DBSCAN)\n",
        "- [ ] Correlaciones evaluadas (heatmap)\n",
        "- [ ] Contexto de negocio consultado\n",
        "- [ ] Decisiones sobre outliers documentadas\n",
        "- [ ] Impacto en estad√≠sticas validado\n",
        "\n",
        "---\n",
        "\n",
        "## 9. Resumen\n",
        "\n",
        "**Patrones detectables:**\n",
        "- ‚úÖ **Temporales** ‚Üí Tendencias, estacionalidad, ciclos\n",
        "- ‚úÖ **Clustering** ‚Üí Agrupaciones naturales (segmentos)\n",
        "- ‚úÖ **Correlaciones** ‚Üí Relaciones entre variables\n",
        "- ‚úÖ **Secuencias** ‚Üí Eventos que ocurren juntos\n",
        "\n",
        "**M√©todos de detecci√≥n de outliers:**\n",
        "- ‚úÖ **IQR** ‚Üí Cl√°sico, robusto, univariado\n",
        "- ‚úÖ **Z-Score** ‚Üí Para distribuciones normales\n",
        "- ‚úÖ **Isolation Forest** ‚Üí Multivariado, machine learning\n",
        "- ‚úÖ **DBSCAN** ‚Üí Clustering + outliers simult√°neo\n",
        "\n",
        "**Framework de decisi√≥n:**\n",
        "```\n",
        "¬øEs f√≠sicamente posible? ‚Üí NO ‚Üí ELIMINAR\n",
        "            ‚Üì S√ç\n",
        "¬øTiene sentido en negocio? ‚Üí NO ‚Üí INVESTIGAR\n",
        "            ‚Üì S√ç\n",
        "¬øEs evento genuino raro? ‚Üí S√ç ‚Üí MANTENER/SEPARAR\n",
        "            ‚Üì NO\n",
        "            WINSORIZAR/TRANSFORMAR\n",
        "```\n",
        "\n",
        "> **Conclusi√≥n:** Los patrones te dicen qu√© esperar. Los outliers te dicen cu√°ndo esperar lo inesperado. Dominar ambos transforma un analista junior en senior.\n",
        "\n",
        "---\n",
        "\n",
        "## 10. Referencias\n",
        "\n",
        "### V√≠deos\n",
        "- [Outlier Detection Explained](https://youtu.be/example1) - M√©todos visuales\n",
        "- [Pattern Recognition in Data](https://youtu.be/example2) - T√©cnicas avanzadas\n",
        "- [Netflix Data Analysis](https://youtu.be/example3) - Caso real\n",
        "\n",
        "### Lecturas\n",
        "- [Scikit-learn Outlier Detection](https://scikit-learn.org/stable/modules/outlier_detection.html)\n",
        "- [Time Series Patterns](https://otexts.com/fpp2/patterns.html)\n",
        "- [Anomaly Detection Survey](https://arxiv.org/abs/1901.03407)\n",
        "\n",
        "### Herramientas\n",
        "- [PyOD](https://github.com/yzhao062/pyod) - Librer√≠a especializada en outliers\n",
        "- [Prophet](https://facebook.github.io/prophet/) - Patrones temporales (Facebook)\n",
        "- [mlxtend](http://rasbt.github.io/mlxtend/) - Market Basket Analysis"
      ],
      "metadata": {
        "id": "oOAUr_71J6iJ"
      }
    }
  ]
}